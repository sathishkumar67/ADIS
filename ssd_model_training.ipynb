{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ADIS'...\n",
      "remote: Enumerating objects: 1080, done.\u001b[K\n",
      "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
      "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
      "remote: Total 1080 (delta 55), reused 72 (delta 27), pack-reused 978 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1080/1080), 39.95 MiB | 39.67 MiB/s, done.\n",
      "Resolving deltas: 100% (551/551), done.\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-25.0.1\n",
      "Collecting ultralytics (from -r requirements.txt (line 1))\n",
      "  Downloading ultralytics-8.3.107-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting albumentations==2.0.5 (from -r requirements.txt (line 2))\n",
      "  Downloading albumentations-2.0.5-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: optuna==4.2.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.2.1)\n",
      "Requirement already satisfied: huggingface-hub==0.30.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.30.2)\n",
      "Collecting lmdb==1.6.2 (from -r requirements.txt (line 5))\n",
      "  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: opencv-python==4.11.0.86 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (4.11.0.86)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (1.26.4)\n",
      "Requirement already satisfied: torchmetrics==1.7.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.7.1)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 2)) (1.15.2)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 2)) (2.11.3)\n",
      "Requirement already satisfied: albucore==0.0.23 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 2)) (0.0.23)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 2)) (4.11.0.86)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.1->-r requirements.txt (line 3)) (1.15.2)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.1->-r requirements.txt (line 3)) (6.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.1->-r requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.1->-r requirements.txt (line 3)) (2.0.38)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna==4.2.1->-r requirements.txt (line 3))\n",
      "  Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 4)) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 4)) (2025.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 4)) (4.13.1)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub==0.30.2->-r requirements.txt (line 4))\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (1.3.8)\n",
      "Collecting mkl_fft (from numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading mkl_fft-1.3.13-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (1.2.4)\n",
      "Collecting mkl_random (from numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading mkl_random-1.2.10-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (0.1.1)\n",
      "Collecting mkl_umath (from numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading mkl_umath-0.1.5-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (2.4.1)\n",
      "Collecting mkl-service (from numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading mkl_service-2.4.2-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.7.1->-r requirements.txt (line 9)) (2.5.1+cu124)\n",
      "Collecting torch>=2.0.0 (from torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.7.1->-r requirements.txt (line 9)) (0.14.3)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations==2.0.5->-r requirements.txt (line 2)) (3.11.3)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.23->albumentations==2.0.5->-r requirements.txt (line 2))\n",
      "  Downloading stringzilla-3.12.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (80 kB)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations==2.0.5->-r requirements.txt (line 2)) (6.2.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (3.7.5)\n",
      "Collecting matplotlib>=3.3.0 (from ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (11.1.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (0.20.1+cu124)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (0.12.2)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna==4.2.1->-r requirements.txt (line 3)) (1.3.9)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna==4.2.1->-r requirements.txt (line 3))\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (75.1.0)\n",
      "Collecting setuptools (from lightning-utilities>=0.8.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (4.56.0)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading fonttools-4.57.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (3.2.1)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations==2.0.5->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations==2.0.5->-r requirements.txt (line 2)) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations==2.0.5->-r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 4)) (2.3.0)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 4))\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 4)) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna==4.2.1->-r requirements.txt (line 3)) (3.1.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4->-r requirements.txt (line 8)) (2024.2.0)\n",
      "Collecting intel-openmp<2026,>=2024 (from mkl->numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading intel_openmp-2025.1.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4->-r requirements.txt (line 8)) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy==1.26.4->-r requirements.txt (line 8)) (1.2.0)\n",
      "Collecting tcmlib==1.* (from tbb==2022.*->mkl->numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading tcmlib-1.3.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (964 bytes)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy==1.26.4->-r requirements.txt (line 8)) (2024.2.0)\n",
      "Collecting intel-cmplr-lib-rt (from mkl_umath->numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading intel_cmplr_lib_rt-2025.1.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting intel-cmplr-lib-ur==2025.1.0 (from intel-openmp<2026,>=2024->mkl->numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading intel_cmplr_lib_ur-2025.1.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting umf==0.10.* (from intel-cmplr-lib-ur==2025.1.0->intel-openmp<2026,>=2024->mkl->numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading umf-0.10.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (3.0.2)\n",
      "Downloading albumentations-2.0.5-py3-none-any.whl (290 kB)\n",
      "Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n",
      "Downloading ultralytics-8.3.107-py3-none-any.whl (974 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.5/974.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m130.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Downloading tcmlib-1.3.0-py2.py3-none-manylinux_2_28_x86_64.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mkl_fft-1.3.13-0-cp311-cp311-manylinux_2_28_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mkl_random-1.2.10-0-cp311-cp311-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mkl_service-2.4.2-0-cp311-cp311-manylinux_2_28_x86_64.whl (77 kB)\n",
      "Downloading mkl_umath-0.1.5-0-cp311-cp311-manylinux_2_28_x86_64.whl (441 kB)\n",
      "Downloading fonttools-4.57.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading intel_openmp-2025.1.0-py2.py3-none-manylinux_2_28_x86_64.whl (48.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 MB\u001b[0m \u001b[31m123.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading intel_cmplr_lib_ur-2025.1.0-py2.py3-none-manylinux_2_28_x86_64.whl (26.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m129.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading umf-0.10.0-py2.py3-none-manylinux_2_28_x86_64.whl (314 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading stringzilla-3.12.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (307 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading intel_cmplr_lib_rt-2025.1.0-py2.py3-none-manylinux_2_28_x86_64.whl (47.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Downloading setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, tcmlib, stringzilla, nvidia-cusparselt-cu12, lmdb, intel-cmplr-lib-rt, urllib3, umf, typing-extensions, setuptools, pyparsing, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, Mako, fonttools, sqlalchemy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, intel-cmplr-lib-ur, nvidia-cusolver-cu12, intel-openmp, torch, mkl-service, mkl_umath, mkl_random, mkl_fft, matplotlib, ultralytics-thop, torchvision, seaborn, ultralytics, albumentations\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "  Attempting uninstall: tcmlib\n",
      "    Found existing installation: tcmlib 1.2.0\n",
      "    Uninstalling tcmlib-1.2.0:\n",
      "      Successfully uninstalled tcmlib-1.2.0\n",
      "  Attempting uninstall: stringzilla\n",
      "    Found existing installation: stringzilla 3.11.3\n",
      "    Uninstalling stringzilla-3.11.3:\n",
      "      Successfully uninstalled stringzilla-3.11.3\n",
      "  Attempting uninstall: intel-cmplr-lib-rt\n",
      "    Found existing installation: intel-cmplr-lib-rt 2024.2.0\n",
      "    Uninstalling intel-cmplr-lib-rt-2024.2.0:\n",
      "      Successfully uninstalled intel-cmplr-lib-rt-2024.2.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.3.0\n",
      "    Uninstalling urllib3-2.3.0:\n",
      "      Successfully uninstalled urllib3-2.3.0\n",
      "  Attempting uninstall: umf\n",
      "    Found existing installation: umf 0.9.1\n",
      "    Uninstalling umf-0.9.1:\n",
      "      Successfully uninstalled umf-0.9.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.13.1\n",
      "    Uninstalling typing_extensions-4.13.1:\n",
      "      Successfully uninstalled typing_extensions-4.13.1\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.1.0\n",
      "    Uninstalling setuptools-75.1.0:\n",
      "      Successfully uninstalled setuptools-75.1.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.2.1\n",
      "    Uninstalling pyparsing-3.2.1:\n",
      "      Successfully uninstalled pyparsing-3.2.1\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: Mako\n",
      "    Found existing installation: Mako 1.3.9\n",
      "    Uninstalling Mako-1.3.9:\n",
      "      Successfully uninstalled Mako-1.3.9\n",
      "  Attempting uninstall: fonttools\n",
      "    Found existing installation: fonttools 4.56.0\n",
      "    Uninstalling fonttools-4.56.0:\n",
      "      Successfully uninstalled fonttools-4.56.0\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.38\n",
      "    Uninstalling SQLAlchemy-2.0.38:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.38\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: intel-cmplr-lib-ur\n",
      "    Found existing installation: intel-cmplr-lib-ur 2024.2.0\n",
      "    Uninstalling intel-cmplr-lib-ur-2024.2.0:\n",
      "      Successfully uninstalled intel-cmplr-lib-ur-2024.2.0\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "  Attempting uninstall: intel-openmp\n",
      "    Found existing installation: intel-openmp 2024.2.0\n",
      "    Uninstalling intel-openmp-2024.2.0:\n",
      "      Successfully uninstalled intel-openmp-2024.2.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1+cu124\n",
      "    Uninstalling torch-2.5.1+cu124:\n",
      "      Successfully uninstalled torch-2.5.1+cu124\n",
      "  Attempting uninstall: mkl-service\n",
      "    Found existing installation: mkl-service 2.4.1\n",
      "    Uninstalling mkl-service-2.4.1:\n",
      "      Successfully uninstalled mkl-service-2.4.1\n",
      "  Attempting uninstall: mkl_umath\n",
      "    Found existing installation: mkl-umath 0.1.1\n",
      "    Uninstalling mkl-umath-0.1.1:\n",
      "      Successfully uninstalled mkl-umath-0.1.1\n",
      "  Attempting uninstall: mkl_random\n",
      "    Found existing installation: mkl-random 1.2.4\n",
      "    Uninstalling mkl-random-1.2.4:\n",
      "      Successfully uninstalled mkl-random-1.2.4\n",
      "  Attempting uninstall: mkl_fft\n",
      "    Found existing installation: mkl-fft 1.3.8\n",
      "    Uninstalling mkl-fft-1.3.8:\n",
      "      Successfully uninstalled mkl-fft-1.3.8\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.5\n",
      "    Uninstalling matplotlib-3.7.5:\n",
      "      Successfully uninstalled matplotlib-3.7.5\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.20.1+cu124\n",
      "    Uninstalling torchvision-0.20.1+cu124:\n",
      "      Successfully uninstalled torchvision-0.20.1+cu124\n",
      "  Attempting uninstall: seaborn\n",
      "    Found existing installation: seaborn 0.12.2\n",
      "    Uninstalling seaborn-0.12.2:\n",
      "      Successfully uninstalled seaborn-0.12.2\n",
      "  Attempting uninstall: albumentations\n",
      "    Found existing installation: albumentations 2.0.4\n",
      "    Uninstalling albumentations-2.0.4:\n",
      "      Successfully uninstalled albumentations-2.0.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sigstore 3.6.1 requires rich~=13.0, but you have rich 14.0.0 which is incompatible.\n",
      "datasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "ydata-profiling 4.16.1 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.1 which is incompatible.\n",
      "nilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "google-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.2 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.0.0 which is incompatible.\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "ibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
      "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\n",
      "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\n",
      "google-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.10 albumentations-2.0.5 fonttools-4.57.0 intel-cmplr-lib-rt-2025.1.0 intel-cmplr-lib-ur-2025.1.0 intel-openmp-2025.1.0 lmdb-1.6.2 matplotlib-3.10.1 mkl-service-2.4.2 mkl_fft-1.3.13 mkl_random-1.2.10 mkl_umath-0.1.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nvjitlink-cu12-12.4.127 pyparsing-3.2.3 seaborn-0.13.2 setuptools-78.1.0 sqlalchemy-2.0.40 stringzilla-3.12.3 tcmlib-1.3.0 torch-2.6.0 torchvision-0.21.0 triton-3.2.0 typing-extensions-4.13.2 ultralytics-8.3.107 ultralytics-thop-2.0.14 umf-0.10.0 urllib3-2.4.0\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu126/torchaudio-2.6.0%2Bcu126-cp311-cp311-linux_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.13)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.10)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.5)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2025.1.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2025.1.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2025.1.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2025.1.0)\n",
      "Requirement already satisfied: umf==0.10.* in /usr/local/lib/python3.11/dist-packages (from intel-cmplr-lib-ur==2025.1.0->intel-openmp<2026,>=2024->mkl->numpy->torchvision) (0.10.0)\n",
      "Downloading https://download.pytorch.org/whl/cu126/torchaudio-2.6.0%2Bcu126-cp311-cp311-linux_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchaudio\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.5.1+cu124\n",
      "    Uninstalling torchaudio-2.5.1+cu124:\n",
      "      Successfully uninstalled torchaudio-2.5.1+cu124\n",
      "Successfully installed torchaudio-2.6.0+cu126\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sathishkumar67/ADIS.git\n",
    "!mv /kaggle/working/ADIS/* /kaggle/working/\n",
    "!pip install --upgrade pip\n",
    "!pip install  -r requirements.txt --upgrade --upgrade-strategy eager\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b32d1f2bf814f8090ab793f37149ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "balanced_dataset.zip:   0%|          | 0.00/7.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unzipping: 100%|██████████| 7.07G/7.07G [00:43<00:00, 164MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 4\n"
     ]
    }
   ],
   "source": [
    "# necessary imports\n",
    "import os\n",
    "from huggingface_hub import hf_hub_download\n",
    "from utils import unzip_file\n",
    "\n",
    "REPO_ID = \"pt-sk/ADIS\" \n",
    "DATASET_NAME = \"balanced_dataset\"\n",
    "REPO_TYPE = \"dataset\"\n",
    "FILENAME_IN_REPO = f\"{DATASET_NAME}.zip\"\n",
    "LOCAL_DIR = os.getcwd()\n",
    "DATASET_PATH = f\"{LOCAL_DIR}/{FILENAME_IN_REPO}\"\n",
    "DATASET_FOLDER_PATH = f\"{LOCAL_DIR}/{DATASET_NAME}\"\n",
    "NUM_CLASSES = 10                                               \n",
    "CLASSES = ['Cat', 'Cattle', 'Chicken', 'Deer', 'Dog', 'Squirrel', 'Eagle', 'Goat', 'Rodents', 'Snake'] \n",
    "BACKGROUND_CLASS_ID = 0\n",
    "MODEL_NUM_CLASSES = NUM_CLASSES + 1     # 1 for background class\n",
    "\n",
    "# download the dataset and unzip it\n",
    "hf_hub_download(repo_id=REPO_ID, filename=FILENAME_IN_REPO, repo_type=REPO_TYPE, local_dir=LOCAL_DIR)\n",
    "unzip_file(DATASET_PATH, LOCAL_DIR)\n",
    "\n",
    "# remove dataset.zip\n",
    "os.remove(DATASET_PATH)\n",
    "\n",
    "# number of cores\n",
    "num_cores = os.cpu_count()\n",
    "print(f\"Number of CPU cores: {num_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import lmdb\n",
    "import numpy as np\n",
    "import shutil\n",
    "from functools import partial\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection import ssdlite320_mobilenet_v3_large\n",
    "from torchvision.models.detection.ssdlite import SSDLiteClassificationHead\n",
    "from torchvision.models.detection import _utils as det_utils\n",
    "from torchmetrics.detection import MeanAveragePrecision\n",
    "from typing import List, Tuple, Dict, Any # Import necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSDLITEOBJDET_DATASET(Dataset):\n",
    "    def __init__(self, root_dir: str, split: str, num_classes: int, img_size: int=320, mode: str=\"train\", dtype=np.float32) -> None:\n",
    "        super().__init__()\n",
    "        self.root_dir, self.split, self.img_size, self.num_classes = root_dir, split.lower(), img_size, num_classes\n",
    "        self.current_dir = os.path.join(self.root_dir, self.split)\n",
    "        self.mode =  mode\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        # check if model is train or eval\n",
    "        if self.mode not in [\"train\", \"eval\"]:\n",
    "            raise ValueError(f\"Invalid mode: {self.mode}. Expected 'train' or 'eval'.\")\n",
    "        \n",
    "        # set interpolation method for resizing\n",
    "        self.interpolation = cv2.INTER_LANCZOS4 if self.mode == \"train\" else cv2.INTER_LINEAR\n",
    "\n",
    "        # Validate current directory\n",
    "        if not os.path.exists(self.current_dir):\n",
    "            raise FileNotFoundError(f\"{self.current_dir} does not exist.\")\n",
    "        elif not os.path.isdir(self.current_dir):\n",
    "            raise NotADirectoryError(f\"{self.current_dir} is not a directory.\")\n",
    "        \n",
    "        # check if the split directory is empty\n",
    "        if len(os.listdir(self.current_dir)) == 0:\n",
    "            raise ValueError(f\"The directory {self.current_dir} is empty.\")\n",
    "        \n",
    "        # get image and label files\n",
    "        self.image_files = sorted(\n",
    "            [os.path.join(self.current_dir, f) for f in os.listdir(self.current_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))],\n",
    "            key=lambda x: os.path.splitext(x)[0]\n",
    "        )\n",
    "        self.label_files = [os.path.join(self.current_dir, os.path.splitext(f)[0] + '.txt') for f in self.image_files]\n",
    "\n",
    "        # Validate existence for ALL label files\n",
    "        for img_file, lbl_file in zip(self.image_files, self.label_files):\n",
    "            if not os.path.exists(lbl_file):\n",
    "                raise FileNotFoundError(f\"Label file missing for {img_file}\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[torch.Tensor, dict]:\n",
    "        img_path, label_path = self.image_files[idx], self.label_files[idx]\n",
    "\n",
    "        # Read image and convert to RGB format\n",
    "        image = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "        orig_height, orig_width, _ = image.shape\n",
    "        # tensor with uint8 datatype \n",
    "        image = cv2.resize(image, (self.img_size, self.img_size), interpolation=self.interpolation)\n",
    "        \n",
    "        # Read label file and parse the bounding boxes and labels\n",
    "        data = np.loadtxt(label_path, dtype=self.dtype, delimiter=' ', ndmin=2)\n",
    "        \n",
    "        if data.size == 0:\n",
    "            return image, {\n",
    "                'boxes': np.array([[0.0, 0.0, 1.0, 1.0]], dtype=self.dtype),\n",
    "                'labels': np.array(0, dtype=np.uint8)\n",
    "            }\n",
    "        else:\n",
    "            # Convert normalized box coordinates into absolute coordinates, where orig_width and orig_height are your original dimensions.\n",
    "            cx, cy, w, h = data[:, 1], data[:, 2], data[:, 3], data[:, 4]\n",
    "            xmin = np.maximum(0, (cx - w/2) * orig_width)\n",
    "            ymin = np.maximum(0, (cy - h/2) * orig_height)\n",
    "            xmax = np.minimum(orig_width, (cx + w/2) * orig_width)\n",
    "            ymax = np.minimum(orig_height, (cy + h/2) * orig_height)\n",
    "            \n",
    "            # Filter degenerate boxes (width or height less than 1)\n",
    "            valid_mask = ((xmax - xmin) >= 1) & ((ymax - ymin) >= 1)\n",
    "            valid_boxes = np.stack([xmin[valid_mask], ymin[valid_mask],\n",
    "                                    xmax[valid_mask], ymax[valid_mask]], axis=1)\n",
    "\n",
    "            # Adjust class IDs (cid from first column)\n",
    "            valid_labels = data[valid_mask, 0].astype(np.uint8) \n",
    "            np.add(valid_labels, 1, out=valid_labels)  # Increment class IDs by 1 for background class\n",
    "\n",
    "            # scale boxes to new image size\n",
    "            scale_factors = np.array([self.img_size / orig_width, self.img_size / orig_height,\n",
    "                                    self.img_size / orig_width, self.img_size / orig_height], dtype=valid_boxes.dtype)\n",
    "            np.multiply(valid_boxes, scale_factors, out=valid_boxes)\n",
    "            \n",
    "            # Validate class IDs\n",
    "            if np.all((valid_labels < 0) & (valid_labels >= self.num_classes)):\n",
    "                raise ValueError(f\"Invalid class ID in {label_path}\")\n",
    "\n",
    "            if self.mode == \"train\":\n",
    "                np.divide(valid_boxes, self.img_size, out=valid_boxes) # Normalize boxes to [0, 1]\n",
    "\n",
    "            return image, {\n",
    "                'boxes': valid_boxes,\n",
    "                'labels': valid_labels}\n",
    "        \n",
    "    def denormalize_bbox(self, boxes: torch.Tensor|np.ndarray) -> torch.Tensor|np.ndarray:\n",
    "        # Denormalize boxes to original size\n",
    "        return boxes * self.img_size\n",
    "    \n",
    "    def normalize_bbox(self, boxes: torch.Tensor|np.ndarray) -> torch.Tensor|np.ndarray:\n",
    "        # Normalize boxes to [0, 1]\n",
    "        return boxes / self.img_size\n",
    "    \n",
    "    def denormalize_image(self, image: torch.Tensor|np.ndarray) -> torch.Tensor|np.ndarray:\n",
    "        # Denormalize image to [0, 255]\n",
    "        return image * 255.0\n",
    "    \n",
    "    def normalize_image(self, image: torch.Tensor|np.ndarray) -> torch.Tensor|np.ndarray:\n",
    "        # Normalize image to [0, 1]\n",
    "        return image / 255.0\n",
    "    \n",
    "# def collate_fn(batch):\n",
    "#     images, targets = [], []\n",
    "#     for img, target in batch:\n",
    "#         images.append(img)\n",
    "#         targets.append(target)\n",
    "#     return  np.stack(images, axis=0), np.stack(targets, axis=0)\n",
    "\n",
    "import torch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate function to process a batch of samples from SSDLITEOBJDET_DATASET.\n",
    "    \n",
    "    Args:\n",
    "        batch: List of tuples containing (image, target_dict)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (images, targets) where:\n",
    "        - images: Tensor of shape (B, C, H, W) with normalized images\n",
    "        - targets: List of dicts with 'boxes' and 'labels' tensors for each image\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    targets = []\n",
    "\n",
    "    # Process each sample in the batch\n",
    "    for img, tgt in batch:\n",
    "        # Convert HWC numpy array to CHW tensor and normalize to [0, 1]\n",
    "        img_tensor = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0\n",
    "        images.append(img_tensor)\n",
    "        \n",
    "        # Convert annotations to tensors\n",
    "        boxes = torch.as_tensor(tgt['boxes'], dtype=torch.float32)\n",
    "        labels = torch.as_tensor(tgt['labels'], dtype=torch.int64)\n",
    "        \n",
    "        targets.append({\n",
    "            'boxes': boxes,\n",
    "            'labels': labels\n",
    "        })\n",
    "    \n",
    "    return tuple(zip(*[images, targets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedSSDLITEOBJDET_DATASET(Dataset):\n",
    "    def __init__(self, dataset_class :SSDLITEOBJDET_DATASET, \n",
    "                root_dir: str, \n",
    "                split: str, \n",
    "                num_classes: int, \n",
    "                img_size: int=320, \n",
    "                dtype: np.dtype=np.float32, \n",
    "                mode: str=\"train\",\n",
    "                lmdb_path: str = None,\n",
    "                map_size: int=1099511627776) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.root_dir, self.split, self.img_size, self.num_classes = root_dir, split.lower(), img_size, num_classes\n",
    "        self.dtype = dtype\n",
    "        self.mode = mode.lower()\n",
    "        self.dataset_class = dataset_class\n",
    "        self.map_size = map_size\n",
    "        self.lmdb_path = lmdb_path if lmdb_path else os.path.join(self.root_dir, f\"{self.split}_cache\")\n",
    "        \n",
    "        # preprocess the dataset and cache it in lmdb\n",
    "        self.preprocess_dataset()\n",
    "        \n",
    "        self.env = lmdb.open(self.lmdb_path, readonly=True, lock=False)\n",
    "        with self.env.begin() as txn:\n",
    "            self.length = txn.stat()['entries']\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        with self.env.begin() as txn:\n",
    "            data = txn.get(str(idx).encode())\n",
    "        return pickle.loads(data)\n",
    "    \n",
    "    \n",
    "    def preprocess_dataset(self) -> None:\n",
    "        dataset = self.dataset_class(root_dir=self.root_dir,\n",
    "                                    split=self.split, \n",
    "                                    num_classes=self.num_classes, \n",
    "                                    img_size=self.img_size, \n",
    "                                    dtype=self.dtype, \n",
    "                                    mode=self.mode)\n",
    "        # Create LMDB environment\n",
    "        env = lmdb.open(self.lmdb_path, map_size=self.map_size)  # 1TB\n",
    "        \n",
    "        with env.begin(write=True) as txn:\n",
    "            for idx in tqdm(range(len(dataset))):\n",
    "                image, target = dataset[idx]\n",
    "                \n",
    "                # Serialize and store\n",
    "                txn.put(\n",
    "                    str(idx).encode(),\n",
    "                    pickle.dumps((image, target), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                )\n",
    "\n",
    "        shutil.rmtree(os.path.join(self.root_dir, self.split))\n",
    "        del dataset\n",
    "    \n",
    "    \n",
    "    def denormalize_bbox(self, boxes: torch.Tensor|np.ndarray) -> torch.Tensor|np.ndarray:\n",
    "        # Denormalize boxes to original size\n",
    "        return boxes * self.img_size\n",
    "    \n",
    "    \n",
    "    def normalize_bbox(self, boxes: torch.Tensor|np.ndarray) -> torch.Tensor|np.ndarray:\n",
    "        # Normalize boxes to [0, 1]\n",
    "        return boxes / self.img_size\n",
    "    \n",
    "    \n",
    "    def denormalize_image(self, image: torch.Tensor|np.ndarray) -> torch.Tensor|np.ndarray:\n",
    "        # Denormalize image to [0, 255]\n",
    "        return image * 255.0\n",
    "    \n",
    "    \n",
    "    def normalize_image(self, image: torch.Tensor|np.ndarray) -> torch.Tensor|np.ndarray:\n",
    "        # Normalize image to [0, 1]\n",
    "        return image / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 9540/18139 [02:11<05:20, 26.86it/s] libpng warning: iCCP: known incorrect sRGB profile\n",
      "100%|██████████| 18139/18139 [03:54<00:00, 77.36it/s] \n"
     ]
    }
   ],
   "source": [
    "train_dataset = CachedSSDLITEOBJDET_DATASET(SSDLITEOBJDET_DATASET,\n",
    "                                        root_dir=DATASET_FOLDER_PATH, \n",
    "                                        split='train', \n",
    "                                        num_classes=MODEL_NUM_CLASSES, \n",
    "                                        img_size=320, \n",
    "                                        dtype=np.float32, \n",
    "                                        mode='train')\n",
    "\n",
    "val_dataset = CachedSSDLITEOBJDET_DATASET(SSDLITEOBJDET_DATASET,\n",
    "                                        root_dir=DATASET_FOLDER_PATH, \n",
    "                                        split='val', \n",
    "                                        num_classes=MODEL_NUM_CLASSES, \n",
    "                                        img_size=320, \n",
    "                                        dtype=np.float32, \n",
    "                                        mode='train')\n",
    "\n",
    "test_dataset = CachedSSDLITEOBJDET_DATASET(SSDLITEOBJDET_DATASET,\n",
    "                                        root_dir=DATASET_FOLDER_PATH, \n",
    "                                        split='test', \n",
    "                                        num_classes=MODEL_NUM_CLASSES, \n",
    "                                        img_size=320, \n",
    "                                        dtype=np.float32, \n",
    "                                        mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, \n",
    "                        batch_size=64, \n",
    "                        shuffle=True, \n",
    "                        collate_fn=collate_fn, \n",
    "                        num_workers=num_cores,\n",
    "                        pin_memory=True,\n",
    "                        persistent_workers=True,\n",
    "                        prefetch_factor=2,\n",
    "                        )\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                        batch_size=64, \n",
    "                        shuffle=True, \n",
    "                        collate_fn=collate_fn, \n",
    "                        num_workers=num_cores,\n",
    "                        pin_memory=True,\n",
    "                        persistent_workers=True,\n",
    "                        prefetch_factor=2,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD_MOBILENET_V3_Large(\n",
       "  (model): SSD(\n",
       "    (backbone): SSDLiteFeatureExtractorMobileNet(\n",
       "      (features): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "                (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "                (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "                (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "                (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (5): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "                (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (6): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "                (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (7): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "                (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (8): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "                (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (9): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "                (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (10): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "                (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (11): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (12): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "                (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (13): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Sequential(\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): ReLU()\n",
       "              (scale_activation): Hardsigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (extra): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2, 3], [2, 3], [2, 3], [2, 3], [2, 3], [2, 3]], clip=True, scales=[0.2, 0.35, 0.5, 0.65, 0.8, 0.95, 1.0], steps=None)\n",
       "    (head): SSDLiteHead(\n",
       "      (classification_head): SSDLiteClassificationHead(\n",
       "        (module_list): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(672, 66, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(480, 66, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(512, 66, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3-4): 2 x Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(256, 66, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(128, 66, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (regression_head): SSDLiteRegressionHead(\n",
       "        (module_list): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(672, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(480, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3-4): 2 x Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(128, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (transform): GeneralizedRCNNTransform(\n",
       "        Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
       "        Resize(min_size=(320,), max_size=320, mode='bilinear')\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SSD_MOBILENET_V3_Large(num_classes_with_bg=MODEL_NUM_CLASSES)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[[0.2980, 0.2706, 0.1412,  ..., 0.2078, 0.2235, 0.2314],\n",
       "           [0.3608, 0.3529, 0.4353,  ..., 0.3569, 0.2275, 0.2078],\n",
       "           [0.3216, 0.2471, 0.3451,  ..., 0.2118, 0.1686, 0.1569],\n",
       "           ...,\n",
       "           [0.6549, 0.5451, 0.6353,  ..., 0.4275, 0.3412, 0.2549],\n",
       "           [0.6510, 0.6824, 0.6863,  ..., 0.5451, 0.4392, 0.4549],\n",
       "           [0.5647, 0.7843, 0.5647,  ..., 0.4745, 0.4471, 0.4510]],\n",
       "  \n",
       "          [[0.2431, 0.3451, 0.1647,  ..., 0.1569, 0.1686, 0.1882],\n",
       "           [0.3020, 0.3333, 0.4353,  ..., 0.3020, 0.1765, 0.3098],\n",
       "           [0.3333, 0.2588, 0.2157,  ..., 0.2275, 0.2392, 0.0784],\n",
       "           ...,\n",
       "           [0.5569, 0.4588, 0.5490,  ..., 0.3020, 0.2980, 0.1765],\n",
       "           [0.5294, 0.4980, 0.5686,  ..., 0.4196, 0.4039, 0.3804],\n",
       "           [0.5098, 0.7098, 0.5255,  ..., 0.3725, 0.3176, 0.3608]],\n",
       "  \n",
       "          [[0.1294, 0.1765, 0.1216,  ..., 0.1333, 0.1294, 0.1725],\n",
       "           [0.2510, 0.2941, 0.3412,  ..., 0.2667, 0.1490, 0.2667],\n",
       "           [0.3020, 0.2902, 0.1647,  ..., 0.1412, 0.1686, 0.1333],\n",
       "           ...,\n",
       "           [0.6157, 0.4196, 0.5373,  ..., 0.2314, 0.3725, 0.1451],\n",
       "           [0.5098, 0.5294, 0.5137,  ..., 0.3804, 0.3451, 0.3373],\n",
       "           [0.4392, 0.6078, 0.4471,  ..., 0.2863, 0.2824, 0.2627]]]),\n",
       "  {'boxes': tensor([[0.0761, 0.0000, 1.0000, 1.0000]]),\n",
       "   'labels': tensor([2])}],\n",
       " [tensor([[[0.4196, 0.4078, 0.3647,  ..., 0.2235, 0.2314, 0.2588],\n",
       "           [0.4078, 0.3961, 0.3608,  ..., 0.2314, 0.2353, 0.2510],\n",
       "           [0.3961, 0.3843, 0.3686,  ..., 0.2353, 0.2392, 0.2392],\n",
       "           ...,\n",
       "           [0.5647, 0.5647, 0.5647,  ..., 0.6392, 0.6392, 0.6392],\n",
       "           [0.5725, 0.5725, 0.5725,  ..., 0.6392, 0.6392, 0.6392],\n",
       "           [0.5765, 0.5765, 0.5765,  ..., 0.6392, 0.6392, 0.6392]],\n",
       "  \n",
       "          [[0.4431, 0.4314, 0.3882,  ..., 0.2941, 0.3020, 0.3294],\n",
       "           [0.4314, 0.4196, 0.3843,  ..., 0.3020, 0.3059, 0.3216],\n",
       "           [0.4196, 0.4078, 0.3922,  ..., 0.3059, 0.3098, 0.3098],\n",
       "           ...,\n",
       "           [0.6157, 0.6157, 0.6157,  ..., 0.6627, 0.6627, 0.6627],\n",
       "           [0.6235, 0.6235, 0.6235,  ..., 0.6627, 0.6627, 0.6627],\n",
       "           [0.6275, 0.6275, 0.6275,  ..., 0.6627, 0.6627, 0.6627]],\n",
       "  \n",
       "          [[0.4353, 0.4235, 0.3804,  ..., 0.3020, 0.3020, 0.3294],\n",
       "           [0.4235, 0.4118, 0.3765,  ..., 0.3098, 0.3059, 0.3216],\n",
       "           [0.4118, 0.4000, 0.3843,  ..., 0.3137, 0.3059, 0.3098],\n",
       "           ...,\n",
       "           [0.6510, 0.6510, 0.6510,  ..., 0.7098, 0.7098, 0.7098],\n",
       "           [0.6588, 0.6588, 0.6588,  ..., 0.7098, 0.7098, 0.7098],\n",
       "           [0.6627, 0.6627, 0.6627,  ..., 0.7098, 0.7098, 0.7098]]]),\n",
       "  {'boxes': tensor([[0.0594, 0.0000, 0.7422, 0.9167]]),\n",
       "   'labels': tensor([1])}],\n",
       " [tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       "  {'boxes': tensor([[0.4683, 0.3895, 0.6905, 0.6814]]),\n",
       "   'labels': tensor([6])}],\n",
       " [tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.4824, 0.4941, 0.4784],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.4745, 0.4784, 0.4667],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.4667, 0.4549, 0.4431],\n",
       "           ...,\n",
       "           [0.8039, 0.7843, 0.7647,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.8078, 0.7882, 0.7686,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.8078, 0.7961, 0.7725,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.3608, 0.3765, 0.3647],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.3490, 0.3569, 0.3490],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.3333, 0.3255, 0.3176],\n",
       "           ...,\n",
       "           [0.7765, 0.7569, 0.7333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.7647, 0.7490, 0.7216,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.7608, 0.7451, 0.7216,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.2824, 0.3020, 0.2980],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.2745, 0.2824, 0.2784],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.2588, 0.2549, 0.2510],\n",
       "           ...,\n",
       "           [0.7137, 0.6941, 0.6627,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.7098, 0.6863, 0.6588,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.7059, 0.6863, 0.6588,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
       "  {'boxes': tensor([[0.1446, 0.0119, 0.7452, 0.7391]]),\n",
       "   'labels': tensor([8])}],\n",
       " [tensor([[[0.1255, 0.1255, 0.1255,  ..., 0.1294, 0.1294, 0.1255],\n",
       "           [0.1255, 0.1255, 0.1255,  ..., 0.1294, 0.1294, 0.1255],\n",
       "           [0.1255, 0.1255, 0.1255,  ..., 0.1294, 0.1294, 0.1294],\n",
       "           ...,\n",
       "           [0.7843, 0.7843, 0.7686,  ..., 0.1529, 0.1529, 0.1569],\n",
       "           [0.7765, 0.7725, 0.7569,  ..., 0.1529, 0.1569, 0.1608],\n",
       "           [0.7725, 0.7686, 0.7490,  ..., 0.1569, 0.1608, 0.1608]],\n",
       "  \n",
       "          [[0.1412, 0.1412, 0.1412,  ..., 0.1373, 0.1373, 0.1333],\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.1373, 0.1373, 0.1333],\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.1373, 0.1373, 0.1373],\n",
       "           ...,\n",
       "           [0.7608, 0.7608, 0.7451,  ..., 0.1569, 0.1569, 0.1608],\n",
       "           [0.7529, 0.7490, 0.7333,  ..., 0.1569, 0.1608, 0.1647],\n",
       "           [0.7490, 0.7451, 0.7255,  ..., 0.1608, 0.1647, 0.1647]],\n",
       "  \n",
       "          [[0.1373, 0.1373, 0.1373,  ..., 0.0863, 0.0863, 0.0824],\n",
       "           [0.1373, 0.1373, 0.1373,  ..., 0.0863, 0.0863, 0.0824],\n",
       "           [0.1373, 0.1373, 0.1373,  ..., 0.0863, 0.0863, 0.0863],\n",
       "           ...,\n",
       "           [0.7608, 0.7608, 0.7451,  ..., 0.1255, 0.1255, 0.1294],\n",
       "           [0.7529, 0.7490, 0.7333,  ..., 0.1255, 0.1294, 0.1333],\n",
       "           [0.7490, 0.7451, 0.7255,  ..., 0.1294, 0.1333, 0.1333]]]),\n",
       "  {'boxes': tensor([[0., 0., 1., 1.]]), 'labels': tensor([5])}],\n",
       " [tensor([[[0.7137, 0.6667, 0.5961,  ..., 0.2824, 0.3608, 0.3020],\n",
       "           [0.7294, 0.6706, 0.5647,  ..., 0.3216, 0.3490, 0.3059],\n",
       "           [0.7490, 0.6745, 0.5529,  ..., 0.3529, 0.3765, 0.3373],\n",
       "           ...,\n",
       "           [0.4902, 0.2275, 0.3373,  ..., 0.4392, 0.5176, 0.5451],\n",
       "           [0.2000, 0.4157, 0.3529,  ..., 0.4275, 0.4980, 0.5294],\n",
       "           [0.4941, 0.4314, 0.3569,  ..., 0.4118, 0.4627, 0.5216]],\n",
       "  \n",
       "          [[0.8510, 0.8392, 0.7804,  ..., 0.8431, 0.8588, 0.8510],\n",
       "           [0.8627, 0.8392, 0.7647,  ..., 0.8745, 0.8431, 0.8549],\n",
       "           [0.8745, 0.8392, 0.7725,  ..., 0.8902, 0.8667, 0.9020],\n",
       "           ...,\n",
       "           [0.4431, 0.1647, 0.2745,  ..., 0.9412, 1.0000, 0.9922],\n",
       "           [0.2157, 0.4078, 0.3255,  ..., 0.9294, 0.9882, 0.9922],\n",
       "           [0.5608, 0.4627, 0.3529,  ..., 0.9176, 0.9647, 0.9843]],\n",
       "  \n",
       "          [[0.7294, 0.6235, 0.5020,  ..., 0.9725, 0.9961, 0.9882],\n",
       "           [0.7569, 0.6510, 0.4667,  ..., 0.9922, 0.9725, 0.9843],\n",
       "           [0.7882, 0.6863, 0.4510,  ..., 1.0000, 0.9922, 1.0000],\n",
       "           ...,\n",
       "           [0.2745, 0.0157, 0.1137,  ..., 0.9725, 1.0000, 1.0000],\n",
       "           [0.0000, 0.1686, 0.1294,  ..., 0.9765, 1.0000, 1.0000],\n",
       "           [0.2118, 0.1725, 0.1490,  ..., 0.9843, 0.9804, 1.0000]]]),\n",
       "  {'boxes': tensor([[0.0522, 0.1313, 0.9277, 0.8353]]),\n",
       "   'labels': tensor([9])}],\n",
       " [tensor([[[0.4000, 0.4118, 0.4627,  ..., 0.5333, 0.6549, 0.7098],\n",
       "           [0.3961, 0.3882, 0.4039,  ..., 0.6039, 0.5216, 0.6588],\n",
       "           [0.4196, 0.3569, 0.3882,  ..., 0.5843, 0.5333, 0.6039],\n",
       "           ...,\n",
       "           [0.5922, 0.6118, 0.6275,  ..., 0.6275, 0.6549, 0.6314],\n",
       "           [0.5765, 0.5804, 0.5608,  ..., 0.5608, 0.5412, 0.5098],\n",
       "           [0.6471, 0.5647, 0.5412,  ..., 0.6157, 0.6235, 0.5804]],\n",
       "  \n",
       "          [[0.2902, 0.3020, 0.3490,  ..., 0.4353, 0.5529, 0.6078],\n",
       "           [0.3059, 0.2980, 0.3137,  ..., 0.4980, 0.4275, 0.5608],\n",
       "           [0.3490, 0.2863, 0.3294,  ..., 0.4824, 0.4314, 0.5020],\n",
       "           ...,\n",
       "           [0.4824, 0.5059, 0.5255,  ..., 0.6078, 0.6392, 0.6196],\n",
       "           [0.4863, 0.5020, 0.4902,  ..., 0.5255, 0.5020, 0.4667],\n",
       "           [0.5725, 0.4902, 0.4745,  ..., 0.5686, 0.5686, 0.5216]],\n",
       "  \n",
       "          [[0.2549, 0.2549, 0.2941,  ..., 0.2824, 0.4157, 0.4667],\n",
       "           [0.2510, 0.2431, 0.2471,  ..., 0.3765, 0.2980, 0.4471],\n",
       "           [0.2706, 0.2118, 0.2510,  ..., 0.3922, 0.3529, 0.4196],\n",
       "           ...,\n",
       "           [0.4549, 0.4784, 0.4980,  ..., 0.5882, 0.6392, 0.6392],\n",
       "           [0.4627, 0.4784, 0.4627,  ..., 0.4980, 0.5098, 0.4941],\n",
       "           [0.5451, 0.4627, 0.4431,  ..., 0.5451, 0.5765, 0.5569]]]),\n",
       "  {'boxes': tensor([[0.4281, 0.2578, 0.7516, 0.8922],\n",
       "           [0.0781, 0.3750, 0.3734, 0.9984],\n",
       "           [0.0891, 0.1453, 0.3969, 0.5234],\n",
       "           [0.6484, 0.1047, 0.9641, 0.6812]]),\n",
       "   'labels': tensor([3, 3, 3, 3])}],\n",
       " [tensor([[[0.3686, 0.4353, 0.5255,  ..., 0.3098, 0.3294, 0.3765],\n",
       "           [0.3569, 0.4627, 0.6392,  ..., 0.2863, 0.2824, 0.3255],\n",
       "           [0.4157, 0.5451, 0.5294,  ..., 0.2667, 0.2627, 0.2980],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "          [[0.3843, 0.4510, 0.5333,  ..., 0.3059, 0.3255, 0.3725],\n",
       "           [0.3686, 0.4745, 0.6471,  ..., 0.2824, 0.2784, 0.3216],\n",
       "           [0.4235, 0.5569, 0.5412,  ..., 0.2627, 0.2588, 0.2941],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "          [[0.3804, 0.4431, 0.5216,  ..., 0.2235, 0.2431, 0.2902],\n",
       "           [0.3647, 0.4667, 0.6353,  ..., 0.2000, 0.1961, 0.2392],\n",
       "           [0.4157, 0.5490, 0.5333,  ..., 0.1804, 0.1765, 0.2118],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
       "  {'boxes': tensor([[0.3455, 0.0939, 0.8955, 0.5990]]),\n",
       "   'labels': tensor([8])}],\n",
       " [tensor([[[0.1216, 0.1059, 0.0941,  ..., 0.7216, 0.7020, 0.7216],\n",
       "           [0.1137, 0.1137, 0.1020,  ..., 0.7216, 0.7020, 0.7216],\n",
       "           [0.1059, 0.1137, 0.1137,  ..., 0.7216, 0.7020, 0.7216],\n",
       "           ...,\n",
       "           [0.1765, 0.1725, 0.1529,  ..., 0.5294, 0.5529, 0.5647],\n",
       "           [0.1294, 0.1255, 0.1216,  ..., 0.4706, 0.5412, 0.5843],\n",
       "           [0.1804, 0.1804, 0.1843,  ..., 0.4980, 0.5490, 0.6039]],\n",
       "  \n",
       "          [[0.1255, 0.1098, 0.0980,  ..., 0.6627, 0.6471, 0.6667],\n",
       "           [0.1176, 0.1176, 0.1059,  ..., 0.6627, 0.6471, 0.6667],\n",
       "           [0.1098, 0.1176, 0.1176,  ..., 0.6627, 0.6471, 0.6667],\n",
       "           ...,\n",
       "           [0.1843, 0.1804, 0.1608,  ..., 0.4706, 0.4902, 0.5020],\n",
       "           [0.1373, 0.1333, 0.1294,  ..., 0.4157, 0.4745, 0.5176],\n",
       "           [0.1882, 0.1882, 0.1922,  ..., 0.4431, 0.4824, 0.5373]],\n",
       "  \n",
       "          [[0.1059, 0.0902, 0.0784,  ..., 0.5608, 0.5451, 0.5647],\n",
       "           [0.0980, 0.0980, 0.0863,  ..., 0.5608, 0.5451, 0.5647],\n",
       "           [0.0902, 0.0980, 0.0980,  ..., 0.5647, 0.5451, 0.5647],\n",
       "           ...,\n",
       "           [0.1333, 0.1373, 0.1216,  ..., 0.3765, 0.4039, 0.4196],\n",
       "           [0.0941, 0.0902, 0.0902,  ..., 0.3216, 0.4000, 0.4392],\n",
       "           [0.1451, 0.1451, 0.1529,  ..., 0.3490, 0.4039, 0.4588]]]),\n",
       "  {'boxes': tensor([[0.0980, 0.0322, 0.9980, 0.9975]]),\n",
       "   'labels': tensor([1])}],\n",
       " [tensor([[[0.6275, 0.6235, 0.6235,  ..., 0.6549, 0.6510, 0.6510],\n",
       "           [0.6275, 0.6275, 0.6235,  ..., 0.6627, 0.6588, 0.6549],\n",
       "           [0.6314, 0.6314, 0.6275,  ..., 0.6706, 0.6667, 0.6667],\n",
       "           ...,\n",
       "           [0.2549, 0.2392, 0.2745,  ..., 0.2902, 0.2667, 0.2824],\n",
       "           [0.3059, 0.3725, 0.4314,  ..., 0.2353, 0.1922, 0.1608],\n",
       "           [0.4431, 0.3608, 0.2863,  ..., 0.1765, 0.1412, 0.1373]],\n",
       "  \n",
       "          [[0.6118, 0.6078, 0.6078,  ..., 0.6275, 0.6235, 0.6235],\n",
       "           [0.6118, 0.6118, 0.6078,  ..., 0.6353, 0.6314, 0.6275],\n",
       "           [0.6157, 0.6157, 0.6118,  ..., 0.6431, 0.6392, 0.6392],\n",
       "           ...,\n",
       "           [0.2510, 0.2353, 0.2706,  ..., 0.2980, 0.2745, 0.2902],\n",
       "           [0.3020, 0.3686, 0.4275,  ..., 0.2275, 0.1843, 0.1569],\n",
       "           [0.4392, 0.3569, 0.2824,  ..., 0.1725, 0.1333, 0.1294]],\n",
       "  \n",
       "          [[0.5647, 0.5608, 0.5608,  ..., 0.5529, 0.5490, 0.5451],\n",
       "           [0.5647, 0.5647, 0.5608,  ..., 0.5647, 0.5608, 0.5569],\n",
       "           [0.5686, 0.5686, 0.5647,  ..., 0.5725, 0.5686, 0.5686],\n",
       "           ...,\n",
       "           [0.2745, 0.2588, 0.2941,  ..., 0.4471, 0.4275, 0.4431],\n",
       "           [0.3255, 0.3922, 0.4510,  ..., 0.3922, 0.3529, 0.3255],\n",
       "           [0.4627, 0.3804, 0.3059,  ..., 0.3451, 0.3176, 0.3137]]]),\n",
       "  {'boxes': tensor([[0.5391, 0.2797, 0.7781, 0.7234],\n",
       "           [0.2094, 0.9328, 0.3641, 1.0000]]),\n",
       "   'labels': tensor([3, 3])}],\n",
       " [tensor([[[0.6353, 0.6078, 0.6157,  ..., 0.6941, 0.6980, 0.6980],\n",
       "           [0.6157, 0.5961, 0.6000,  ..., 0.7176, 0.7059, 0.7098],\n",
       "           [0.6157, 0.6314, 0.6157,  ..., 0.7098, 0.7020, 0.7255],\n",
       "           ...,\n",
       "           [0.4941, 0.5059, 0.4863,  ..., 0.1961, 0.1922, 0.1843],\n",
       "           [0.4784, 0.4745, 0.4863,  ..., 0.2039, 0.1804, 0.1922],\n",
       "           [0.4667, 0.4549, 0.4706,  ..., 0.2000, 0.2000, 0.1961]],\n",
       "  \n",
       "          [[0.6510, 0.6353, 0.6431,  ..., 0.7490, 0.7529, 0.7529],\n",
       "           [0.6314, 0.6235, 0.6275,  ..., 0.7725, 0.7608, 0.7647],\n",
       "           [0.6431, 0.6431, 0.6471,  ..., 0.7647, 0.7569, 0.7804],\n",
       "           ...,\n",
       "           [0.6275, 0.6235, 0.6039,  ..., 0.1216, 0.1216, 0.1059],\n",
       "           [0.6235, 0.5922, 0.6039,  ..., 0.1294, 0.1059, 0.1176],\n",
       "           [0.6118, 0.5843, 0.6000,  ..., 0.1255, 0.1255, 0.1216]],\n",
       "  \n",
       "          [[0.6941, 0.6745, 0.6824,  ..., 0.7922, 0.7961, 0.7961],\n",
       "           [0.6745, 0.6627, 0.6667,  ..., 0.8157, 0.8039, 0.8078],\n",
       "           [0.6824, 0.6863, 0.6824,  ..., 0.8078, 0.8000, 0.8235],\n",
       "           ...,\n",
       "           [0.6667, 0.6667, 0.6471,  ..., 0.0941, 0.0902, 0.0706],\n",
       "           [0.6588, 0.6353, 0.6471,  ..., 0.1020, 0.0784, 0.0902],\n",
       "           [0.6471, 0.6235, 0.6431,  ..., 0.0980, 0.0980, 0.0941]]]),\n",
       "  {'boxes': tensor([[0.0355, 0.0868, 0.6157, 0.7168]]),\n",
       "   'labels': tensor([10])}],\n",
       " [tensor([[[0.2353, 0.3137, 0.2902,  ..., 0.6118, 0.4157, 0.5020],\n",
       "           [0.2784, 0.2902, 0.3333,  ..., 0.5255, 0.7137, 0.6157],\n",
       "           [0.2902, 0.3451, 0.3059,  ..., 0.6000, 0.7137, 0.7686],\n",
       "           ...,\n",
       "           [0.5373, 0.7569, 0.4392,  ..., 0.7529, 0.5569, 0.7765],\n",
       "           [0.4902, 0.7412, 0.4353,  ..., 0.8588, 0.6588, 0.6941],\n",
       "           [0.3647, 0.4667, 0.3647,  ..., 0.5176, 0.4510, 0.5333]],\n",
       "  \n",
       "          [[0.2078, 0.2745, 0.2471,  ..., 0.4392, 0.2431, 0.3255],\n",
       "           [0.2510, 0.2549, 0.2902,  ..., 0.3255, 0.5098, 0.4078],\n",
       "           [0.2627, 0.3098, 0.2667,  ..., 0.3843, 0.4902, 0.5451],\n",
       "           ...,\n",
       "           [0.5059, 0.6824, 0.3255,  ..., 0.5804, 0.3843, 0.5961],\n",
       "           [0.4431, 0.6627, 0.3216,  ..., 0.6980, 0.5020, 0.5333],\n",
       "           [0.3098, 0.3765, 0.2471,  ..., 0.3804, 0.3137, 0.3922]],\n",
       "  \n",
       "          [[0.1451, 0.2078, 0.1843,  ..., 0.3686, 0.1804, 0.2745],\n",
       "           [0.1882, 0.1882, 0.2275,  ..., 0.2549, 0.4549, 0.3608],\n",
       "           [0.1922, 0.2431, 0.2000,  ..., 0.3098, 0.4275, 0.4902],\n",
       "           ...,\n",
       "           [0.4275, 0.5608, 0.2353,  ..., 0.4863, 0.3059, 0.5333],\n",
       "           [0.3725, 0.5412, 0.2275,  ..., 0.5804, 0.4000, 0.4667],\n",
       "           [0.2431, 0.2745, 0.1647,  ..., 0.2471, 0.2039, 0.3176]]]),\n",
       "  {'boxes': tensor([[0.4722, 0.3734, 0.5894, 0.5578]]),\n",
       "   'labels': tensor([4])}],\n",
       " [tensor([[[0.3725, 0.3686, 0.3608,  ..., 0.6039, 0.5098, 0.4471],\n",
       "           [0.3608, 0.3647, 0.3608,  ..., 0.6588, 0.5922, 0.4863],\n",
       "           [0.3569, 0.3608, 0.3647,  ..., 0.6784, 0.6431, 0.5647],\n",
       "           ...,\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 0.4039, 0.4353, 0.3804],\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 0.4039, 0.4588, 0.4235],\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 0.3686, 0.4235, 0.4118]],\n",
       "  \n",
       "          [[0.3725, 0.3686, 0.3608,  ..., 0.6039, 0.5098, 0.4471],\n",
       "           [0.3608, 0.3647, 0.3608,  ..., 0.6588, 0.5922, 0.4863],\n",
       "           [0.3569, 0.3608, 0.3647,  ..., 0.6784, 0.6431, 0.5647],\n",
       "           ...,\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 0.4039, 0.4353, 0.3804],\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 0.4039, 0.4588, 0.4235],\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 0.3686, 0.4235, 0.4118]],\n",
       "  \n",
       "          [[0.3725, 0.3686, 0.3608,  ..., 0.6039, 0.5098, 0.4471],\n",
       "           [0.3608, 0.3647, 0.3608,  ..., 0.6588, 0.5922, 0.4863],\n",
       "           [0.3569, 0.3608, 0.3647,  ..., 0.6784, 0.6431, 0.5647],\n",
       "           ...,\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 0.4039, 0.4353, 0.3804],\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 0.4039, 0.4588, 0.4235],\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 0.3686, 0.4235, 0.4118]]]),\n",
       "  {'boxes': tensor([[0.0000, 0.1705, 0.5787, 0.9871]]),\n",
       "   'labels': tensor([8])}],\n",
       " [tensor([[[0.2353, 0.2824, 0.2588,  ..., 0.2157, 0.1647, 0.1843],\n",
       "           [0.3059, 0.2863, 0.2745,  ..., 0.2353, 0.2353, 0.2157],\n",
       "           [0.2941, 0.2235, 0.2353,  ..., 0.2275, 0.2863, 0.1882],\n",
       "           ...,\n",
       "           [0.5176, 0.4941, 0.5686,  ..., 0.5176, 0.6078, 0.7333],\n",
       "           [0.7294, 0.5843, 0.2196,  ..., 0.5294, 0.5608, 0.4275],\n",
       "           [0.4510, 0.7216, 0.4235,  ..., 0.4745, 0.6549, 0.6118]],\n",
       "  \n",
       "          [[0.2667, 0.3059, 0.2745,  ..., 0.2549, 0.2118, 0.2353],\n",
       "           [0.3373, 0.3137, 0.2980,  ..., 0.2706, 0.2784, 0.2549],\n",
       "           [0.3137, 0.2471, 0.2667,  ..., 0.2588, 0.3176, 0.2157],\n",
       "           ...,\n",
       "           [0.5333, 0.4863, 0.5765,  ..., 0.5333, 0.5882, 0.7412],\n",
       "           [0.7098, 0.5608, 0.2314,  ..., 0.5765, 0.5725, 0.4667],\n",
       "           [0.4627, 0.6039, 0.3176,  ..., 0.4941, 0.6275, 0.6078]],\n",
       "  \n",
       "          [[0.1843, 0.2392, 0.2196,  ..., 0.2157, 0.1647, 0.1922],\n",
       "           [0.2471, 0.2314, 0.2157,  ..., 0.2000, 0.2118, 0.1961],\n",
       "           [0.2275, 0.1647, 0.1765,  ..., 0.1686, 0.2431, 0.1569],\n",
       "           ...,\n",
       "           [0.3020, 0.3255, 0.4431,  ..., 0.2275, 0.2745, 0.3412],\n",
       "           [0.5255, 0.4118, 0.0667,  ..., 0.2235, 0.2549, 0.0627],\n",
       "           [0.2235, 0.4353, 0.1686,  ..., 0.0863, 0.3176, 0.2980]]]),\n",
       "  {'boxes': tensor([[0.0708, 0.3363, 0.3908, 0.7575],\n",
       "           [0.4342, 0.4625, 0.8808, 0.8225]]),\n",
       "   'labels': tensor([2, 2])}],\n",
       " [tensor([[[0.1294, 0.3725, 0.4157,  ..., 0.2078, 0.2000, 0.1882],\n",
       "           [0.1922, 0.4118, 0.4157,  ..., 0.2118, 0.2039, 0.1765],\n",
       "           [0.3216, 0.3882, 0.4157,  ..., 0.2235, 0.2039, 0.1804],\n",
       "           ...,\n",
       "           [0.1804, 0.2196, 0.2431,  ..., 0.2275, 0.2157, 0.2078],\n",
       "           [0.2314, 0.2471, 0.2588,  ..., 0.2196, 0.2118, 0.2157],\n",
       "           [0.2039, 0.2471, 0.2431,  ..., 0.2196, 0.2118, 0.2118]],\n",
       "  \n",
       "          [[0.1412, 0.3373, 0.4078,  ..., 0.2157, 0.2078, 0.1922],\n",
       "           [0.1882, 0.3882, 0.4157,  ..., 0.2235, 0.2157, 0.1882],\n",
       "           [0.2980, 0.3804, 0.4157,  ..., 0.2314, 0.2078, 0.2000],\n",
       "           ...,\n",
       "           [0.2000, 0.2588, 0.2941,  ..., 0.2275, 0.2118, 0.2196],\n",
       "           [0.2471, 0.2824, 0.2902,  ..., 0.2196, 0.2118, 0.2078],\n",
       "           [0.2353, 0.2784, 0.2824,  ..., 0.2275, 0.2196, 0.2039]],\n",
       "  \n",
       "          [[0.1020, 0.2824, 0.3922,  ..., 0.1451, 0.1529, 0.1608],\n",
       "           [0.1137, 0.3176, 0.3765,  ..., 0.1373, 0.1529, 0.1451],\n",
       "           [0.2196, 0.3451, 0.4000,  ..., 0.1490, 0.1490, 0.1529],\n",
       "           ...,\n",
       "           [0.1569, 0.1843, 0.2039,  ..., 0.1961, 0.1804, 0.1843],\n",
       "           [0.1804, 0.1843, 0.1922,  ..., 0.1882, 0.1843, 0.1804],\n",
       "           [0.1529, 0.1843, 0.1804,  ..., 0.1843, 0.1765, 0.1686]]]),\n",
       "  {'boxes': tensor([[0.0548, 0.0464, 0.9168, 0.9119]]),\n",
       "   'labels': tensor([10])}],\n",
       " [tensor([[[0.2392, 0.1412, 0.2784,  ..., 0.3059, 0.2431, 0.2353],\n",
       "           [0.2902, 0.2941, 0.0510,  ..., 0.2510, 0.2353, 0.3020],\n",
       "           [0.2471, 0.1098, 0.3137,  ..., 0.1765, 0.1804, 0.0980],\n",
       "           ...,\n",
       "           [0.3804, 0.4314, 0.5294,  ..., 0.6431, 0.7059, 0.8196],\n",
       "           [0.3569, 0.3961, 0.4196,  ..., 0.8275, 0.7529, 0.9294],\n",
       "           [0.3882, 0.3294, 0.5098,  ..., 0.7412, 0.9059, 0.9059]],\n",
       "  \n",
       "          [[0.2549, 0.2745, 0.3216,  ..., 0.2471, 0.1843, 0.2039],\n",
       "           [0.3569, 0.3137, 0.0667,  ..., 0.2157, 0.3137, 0.3490],\n",
       "           [0.3765, 0.2588, 0.3882,  ..., 0.1490, 0.2706, 0.1412],\n",
       "           ...,\n",
       "           [0.4275, 0.5725, 0.5725,  ..., 0.3804, 0.4627, 0.4706],\n",
       "           [0.4118, 0.5647, 0.5686,  ..., 0.5804, 0.4549, 0.5804],\n",
       "           [0.4784, 0.5412, 0.5569,  ..., 0.5647, 0.6784, 0.7333]],\n",
       "  \n",
       "          [[0.2745, 0.3176, 0.3373,  ..., 0.2902, 0.2235, 0.2588],\n",
       "           [0.2941, 0.2275, 0.0902,  ..., 0.2824, 0.3451, 0.2706],\n",
       "           [0.1294, 0.1882, 0.4314,  ..., 0.2510, 0.2863, 0.1725],\n",
       "           ...,\n",
       "           [0.2588, 0.2667, 0.3333,  ..., 0.3333, 0.4118, 0.4588],\n",
       "           [0.1843, 0.1647, 0.3412,  ..., 0.4392, 0.4706, 0.4824],\n",
       "           [0.1882, 0.2157, 0.3412,  ..., 0.5333, 0.5765, 0.5098]]]),\n",
       "  {'boxes': tensor([[0.0649, 0.1179, 1.0000, 1.0000]]),\n",
       "   'labels': tensor([9])}],\n",
       " [tensor([[[0.1333, 0.1137, 0.2039,  ..., 0.7098, 0.3961, 0.3725],\n",
       "           [0.1216, 0.1490, 0.2549,  ..., 0.8275, 0.6235, 0.4157],\n",
       "           [0.1294, 0.1569, 0.2588,  ..., 0.8471, 0.5451, 0.5882],\n",
       "           ...,\n",
       "           [0.3804, 0.3137, 0.4039,  ..., 0.5333, 0.4549, 0.7255],\n",
       "           [0.4588, 0.4431, 0.4196,  ..., 0.6588, 0.5765, 0.7216],\n",
       "           [0.4549, 0.4314, 0.4549,  ..., 0.3216, 0.2863, 0.6235]],\n",
       "  \n",
       "          [[0.0745, 0.0588, 0.1490,  ..., 0.7529, 0.4471, 0.4196],\n",
       "           [0.0627, 0.0941, 0.1961,  ..., 0.8667, 0.6745, 0.4627],\n",
       "           [0.0706, 0.0980, 0.1961,  ..., 0.8824, 0.5882, 0.6353],\n",
       "           ...,\n",
       "           [0.2510, 0.1725, 0.2627,  ..., 0.4824, 0.4039, 0.6824],\n",
       "           [0.3176, 0.2941, 0.2667,  ..., 0.6196, 0.5373, 0.6980],\n",
       "           [0.3059, 0.2824, 0.2980,  ..., 0.2863, 0.2510, 0.6039]],\n",
       "  \n",
       "          [[0.0863, 0.0196, 0.0667,  ..., 0.3647, 0.1216, 0.1647],\n",
       "           [0.0745, 0.0549, 0.1216,  ..., 0.4588, 0.3137, 0.1569],\n",
       "           [0.0745, 0.0627, 0.1333,  ..., 0.4627, 0.1922, 0.2706],\n",
       "           ...,\n",
       "           [0.2118, 0.1373, 0.2235,  ..., 0.2314, 0.1608, 0.3412],\n",
       "           [0.2706, 0.2510, 0.2314,  ..., 0.3725, 0.3059, 0.3686],\n",
       "           [0.2549, 0.2392, 0.2627,  ..., 0.0510, 0.0510, 0.2902]]]),\n",
       "  {'boxes': tensor([[0.2583, 0.0658, 0.9028, 0.9616]]),\n",
       "   'labels': tensor([4])}],\n",
       " [tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       "  {'boxes': tensor([[0.5102, 0.1876, 0.9084, 0.8758]]),\n",
       "   'labels': tensor([7])}],\n",
       " [tensor([[[0.4431, 0.4431, 0.4431,  ..., 0.4157, 0.4157, 0.4118],\n",
       "           [0.4431, 0.4431, 0.4431,  ..., 0.4157, 0.4157, 0.4118],\n",
       "           [0.4431, 0.4431, 0.4431,  ..., 0.4196, 0.4196, 0.4157],\n",
       "           ...,\n",
       "           [0.4745, 0.4941, 0.4000,  ..., 0.4980, 0.4510, 0.4706],\n",
       "           [0.4706, 0.4902, 0.4510,  ..., 0.4941, 0.4471, 0.4392],\n",
       "           [0.4627, 0.4980, 0.4627,  ..., 0.4902, 0.4431, 0.4431]],\n",
       "  \n",
       "          [[0.4941, 0.4941, 0.4941,  ..., 0.4471, 0.4392, 0.4353],\n",
       "           [0.4941, 0.4941, 0.4941,  ..., 0.4471, 0.4392, 0.4353],\n",
       "           [0.4941, 0.4941, 0.4941,  ..., 0.4510, 0.4431, 0.4392],\n",
       "           ...,\n",
       "           [0.5255, 0.5373, 0.4275,  ..., 0.5569, 0.5216, 0.5412],\n",
       "           [0.5294, 0.5412, 0.4784,  ..., 0.5608, 0.5294, 0.5255],\n",
       "           [0.5216, 0.5490, 0.4941,  ..., 0.5608, 0.5333, 0.5294]],\n",
       "  \n",
       "          [[0.3255, 0.3255, 0.3255,  ..., 0.3020, 0.2941, 0.2863],\n",
       "           [0.3255, 0.3255, 0.3255,  ..., 0.3020, 0.2941, 0.2863],\n",
       "           [0.3255, 0.3255, 0.3255,  ..., 0.3059, 0.2980, 0.2902],\n",
       "           ...,\n",
       "           [0.3059, 0.3490, 0.2667,  ..., 0.4078, 0.3647, 0.3843],\n",
       "           [0.3098, 0.3451, 0.3020,  ..., 0.3961, 0.3608, 0.3529],\n",
       "           [0.2980, 0.3451, 0.3176,  ..., 0.3961, 0.3529, 0.3490]]]),\n",
       "  {'boxes': tensor([[0.0163, 0.1301, 0.8025, 0.8136]]),\n",
       "   'labels': tensor([5])}],\n",
       " [tensor([[[0.1412, 0.1333, 0.1137,  ..., 0.4824, 0.5137, 0.5333],\n",
       "           [0.0941, 0.1333, 0.1294,  ..., 0.4902, 0.5020, 0.5137],\n",
       "           [0.0627, 0.1020, 0.1137,  ..., 0.5020, 0.4980, 0.5098],\n",
       "           ...,\n",
       "           [0.7255, 0.7098, 0.6510,  ..., 0.3098, 0.2706, 0.2431],\n",
       "           [0.7804, 0.7451, 0.6784,  ..., 0.2824, 0.2588, 0.2078],\n",
       "           [0.7922, 0.7490, 0.6667,  ..., 0.2392, 0.2627, 0.2510]],\n",
       "  \n",
       "          [[0.6627, 0.6353, 0.5882,  ..., 0.3608, 0.3882, 0.4078],\n",
       "           [0.6549, 0.6706, 0.6431,  ..., 0.3647, 0.3765, 0.3882],\n",
       "           [0.6824, 0.6980, 0.6824,  ..., 0.3765, 0.3686, 0.3765],\n",
       "           ...,\n",
       "           [0.6902, 0.6902, 0.6549,  ..., 0.5412, 0.5020, 0.4745],\n",
       "           [0.7412, 0.7216, 0.6902,  ..., 0.5922, 0.5686, 0.5176],\n",
       "           [0.7647, 0.7255, 0.6706,  ..., 0.5922, 0.6196, 0.6157]],\n",
       "  \n",
       "          [[0.1725, 0.1529, 0.1216,  ..., 0.1373, 0.1647, 0.1843],\n",
       "           [0.1412, 0.1765, 0.1647,  ..., 0.1451, 0.1529, 0.1647],\n",
       "           [0.1490, 0.1843, 0.1882,  ..., 0.1529, 0.1608, 0.1686],\n",
       "           ...,\n",
       "           [0.4353, 0.4275, 0.3882,  ..., 0.2118, 0.1686, 0.1451],\n",
       "           [0.4588, 0.4314, 0.3922,  ..., 0.2314, 0.2000, 0.1490],\n",
       "           [0.4588, 0.4235, 0.3569,  ..., 0.2196, 0.2353, 0.2157]]]),\n",
       "  {'boxes': tensor([[0.0219, 0.0328, 1.0000, 0.9750]]),\n",
       "   'labels': tensor([3])}],\n",
       " [tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.4196, 0.4078, 0.3922],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.4275, 0.4196, 0.4118],\n",
       "           [0.0000, 0.0000, 0.0039,  ..., 0.4392, 0.4196, 0.4118],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.2941, 0.2863, 0.2745],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.3020, 0.2980, 0.2902],\n",
       "           [0.0000, 0.0000, 0.0039,  ..., 0.3098, 0.2941, 0.2902],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "          [[0.0078, 0.0078, 0.0078,  ..., 0.2235, 0.2157, 0.2039],\n",
       "           [0.0078, 0.0078, 0.0078,  ..., 0.2314, 0.2275, 0.2196],\n",
       "           [0.0039, 0.0039, 0.0039,  ..., 0.2392, 0.2275, 0.2196],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
       "  {'boxes': tensor([[0.1765, 0.3007, 0.8693, 0.7222]]),\n",
       "   'labels': tensor([7])}],\n",
       " [tensor([[[0.1882, 0.1843, 0.1804,  ..., 0.1765, 0.1804, 0.1843],\n",
       "           [0.1843, 0.1843, 0.1804,  ..., 0.1765, 0.1804, 0.1843],\n",
       "           [0.1843, 0.1804, 0.1765,  ..., 0.1765, 0.1804, 0.1843],\n",
       "           ...,\n",
       "           [0.0824, 0.2039, 0.1294,  ..., 0.0863, 0.0745, 0.0588],\n",
       "           [0.1686, 0.1373, 0.1765,  ..., 0.0863, 0.0627, 0.0353],\n",
       "           [0.1490, 0.2745, 0.3059,  ..., 0.1412, 0.0941, 0.0588]],\n",
       "  \n",
       "          [[0.2627, 0.2588, 0.2549,  ..., 0.2235, 0.2275, 0.2314],\n",
       "           [0.2588, 0.2588, 0.2549,  ..., 0.2235, 0.2275, 0.2314],\n",
       "           [0.2588, 0.2549, 0.2510,  ..., 0.2235, 0.2275, 0.2314],\n",
       "           ...,\n",
       "           [0.0667, 0.2000, 0.1412,  ..., 0.0980, 0.0863, 0.0667],\n",
       "           [0.1451, 0.1333, 0.1843,  ..., 0.0941, 0.0745, 0.0392],\n",
       "           [0.1255, 0.2667, 0.3176,  ..., 0.1490, 0.1098, 0.0667]],\n",
       "  \n",
       "          [[0.0863, 0.0824, 0.0784,  ..., 0.0353, 0.0392, 0.0431],\n",
       "           [0.0824, 0.0824, 0.0784,  ..., 0.0353, 0.0392, 0.0431],\n",
       "           [0.0824, 0.0784, 0.0745,  ..., 0.0353, 0.0392, 0.0431],\n",
       "           ...,\n",
       "           [0.0000, 0.1176, 0.0392,  ..., 0.0000, 0.0118, 0.0235],\n",
       "           [0.0824, 0.0510, 0.0824,  ..., 0.0039, 0.0039, 0.0039],\n",
       "           [0.0627, 0.1882, 0.2118,  ..., 0.0588, 0.0353, 0.0275]]]),\n",
       "  {'boxes': tensor([[0.2222, 0.3068, 0.4412, 0.7814]]),\n",
       "   'labels': tensor([6])}],\n",
       " [tensor([[[0.1176, 0.1804, 0.1725,  ..., 0.2078, 0.2627, 0.5725],\n",
       "           [0.2784, 0.0941, 0.1647,  ..., 0.2941, 0.5490, 0.4667],\n",
       "           [0.2235, 0.0863, 0.2314,  ..., 0.3490, 0.2588, 0.4353],\n",
       "           ...,\n",
       "           [0.1569, 0.0235, 0.1647,  ..., 0.1059, 0.2392, 0.2196],\n",
       "           [0.2431, 0.1176, 0.0353,  ..., 0.0902, 0.0549, 0.0471],\n",
       "           [0.0431, 0.0706, 0.0078,  ..., 0.1412, 0.2471, 0.1020]],\n",
       "  \n",
       "          [[0.1137, 0.0588, 0.1569,  ..., 0.2667, 0.3529, 0.5373],\n",
       "           [0.1765, 0.0118, 0.1098,  ..., 0.2627, 0.6392, 0.5294],\n",
       "           [0.2824, 0.1608, 0.2706,  ..., 0.3333, 0.3490, 0.5451],\n",
       "           ...,\n",
       "           [0.1882, 0.0000, 0.1020,  ..., 0.2039, 0.2784, 0.1569],\n",
       "           [0.2549, 0.1412, 0.1020,  ..., 0.2196, 0.0902, 0.1020],\n",
       "           [0.0824, 0.0471, 0.0039,  ..., 0.2118, 0.2510, 0.0941]],\n",
       "  \n",
       "          [[0.0980, 0.0941, 0.2392,  ..., 0.2431, 0.3843, 0.6353],\n",
       "           [0.1294, 0.1176, 0.0588,  ..., 0.2431, 0.6235, 0.5804],\n",
       "           [0.2157, 0.1686, 0.2275,  ..., 0.3608, 0.4314, 0.5569],\n",
       "           ...,\n",
       "           [0.0863, 0.0667, 0.0863,  ..., 0.1725, 0.3176, 0.2627],\n",
       "           [0.2000, 0.1529, 0.0431,  ..., 0.1255, 0.0000, 0.1529],\n",
       "           [0.0824, 0.1569, 0.0000,  ..., 0.1843, 0.2392, 0.0667]]]),\n",
       "  {'boxes': tensor([[0.0000, 0.0000, 0.9702, 0.8385]]),\n",
       "   'labels': tensor([10])}],\n",
       " [tensor([[[0.9176, 0.6941, 0.7176,  ..., 0.3373, 0.3294, 0.2824],\n",
       "           [0.8941, 0.7137, 0.7098,  ..., 0.3765, 0.4118, 0.3804],\n",
       "           [0.8745, 0.7137, 0.6941,  ..., 0.4118, 0.4392, 0.4235],\n",
       "           ...,\n",
       "           [0.1922, 0.1647, 0.1373,  ..., 0.8392, 0.5529, 0.2039],\n",
       "           [0.4157, 0.4510, 0.2157,  ..., 0.8510, 0.6039, 0.6431],\n",
       "           [0.6510, 0.1569, 0.3686,  ..., 0.3059, 0.5216, 0.8078]],\n",
       "  \n",
       "          [[0.8627, 0.6863, 0.6784,  ..., 0.3059, 0.2863, 0.2549],\n",
       "           [0.8392, 0.6980, 0.6627,  ..., 0.3451, 0.3725, 0.3529],\n",
       "           [0.8314, 0.7059, 0.6510,  ..., 0.3804, 0.3922, 0.4000],\n",
       "           ...,\n",
       "           [0.2431, 0.0980, 0.2392,  ..., 0.8510, 0.6275, 0.3020],\n",
       "           [0.4510, 0.4471, 0.2941,  ..., 0.8627, 0.7412, 0.6824],\n",
       "           [0.6627, 0.1294, 0.3216,  ..., 0.3961, 0.6118, 0.7451]],\n",
       "  \n",
       "          [[0.6627, 0.2275, 0.1882,  ..., 0.1098, 0.1059, 0.1216],\n",
       "           [0.6627, 0.2824, 0.2392,  ..., 0.1412, 0.1765, 0.1843],\n",
       "           [0.6549, 0.3137, 0.2745,  ..., 0.1686, 0.1843, 0.1882],\n",
       "           ...,\n",
       "           [0.0078, 0.0118, 0.0000,  ..., 0.0039, 0.4588, 0.1725],\n",
       "           [0.1333, 0.1725, 0.0314,  ..., 0.3647, 0.4000, 0.2510],\n",
       "           [0.1176, 0.1137, 0.2039,  ..., 0.1608, 0.1098, 0.3686]]]),\n",
       "  {'boxes': tensor([[0.1937, 0.1429, 0.6250, 0.9929]]),\n",
       "   'labels': tensor([5])}],\n",
       " [tensor([[[0.9137, 0.8275, 0.7294,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.9451, 0.9333, 0.9490,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.9294, 0.9412, 0.9373,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0157,  ..., 0.6667, 0.7333, 0.7216],\n",
       "           [0.0000, 0.0039, 0.0196,  ..., 0.8118, 0.8275, 0.7725],\n",
       "           [0.0039, 0.0078, 0.0235,  ..., 0.9176, 0.8078, 0.7725]],\n",
       "  \n",
       "          [[0.8471, 0.7608, 0.6588,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.8784, 0.8706, 0.8824,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.8667, 0.8745, 0.8706,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0039, 0.0000,  ..., 0.5725, 0.6431, 0.6353],\n",
       "           [0.0039, 0.0078, 0.0039,  ..., 0.7176, 0.7333, 0.6824],\n",
       "           [0.0039, 0.0078, 0.0078,  ..., 0.8235, 0.7137, 0.6784]],\n",
       "  \n",
       "          [[0.8157, 0.7294, 0.6314,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.8431, 0.8353, 0.8471,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.8235, 0.8353, 0.8314,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0157, 0.0118, 0.0000,  ..., 0.5373, 0.6039, 0.5922],\n",
       "           [0.0196, 0.0196, 0.0039,  ..., 0.6784, 0.6941, 0.6392],\n",
       "           [0.0235, 0.0235, 0.0078,  ..., 0.7843, 0.6745, 0.6392]]]),\n",
       "  {'boxes': tensor([[0.0889, 0.1659, 0.8894, 0.9976]]),\n",
       "   'labels': tensor([8])}],\n",
       " [tensor([[[1.0000, 1.0000, 1.0000,  ..., 0.1569, 0.1569, 0.1569],\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 0.1569, 0.1569, 0.1569],\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 0.1569, 0.1569, 0.1569],\n",
       "           ...,\n",
       "           [0.8392, 0.7569, 0.6627,  ..., 0.1569, 0.1569, 0.1569],\n",
       "           [0.7216, 0.7686, 0.7216,  ..., 0.1569, 0.1569, 0.1569],\n",
       "           [0.7490, 0.7882, 0.7647,  ..., 0.1569, 0.1569, 0.1569]],\n",
       "  \n",
       "          [[1.0000, 1.0000, 1.0000,  ..., 0.1569, 0.1569, 0.1569],\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 0.1569, 0.1569, 0.1569],\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 0.1569, 0.1569, 0.1569],\n",
       "           ...,\n",
       "           [0.8118, 0.7255, 0.6235,  ..., 0.1569, 0.1569, 0.1569],\n",
       "           [0.6941, 0.7412, 0.6902,  ..., 0.1569, 0.1569, 0.1569],\n",
       "           [0.7216, 0.7608, 0.7333,  ..., 0.1569, 0.1569, 0.1569]],\n",
       "  \n",
       "          [[1.0000, 1.0000, 1.0000,  ..., 0.1569, 0.1569, 0.1569],\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 0.1569, 0.1569, 0.1569],\n",
       "           [1.0000, 1.0000, 1.0000,  ..., 0.1569, 0.1569, 0.1569],\n",
       "           ...,\n",
       "           [0.6549, 0.5725, 0.4745,  ..., 0.1569, 0.1569, 0.1569],\n",
       "           [0.5255, 0.5725, 0.5412,  ..., 0.1569, 0.1569, 0.1569],\n",
       "           [0.5412, 0.5922, 0.5804,  ..., 0.1569, 0.1569, 0.1569]]]),\n",
       "  {'boxes': tensor([[0.4175, 0.5124, 0.4401, 0.5484]]),\n",
       "   'labels': tensor([7])}],\n",
       " [tensor([[[0.1294, 0.0745, 0.0980,  ..., 0.9725, 0.8941, 0.9490],\n",
       "           [0.2235, 0.1412, 0.2980,  ..., 0.9804, 0.7569, 0.8353],\n",
       "           [0.0980, 0.2118, 0.0863,  ..., 0.9373, 0.9843, 0.7529],\n",
       "           ...,\n",
       "           [0.0588, 0.2353, 0.1216,  ..., 0.8824, 0.8824, 0.9176],\n",
       "           [0.1412, 0.2235, 0.2157,  ..., 0.9608, 0.8588, 1.0000],\n",
       "           [0.2941, 0.2196, 0.1569,  ..., 0.4980, 0.8392, 0.6824]],\n",
       "  \n",
       "          [[0.1490, 0.0824, 0.1255,  ..., 0.5686, 0.4431, 0.5333],\n",
       "           [0.1608, 0.1176, 0.3412,  ..., 0.5725, 0.4196, 0.4275],\n",
       "           [0.0000, 0.1725, 0.1725,  ..., 0.5490, 0.6431, 0.4000],\n",
       "           ...,\n",
       "           [0.1608, 0.2824, 0.0902,  ..., 0.4353, 0.4549, 0.5255],\n",
       "           [0.1294, 0.1765, 0.1529,  ..., 0.6706, 0.5255, 0.7373],\n",
       "           [0.1412, 0.0745, 0.0706,  ..., 0.3647, 0.6588, 0.4392]],\n",
       "  \n",
       "          [[0.2392, 0.1843, 0.1804,  ..., 0.7608, 0.6431, 0.7294],\n",
       "           [0.2431, 0.1608, 0.3255,  ..., 0.6235, 0.5216, 0.5686],\n",
       "           [0.0314, 0.1333, 0.0431,  ..., 0.4745, 0.6471, 0.4667],\n",
       "           ...,\n",
       "           [0.1255, 0.3216, 0.1686,  ..., 0.5451, 0.6235, 0.6863],\n",
       "           [0.1529, 0.2667, 0.2667,  ..., 0.5882, 0.5569, 0.8667],\n",
       "           [0.2706, 0.2353, 0.2235,  ..., 0.1137, 0.5333, 0.4863]]]),\n",
       "  {'boxes': tensor([[0.2625, 0.0460, 0.8496, 0.9885]]),\n",
       "   'labels': tensor([8])}],\n",
       " [tensor([[[0.1412, 0.1412, 0.1412,  ..., 0.1412, 0.1412, 0.1412],\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.1412, 0.1412, 0.1412],\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.1412, 0.1412, 0.1412],\n",
       "           ...,\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.7647, 0.7608, 0.7608],\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.7647, 0.7608, 0.7608],\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.7647, 0.7608, 0.7608]],\n",
       "  \n",
       "          [[0.1412, 0.1412, 0.1412,  ..., 0.1412, 0.1412, 0.1412],\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.1412, 0.1412, 0.1412],\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.1412, 0.1412, 0.1412],\n",
       "           ...,\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.7255, 0.7216, 0.7216],\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.7255, 0.7216, 0.7216],\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.7255, 0.7216, 0.7216]],\n",
       "  \n",
       "          [[0.1412, 0.1412, 0.1412,  ..., 0.1412, 0.1412, 0.1412],\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.1412, 0.1412, 0.1412],\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.1412, 0.1412, 0.1412],\n",
       "           ...,\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.7176, 0.7137, 0.7137],\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.7176, 0.7137, 0.7137],\n",
       "           [0.1412, 0.1412, 0.1412,  ..., 0.7176, 0.7137, 0.7137]]]),\n",
       "  {'boxes': tensor([[0.0150, 0.2644, 0.9994, 0.8654]]),\n",
       "   'labels': tensor([9])}],\n",
       " [tensor([[[0.1804, 0.1686, 0.1569,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.1843, 0.1725, 0.1608,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.1843, 0.1725, 0.1608,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.3137, 0.3216, 0.3412,  ..., 0.2824, 0.2157, 0.1529],\n",
       "           [0.3412, 0.3176, 0.3412,  ..., 0.4039, 0.3176, 0.2510],\n",
       "           [0.3686, 0.3569, 0.3608,  ..., 0.4784, 0.4314, 0.3569]],\n",
       "  \n",
       "          [[0.1529, 0.1412, 0.1294,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.1569, 0.1451, 0.1333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.1569, 0.1451, 0.1333,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.2824, 0.2902, 0.3098,  ..., 0.2510, 0.1765, 0.1176],\n",
       "           [0.3098, 0.2863, 0.3098,  ..., 0.3529, 0.2784, 0.2078],\n",
       "           [0.3373, 0.3255, 0.3294,  ..., 0.4275, 0.3843, 0.3098]],\n",
       "  \n",
       "          [[0.1137, 0.1020, 0.0902,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.1176, 0.1059, 0.0941,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.1176, 0.1059, 0.0941,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.2706, 0.2784, 0.2980,  ..., 0.1294, 0.0863, 0.0353],\n",
       "           [0.2980, 0.2745, 0.2980,  ..., 0.2078, 0.1451, 0.0941],\n",
       "           [0.3255, 0.3137, 0.3216,  ..., 0.2510, 0.2235, 0.1608]]]),\n",
       "  {'boxes': tensor([[0.0000, 0.0369, 1.0000, 1.0000]]),\n",
       "   'labels': tensor([1])}],\n",
       " [tensor([[[0.0157, 0.0314, 0.0235,  ..., 0.0392, 0.0392, 0.0549],\n",
       "           [0.0275, 0.0275, 0.0353,  ..., 0.0314, 0.0431, 0.0353],\n",
       "           [0.0235, 0.0353, 0.0275,  ..., 0.0431, 0.0510, 0.0549],\n",
       "           ...,\n",
       "           [0.3373, 0.2941, 0.2588,  ..., 0.1490, 0.1608, 0.1137],\n",
       "           [0.2431, 0.2314, 0.2627,  ..., 0.1451, 0.1373, 0.1216],\n",
       "           [0.2314, 0.2235, 0.2392,  ..., 0.1216, 0.1294, 0.1020]],\n",
       "  \n",
       "          [[0.0157, 0.0314, 0.0235,  ..., 0.0431, 0.0392, 0.0549],\n",
       "           [0.0275, 0.0275, 0.0353,  ..., 0.0314, 0.0471, 0.0353],\n",
       "           [0.0235, 0.0353, 0.0275,  ..., 0.0353, 0.0471, 0.0471],\n",
       "           ...,\n",
       "           [0.1961, 0.1451, 0.1333,  ..., 0.0784, 0.0824, 0.0784],\n",
       "           [0.1294, 0.1294, 0.1373,  ..., 0.0941, 0.0824, 0.0667],\n",
       "           [0.1216, 0.1098, 0.1176,  ..., 0.0784, 0.0824, 0.0706]],\n",
       "  \n",
       "          [[0.0078, 0.0196, 0.0196,  ..., 0.0235, 0.0196, 0.0392],\n",
       "           [0.0275, 0.0275, 0.0314,  ..., 0.0196, 0.0314, 0.0275],\n",
       "           [0.0196, 0.0353, 0.0275,  ..., 0.0275, 0.0353, 0.0510],\n",
       "           ...,\n",
       "           [0.0745, 0.0863, 0.0627,  ..., 0.0392, 0.0588, 0.0314],\n",
       "           [0.0980, 0.0549, 0.0824,  ..., 0.0667, 0.0706, 0.0588],\n",
       "           [0.0667, 0.0627, 0.0902,  ..., 0.0706, 0.0588, 0.0353]]]),\n",
       "  {'boxes': tensor([[0.0873, 0.2217, 0.9391, 0.9696]]),\n",
       "   'labels': tensor([4])}],\n",
       " [tensor([[[0.3176, 0.3176, 0.3216,  ..., 0.3216, 0.3176, 0.3020],\n",
       "           [0.3216, 0.3176, 0.3216,  ..., 0.3137, 0.3176, 0.3176],\n",
       "           [0.3059, 0.3098, 0.3137,  ..., 0.3176, 0.3137, 0.3137],\n",
       "           ...,\n",
       "           [0.3216, 0.3176, 0.3294,  ..., 0.3451, 0.3373, 0.3373],\n",
       "           [0.3255, 0.3412, 0.3333,  ..., 0.3333, 0.3255, 0.3255],\n",
       "           [0.3294, 0.3294, 0.3255,  ..., 0.3294, 0.3216, 0.3176]],\n",
       "  \n",
       "          [[0.4431, 0.4431, 0.4510,  ..., 0.4392, 0.4431, 0.4392],\n",
       "           [0.4471, 0.4392, 0.4431,  ..., 0.4392, 0.4353, 0.4353],\n",
       "           [0.4471, 0.4431, 0.4392,  ..., 0.4431, 0.4392, 0.4392],\n",
       "           ...,\n",
       "           [0.4627, 0.4549, 0.4588,  ..., 0.4667, 0.4627, 0.4627],\n",
       "           [0.4627, 0.4627, 0.4588,  ..., 0.4588, 0.4627, 0.4588],\n",
       "           [0.4549, 0.4510, 0.4588,  ..., 0.4510, 0.4588, 0.4588]],\n",
       "  \n",
       "          [[0.6745, 0.6745, 0.6745,  ..., 0.6824, 0.6824, 0.6863],\n",
       "           [0.6706, 0.6706, 0.6784,  ..., 0.6706, 0.6863, 0.6863],\n",
       "           [0.6706, 0.6706, 0.6745,  ..., 0.6706, 0.6784, 0.6745],\n",
       "           ...,\n",
       "           [0.6941, 0.6824, 0.6863,  ..., 0.7059, 0.7020, 0.6902],\n",
       "           [0.6784, 0.6941, 0.6941,  ..., 0.6902, 0.6902, 0.6980],\n",
       "           [0.6941, 0.7020, 0.7059,  ..., 0.6745, 0.6863, 0.7020]]]),\n",
       "  {'boxes': tensor([[0.4292, 0.1019, 0.8533, 0.5888]]),\n",
       "   'labels': tensor([7])}],\n",
       " [tensor([[[0.6824, 0.6824, 0.6863,  ..., 0.6510, 0.6471, 0.6471],\n",
       "           [0.6824, 0.6863, 0.6863,  ..., 0.6510, 0.6471, 0.6471],\n",
       "           [0.6863, 0.6863, 0.6863,  ..., 0.6510, 0.6471, 0.6471],\n",
       "           ...,\n",
       "           [0.4353, 0.4235, 0.4118,  ..., 0.3098, 0.3059, 0.3059],\n",
       "           [0.4314, 0.4196, 0.4078,  ..., 0.3020, 0.3020, 0.2980],\n",
       "           [0.4314, 0.4196, 0.4078,  ..., 0.3020, 0.2980, 0.2980]],\n",
       "  \n",
       "          [[0.6667, 0.6667, 0.6706,  ..., 0.6471, 0.6431, 0.6431],\n",
       "           [0.6667, 0.6706, 0.6706,  ..., 0.6471, 0.6431, 0.6431],\n",
       "           [0.6706, 0.6706, 0.6706,  ..., 0.6471, 0.6431, 0.6431],\n",
       "           ...,\n",
       "           [0.4431, 0.4314, 0.4196,  ..., 0.3373, 0.3333, 0.3294],\n",
       "           [0.4392, 0.4275, 0.4157,  ..., 0.3294, 0.3294, 0.3255],\n",
       "           [0.4392, 0.4275, 0.4157,  ..., 0.3294, 0.3255, 0.3255]],\n",
       "  \n",
       "          [[0.6706, 0.6706, 0.6745,  ..., 0.6667, 0.6627, 0.6627],\n",
       "           [0.6706, 0.6745, 0.6745,  ..., 0.6667, 0.6627, 0.6627],\n",
       "           [0.6745, 0.6745, 0.6745,  ..., 0.6667, 0.6627, 0.6627],\n",
       "           ...,\n",
       "           [0.3922, 0.3882, 0.3765,  ..., 0.3608, 0.3569, 0.3569],\n",
       "           [0.3882, 0.3804, 0.3725,  ..., 0.3529, 0.3529, 0.3490],\n",
       "           [0.3882, 0.3804, 0.3686,  ..., 0.3529, 0.3490, 0.3490]]]),\n",
       "  {'boxes': tensor([[0.1214, 0.6562, 0.7151, 0.8678]]),\n",
       "   'labels': tensor([7])}],\n",
       " [tensor([[[0.7216, 0.6824, 0.5608,  ..., 0.6235, 0.6235, 0.6627],\n",
       "           [0.7216, 0.6118, 0.8235,  ..., 0.6824, 0.5686, 0.7373],\n",
       "           [0.6549, 0.7608, 0.7216,  ..., 0.7451, 0.6902, 0.5843],\n",
       "           ...,\n",
       "           [0.9961, 0.9843, 1.0000,  ..., 0.4863, 0.3647, 0.3686],\n",
       "           [0.9961, 0.9647, 1.0000,  ..., 0.3373, 0.4510, 0.5137],\n",
       "           [0.9843, 1.0000, 0.9333,  ..., 0.6157, 0.3922, 0.3373]],\n",
       "  \n",
       "          [[0.8000, 0.6980, 0.5137,  ..., 0.6078, 0.5961, 0.6235],\n",
       "           [0.6471, 0.5725, 0.8235,  ..., 0.6824, 0.6000, 0.7843],\n",
       "           [0.5843, 0.6980, 0.6745,  ..., 0.7765, 0.7451, 0.6431],\n",
       "           ...,\n",
       "           [0.9843, 0.9843, 1.0000,  ..., 0.5059, 0.4118, 0.4549],\n",
       "           [0.9922, 0.9569, 0.9961,  ..., 0.2745, 0.4471, 0.5882],\n",
       "           [0.9608, 0.9725, 0.9098,  ..., 0.5490, 0.4196, 0.4588]],\n",
       "  \n",
       "          [[0.8000, 0.7569, 0.6196,  ..., 0.7020, 0.7059, 0.7373],\n",
       "           [0.7765, 0.6784, 0.8824,  ..., 0.6824, 0.6275, 0.8392],\n",
       "           [0.6627, 0.7647, 0.7216,  ..., 0.6824, 0.6863, 0.6314],\n",
       "           ...,\n",
       "           [0.9765, 0.9843, 1.0000,  ..., 0.4902, 0.3961, 0.4314],\n",
       "           [0.9686, 0.9647, 1.0000,  ..., 0.2588, 0.4549, 0.6000],\n",
       "           [0.9569, 0.9922, 0.9451,  ..., 0.5255, 0.4078, 0.4471]]]),\n",
       "  {'boxes': tensor([[0.1773, 0.0240, 1.0000, 0.9980]]),\n",
       "   'labels': tensor([1])}],\n",
       " [tensor([[[0.6863, 0.8824, 0.8824,  ..., 0.8078, 0.7725, 0.7490],\n",
       "           [0.5882, 0.6157, 0.9020,  ..., 0.7922, 0.7725, 0.7451],\n",
       "           [1.0000, 1.0000, 0.8431,  ..., 0.8039, 0.7725, 0.7412],\n",
       "           ...,\n",
       "           [0.3216, 0.3451, 0.6039,  ..., 0.4039, 0.4902, 0.7216],\n",
       "           [0.2353, 0.3451, 0.2471,  ..., 0.3137, 0.5725, 0.6745],\n",
       "           [0.2000, 0.4157, 0.3176,  ..., 0.5137, 0.1373, 0.6510]],\n",
       "  \n",
       "          [[0.6431, 0.8314, 0.8549,  ..., 0.7961, 0.7608, 0.7373],\n",
       "           [0.5490, 0.5647, 0.8745,  ..., 0.7804, 0.7608, 0.7333],\n",
       "           [0.9765, 0.9882, 0.8196,  ..., 0.7922, 0.7608, 0.7294],\n",
       "           ...,\n",
       "           [0.2706, 0.2706, 0.5451,  ..., 0.3255, 0.4275, 0.6510],\n",
       "           [0.1804, 0.2745, 0.1804,  ..., 0.2392, 0.5020, 0.6000],\n",
       "           [0.1294, 0.3451, 0.2431,  ..., 0.4471, 0.0824, 0.5961]],\n",
       "  \n",
       "          [[0.6627, 0.8275, 0.8471,  ..., 0.7686, 0.7333, 0.7098],\n",
       "           [0.5647, 0.5647, 0.8706,  ..., 0.7529, 0.7333, 0.7059],\n",
       "           [0.9922, 0.9843, 0.8078,  ..., 0.7647, 0.7333, 0.7020],\n",
       "           ...,\n",
       "           [0.1961, 0.2157, 0.4549,  ..., 0.2157, 0.2980, 0.5255],\n",
       "           [0.1020, 0.2196, 0.1137,  ..., 0.1255, 0.3961, 0.4941],\n",
       "           [0.0863, 0.3137, 0.2039,  ..., 0.3373, 0.0157, 0.5255]]]),\n",
       "  {'boxes': tensor([[0.0734, 0.1236, 0.7691, 0.8535]]),\n",
       "   'labels': tensor([2])}],\n",
       " [tensor([[[0.6667, 0.6784, 0.6667,  ..., 0.4588, 0.4549, 0.4824],\n",
       "           [0.6667, 0.6784, 0.6667,  ..., 0.4431, 0.4510, 0.4627],\n",
       "           [0.6667, 0.6784, 0.6667,  ..., 0.4314, 0.4431, 0.4431],\n",
       "           ...,\n",
       "           [0.8314, 0.8275, 0.8275,  ..., 0.8471, 0.8471, 0.8431],\n",
       "           [0.8275, 0.8235, 0.8235,  ..., 0.8549, 0.8510, 0.8471],\n",
       "           [0.8431, 0.8353, 0.8353,  ..., 0.8549, 0.8588, 0.8549]],\n",
       "  \n",
       "          [[0.6667, 0.6784, 0.6667,  ..., 0.4588, 0.4549, 0.4824],\n",
       "           [0.6667, 0.6784, 0.6667,  ..., 0.4431, 0.4510, 0.4627],\n",
       "           [0.6667, 0.6784, 0.6667,  ..., 0.4314, 0.4431, 0.4431],\n",
       "           ...,\n",
       "           [0.8314, 0.8275, 0.8275,  ..., 0.8471, 0.8471, 0.8431],\n",
       "           [0.8275, 0.8235, 0.8235,  ..., 0.8549, 0.8510, 0.8471],\n",
       "           [0.8431, 0.8353, 0.8353,  ..., 0.8549, 0.8588, 0.8549]],\n",
       "  \n",
       "          [[0.6667, 0.6784, 0.6667,  ..., 0.4588, 0.4549, 0.4824],\n",
       "           [0.6667, 0.6784, 0.6667,  ..., 0.4431, 0.4510, 0.4627],\n",
       "           [0.6667, 0.6784, 0.6667,  ..., 0.4314, 0.4431, 0.4431],\n",
       "           ...,\n",
       "           [0.8314, 0.8275, 0.8275,  ..., 0.8471, 0.8471, 0.8431],\n",
       "           [0.8275, 0.8235, 0.8235,  ..., 0.8549, 0.8510, 0.8471],\n",
       "           [0.8431, 0.8353, 0.8353,  ..., 0.8549, 0.8588, 0.8549]]]),\n",
       "  {'boxes': tensor([[0.2164, 0.0398, 0.9117, 0.9914]]),\n",
       "   'labels': tensor([9])}],\n",
       " [tensor([[[0.2667, 0.5098, 0.2000,  ..., 0.2235, 0.4039, 0.4431],\n",
       "           [0.1882, 0.4824, 0.4588,  ..., 0.2157, 0.3961, 0.5216],\n",
       "           [0.1882, 0.3608, 0.3647,  ..., 0.1686, 0.5020, 0.5922],\n",
       "           ...,\n",
       "           [0.4157, 0.4824, 0.4118,  ..., 0.6000, 0.6510, 0.3412],\n",
       "           [0.3608, 0.3647, 0.2275,  ..., 0.8196, 0.7294, 0.4627],\n",
       "           [0.2000, 0.4510, 0.2353,  ..., 0.8392, 0.7490, 0.6941]],\n",
       "  \n",
       "          [[0.4157, 0.6588, 0.3412,  ..., 0.3569, 0.5373, 0.5765],\n",
       "           [0.3294, 0.6196, 0.6000,  ..., 0.3373, 0.5137, 0.6353],\n",
       "           [0.3294, 0.5020, 0.5059,  ..., 0.2745, 0.6039, 0.6902],\n",
       "           ...,\n",
       "           [0.5216, 0.5843, 0.5216,  ..., 0.6941, 0.7490, 0.4353],\n",
       "           [0.4667, 0.4706, 0.3333,  ..., 0.9176, 0.8392, 0.5725],\n",
       "           [0.3020, 0.5569, 0.3412,  ..., 0.9451, 0.8627, 0.8157]],\n",
       "  \n",
       "          [[0.2627, 0.5059, 0.2000,  ..., 0.2510, 0.4392, 0.4824],\n",
       "           [0.1765, 0.4706, 0.4588,  ..., 0.2353, 0.4235, 0.5490],\n",
       "           [0.1882, 0.3647, 0.3647,  ..., 0.1765, 0.5020, 0.6078],\n",
       "           ...,\n",
       "           [0.3216, 0.3686, 0.2941,  ..., 0.4510, 0.5255, 0.2275],\n",
       "           [0.2667, 0.2588, 0.1098,  ..., 0.7020, 0.6118, 0.3333],\n",
       "           [0.1098, 0.3451, 0.1216,  ..., 0.7529, 0.6275, 0.5569]]]),\n",
       "  {'boxes': tensor([[0.4266, 0.2594, 0.9656, 0.6391]]),\n",
       "   'labels': tensor([3])}],\n",
       " [tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.2667, 0.1137],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0549, 0.0627, 0.0706],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0588, 0.1333],\n",
       "           ...,\n",
       "           [0.8667, 0.8471, 0.8392,  ..., 0.8157, 0.8118, 0.7961],\n",
       "           [0.8588, 0.8549, 0.8431,  ..., 0.8157, 0.8000, 0.7922],\n",
       "           [0.8353, 0.8706, 0.8510,  ..., 0.8275, 0.8157, 0.8039]],\n",
       "  \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0078, 0.2745, 0.1216],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0588, 0.0706, 0.0784],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0784, 0.0667, 0.1412],\n",
       "           ...,\n",
       "           [0.7922, 0.7922, 0.7961,  ..., 0.7490, 0.7451, 0.7294],\n",
       "           [0.7843, 0.8039, 0.8000,  ..., 0.7490, 0.7333, 0.7255],\n",
       "           [0.7608, 0.8196, 0.8078,  ..., 0.7647, 0.7490, 0.7373]],\n",
       "  \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2235, 0.0706],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0275, 0.0196, 0.0235],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0471, 0.0157, 0.0902],\n",
       "           ...,\n",
       "           [0.6863, 0.6784, 0.6784,  ..., 0.6392, 0.6353, 0.6196],\n",
       "           [0.6745, 0.6863, 0.6784,  ..., 0.6275, 0.6196, 0.6118],\n",
       "           [0.6431, 0.6941, 0.6824,  ..., 0.6353, 0.6314, 0.6196]]]),\n",
       "  {'boxes': tensor([[0.2836, 0.1422, 0.7748, 0.8543]]),\n",
       "   'labels': tensor([2])}],\n",
       " [tensor([[[0.1647, 0.1529, 0.0745,  ..., 0.1412, 0.1137, 0.2078],\n",
       "           [0.1843, 0.1882, 0.1882,  ..., 0.0902, 0.0980, 0.0471],\n",
       "           [0.1412, 0.0627, 0.0902,  ..., 0.0627, 0.1490, 0.1843],\n",
       "           ...,\n",
       "           [0.2157, 0.0314, 0.0902,  ..., 0.1020, 0.1059, 0.2235],\n",
       "           [0.1608, 0.1843, 0.1255,  ..., 0.0784, 0.2902, 0.0941],\n",
       "           [0.2549, 0.2039, 0.2000,  ..., 0.2235, 0.1098, 0.1922]],\n",
       "  \n",
       "          [[0.1569, 0.1020, 0.0706,  ..., 0.1569, 0.0941, 0.2235],\n",
       "           [0.1176, 0.1961, 0.1961,  ..., 0.1608, 0.1373, 0.0549],\n",
       "           [0.2078, 0.1922, 0.0824,  ..., 0.0235, 0.1647, 0.1216],\n",
       "           ...,\n",
       "           [0.1529, 0.0078, 0.0588,  ..., 0.0471, 0.0392, 0.2745],\n",
       "           [0.1765, 0.1412, 0.1843,  ..., 0.1412, 0.3137, 0.0549],\n",
       "           [0.2157, 0.2118, 0.2471,  ..., 0.2314, 0.1843, 0.1647]],\n",
       "  \n",
       "          [[0.2078, 0.0941, 0.0745,  ..., 0.1922, 0.1451, 0.2235],\n",
       "           [0.1137, 0.1333, 0.1294,  ..., 0.1765, 0.2039, 0.1137],\n",
       "           [0.2078, 0.1098, 0.0510,  ..., 0.0863, 0.1490, 0.0941],\n",
       "           ...,\n",
       "           [0.1961, 0.0941, 0.1569,  ..., 0.1020, 0.0549, 0.2353],\n",
       "           [0.0706, 0.1882, 0.1804,  ..., 0.2196, 0.2118, 0.0706],\n",
       "           [0.1059, 0.1843, 0.1451,  ..., 0.2118, 0.0627, 0.1608]]]),\n",
       "  {'boxes': tensor([[0.0630, 0.0920, 0.6705, 0.8916],\n",
       "           [0.6222, 0.0000, 0.9542, 0.4493],\n",
       "           [0.0000, 0.0043, 0.3250, 0.4928]]),\n",
       "   'labels': tensor([3, 3, 3])}],\n",
       " [tensor([[[0.1922, 0.1804, 0.1569,  ..., 0.1451, 0.0510, 0.1373],\n",
       "           [0.1843, 0.1725, 0.1647,  ..., 0.1451, 0.0510, 0.1294],\n",
       "           [0.1765, 0.1686, 0.1647,  ..., 0.1490, 0.0549, 0.1294],\n",
       "           ...,\n",
       "           [0.7922, 0.7922, 0.7922,  ..., 0.4745, 0.4824, 0.4980],\n",
       "           [0.7922, 0.7922, 0.7961,  ..., 0.4471, 0.4627, 0.4745],\n",
       "           [0.7922, 0.7882, 0.7922,  ..., 0.4314, 0.4392, 0.4549]],\n",
       "  \n",
       "          [[0.0784, 0.0706, 0.0627,  ..., 0.1608, 0.0706, 0.1569],\n",
       "           [0.0706, 0.0667, 0.0627,  ..., 0.1608, 0.0706, 0.1529],\n",
       "           [0.0627, 0.0627, 0.0627,  ..., 0.1647, 0.0706, 0.1490],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.3216, 0.3333, 0.3490],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.3020, 0.3137, 0.3255],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.2784, 0.2980, 0.3098]],\n",
       "  \n",
       "          [[0.0471, 0.0353, 0.0235,  ..., 0.1451, 0.0471, 0.1333],\n",
       "           [0.0392, 0.0314, 0.0275,  ..., 0.1490, 0.0471, 0.1294],\n",
       "           [0.0314, 0.0275, 0.0275,  ..., 0.1529, 0.0588, 0.1333],\n",
       "           ...,\n",
       "           [0.0941, 0.0941, 0.0941,  ..., 0.2392, 0.2510, 0.2667],\n",
       "           [0.0941, 0.0941, 0.0941,  ..., 0.2235, 0.2314, 0.2471],\n",
       "           [0.0941, 0.0902, 0.0941,  ..., 0.2078, 0.2235, 0.2392]]]),\n",
       "  {'boxes': tensor([[0.2020, 0.2072, 0.9980, 0.6937],\n",
       "           [0.1040, 0.0330, 0.9980, 0.9399]]),\n",
       "   'labels': tensor([1, 1])}],\n",
       " [tensor([[[0.9922, 0.9882, 0.9804,  ..., 0.0235, 0.4824, 0.3647],\n",
       "           [0.9922, 0.9843, 0.9882,  ..., 0.1843, 0.5490, 0.5843],\n",
       "           [0.9804, 0.9373, 0.9412,  ..., 0.2667, 0.3647, 0.6902],\n",
       "           ...,\n",
       "           [0.9412, 0.9451, 0.9569,  ..., 1.0000, 1.0000, 0.9961],\n",
       "           [0.9608, 0.9490, 0.9569,  ..., 0.9961, 1.0000, 1.0000],\n",
       "           [0.9569, 0.9569, 0.9647,  ..., 1.0000, 1.0000, 0.9922]],\n",
       "  \n",
       "          [[0.9569, 0.9529, 0.9333,  ..., 0.0431, 0.5020, 0.3804],\n",
       "           [0.9569, 0.9490, 0.9451,  ..., 0.2275, 0.5922, 0.5922],\n",
       "           [0.9451, 0.8980, 0.8941,  ..., 0.3451, 0.4275, 0.7020],\n",
       "           ...,\n",
       "           [0.9059, 0.9098, 0.9216,  ..., 0.9804, 0.9882, 0.9765],\n",
       "           [0.9255, 0.9137, 0.9216,  ..., 0.9804, 0.9804, 0.9765],\n",
       "           [0.9216, 0.9216, 0.9294,  ..., 0.9882, 0.9843, 0.9647]],\n",
       "  \n",
       "          [[0.2157, 0.2078, 0.2118,  ..., 0.0314, 0.4118, 0.2980],\n",
       "           [0.2157, 0.1961, 0.2118,  ..., 0.1412, 0.4510, 0.4941],\n",
       "           [0.2000, 0.1686, 0.1843,  ..., 0.1961, 0.2824, 0.6275],\n",
       "           ...,\n",
       "           [0.7529, 0.7569, 0.7686,  ..., 0.8157, 0.8118, 0.8275],\n",
       "           [0.7725, 0.7608, 0.7647,  ..., 0.8196, 0.8157, 0.8471],\n",
       "           [0.7686, 0.7686, 0.7686,  ..., 0.8235, 0.8314, 0.8510]]]),\n",
       "  {'boxes': tensor([[0.3535, 0.1717, 0.8235, 0.9796]]),\n",
       "   'labels': tensor([2])}],\n",
       " [tensor([[[0.9176, 0.9216, 0.9020,  ..., 0.8510, 0.8235, 0.8471],\n",
       "           [0.9020, 0.9059, 0.8902,  ..., 0.8745, 0.8706, 0.8627],\n",
       "           [0.9176, 0.8863, 0.8078,  ..., 0.8118, 0.8588, 0.8706],\n",
       "           ...,\n",
       "           [0.9059, 0.9176, 0.9333,  ..., 0.7882, 0.8196, 0.8745],\n",
       "           [0.9137, 0.9216, 0.9176,  ..., 0.8706, 0.8745, 0.8941],\n",
       "           [0.8863, 0.8980, 0.8980,  ..., 0.8549, 0.8706, 0.8784]],\n",
       "  \n",
       "          [[0.4275, 0.4157, 0.4275,  ..., 0.6039, 0.5882, 0.6157],\n",
       "           [0.4314, 0.4235, 0.4235,  ..., 0.6078, 0.6039, 0.5725],\n",
       "           [0.4235, 0.4353, 0.4667,  ..., 0.6157, 0.6157, 0.5922],\n",
       "           ...,\n",
       "           [0.3490, 0.3569, 0.3725,  ..., 0.5608, 0.5451, 0.5451],\n",
       "           [0.3529, 0.3608, 0.3608,  ..., 0.5412, 0.5529, 0.5725],\n",
       "           [0.3294, 0.3373, 0.3412,  ..., 0.5373, 0.5608, 0.5490]],\n",
       "  \n",
       "          [[0.2667, 0.2863, 0.2863,  ..., 0.2510, 0.2549, 0.3020],\n",
       "           [0.2667, 0.2824, 0.2784,  ..., 0.2588, 0.2471, 0.2392],\n",
       "           [0.2824, 0.2627, 0.2314,  ..., 0.3333, 0.2980, 0.2588],\n",
       "           ...,\n",
       "           [0.2863, 0.2902, 0.3020,  ..., 0.3647, 0.2745, 0.2667],\n",
       "           [0.2902, 0.2941, 0.2863,  ..., 0.2745, 0.2588, 0.2941],\n",
       "           [0.2667, 0.2706, 0.2667,  ..., 0.2941, 0.2863, 0.2941]]]),\n",
       "  {'boxes': tensor([[0.0141, 0.0208, 0.9281, 0.8722]]),\n",
       "   'labels': tensor([10])}],\n",
       " [tensor([[[0.3725, 0.3686, 0.3333,  ..., 0.3686, 0.4745, 0.4667],\n",
       "           [0.3686, 0.3333, 0.4235,  ..., 0.5255, 0.4353, 0.3176],\n",
       "           [0.3412, 0.3843, 0.3608,  ..., 0.5216, 0.5412, 0.4588],\n",
       "           ...,\n",
       "           [0.4941, 0.5059, 0.5647,  ..., 0.4314, 0.4745, 0.4353],\n",
       "           [0.4863, 0.5255, 0.5137,  ..., 0.4667, 0.6275, 0.3686],\n",
       "           [0.4431, 0.4902, 0.4824,  ..., 0.4667, 0.4667, 0.2824]],\n",
       "  \n",
       "          [[0.4000, 0.3961, 0.3608,  ..., 0.3647, 0.4745, 0.4824],\n",
       "           [0.4000, 0.3608, 0.4510,  ..., 0.5176, 0.4353, 0.3333],\n",
       "           [0.3686, 0.4118, 0.3882,  ..., 0.5137, 0.5412, 0.4784],\n",
       "           ...,\n",
       "           [0.5098, 0.4980, 0.5490,  ..., 0.4588, 0.5137, 0.4980],\n",
       "           [0.5294, 0.5490, 0.5255,  ..., 0.4863, 0.6549, 0.4314],\n",
       "           [0.4980, 0.5373, 0.5137,  ..., 0.4706, 0.4863, 0.3294]],\n",
       "  \n",
       "          [[0.3725, 0.3686, 0.3333,  ..., 0.3804, 0.4784, 0.4627],\n",
       "           [0.3686, 0.3333, 0.4235,  ..., 0.5373, 0.4353, 0.3098],\n",
       "           [0.3412, 0.3843, 0.3608,  ..., 0.5373, 0.5529, 0.4627],\n",
       "           ...,\n",
       "           [0.4824, 0.4784, 0.5333,  ..., 0.3882, 0.4745, 0.3922],\n",
       "           [0.4902, 0.5216, 0.4980,  ..., 0.4157, 0.6118, 0.2941],\n",
       "           [0.4549, 0.4980, 0.4824,  ..., 0.4196, 0.4314, 0.1804]]]),\n",
       "  {'boxes': tensor([[0.0587, 0.1708, 0.2819, 0.5142],\n",
       "           [0.2925, 0.2417, 0.5044, 0.6175],\n",
       "           [0.6269, 0.3000, 0.9962, 0.7258]]),\n",
       "   'labels': tensor([4, 4, 4])}],\n",
       " [tensor([[[0.4706, 0.4980, 0.4471,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.4314, 0.4941, 0.5098,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.3765, 0.4588, 0.4627,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.5961, 0.7059, 0.8431],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.5686, 0.5529, 0.6314],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.5098, 0.4706, 0.5765]],\n",
       "  \n",
       "          [[0.4235, 0.4471, 0.4039,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.3725, 0.4471, 0.4588,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.3137, 0.4000, 0.4078,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.5098, 0.6314, 0.7765],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.4863, 0.4824, 0.5725],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.4314, 0.4078, 0.5176]],\n",
       "  \n",
       "          [[0.3686, 0.4000, 0.3686,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.3176, 0.3961, 0.4196,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.2549, 0.3451, 0.3608,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.3804, 0.5137, 0.6667],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.3647, 0.3765, 0.4784],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.3216, 0.3098, 0.4353]]]),\n",
       "  {'boxes': tensor([[0.4087, 0.0938, 0.9976, 0.9976],\n",
       "           [0.0000, 0.0000, 0.6895, 0.6432]]),\n",
       "   'labels': tensor([8, 8])}],\n",
       " [tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       "  {'boxes': tensor([[0.1514, 0.0055, 0.7564, 0.9382]]),\n",
       "   'labels': tensor([3])}],\n",
       " [tensor([[[0.0235, 0.4980, 0.3333,  ..., 0.2588, 0.0510, 0.0275],\n",
       "           [0.3333, 0.2353, 0.3843,  ..., 0.1922, 0.0235, 0.0510],\n",
       "           [0.4078, 0.1843, 0.4196,  ..., 0.0627, 0.0039, 0.0706],\n",
       "           ...,\n",
       "           [0.8980, 0.8980, 0.8980,  ..., 0.9098, 0.8745, 0.8745],\n",
       "           [0.9020, 0.8941, 0.8980,  ..., 0.9294, 0.8824, 0.8824],\n",
       "           [0.8980, 0.8902, 0.8902,  ..., 0.9020, 0.8667, 0.8941]],\n",
       "  \n",
       "          [[0.0902, 0.5882, 0.4235,  ..., 0.3176, 0.0863, 0.0471],\n",
       "           [0.4157, 0.3333, 0.4824,  ..., 0.2471, 0.0627, 0.0706],\n",
       "           [0.4941, 0.2824, 0.5255,  ..., 0.1176, 0.0431, 0.0902],\n",
       "           ...,\n",
       "           [0.7882, 0.7882, 0.8000,  ..., 0.8471, 0.8078, 0.8078],\n",
       "           [0.7961, 0.7922, 0.7961,  ..., 0.8667, 0.8196, 0.8196],\n",
       "           [0.7961, 0.7922, 0.7922,  ..., 0.8392, 0.8118, 0.8353]],\n",
       "  \n",
       "          [[0.0078, 0.3137, 0.0902,  ..., 0.1725, 0.0275, 0.0549],\n",
       "           [0.1765, 0.0510, 0.1137,  ..., 0.1294, 0.0118, 0.0824],\n",
       "           [0.2471, 0.0078, 0.1490,  ..., 0.0118, 0.0039, 0.1059],\n",
       "           ...,\n",
       "           [0.6314, 0.6314, 0.6392,  ..., 0.7176, 0.6902, 0.6902],\n",
       "           [0.6392, 0.6314, 0.6392,  ..., 0.7412, 0.6980, 0.6980],\n",
       "           [0.6510, 0.6431, 0.6353,  ..., 0.7137, 0.6863, 0.7137]]]),\n",
       "  {'boxes': tensor([[0.1877, 0.1156, 0.8111, 0.8441]]),\n",
       "   'labels': tensor([2])}],\n",
       " [tensor([[[0.0863, 0.0667, 0.1647,  ..., 0.0392, 0.4000, 0.3373],\n",
       "           [0.0667, 0.0941, 0.1059,  ..., 0.2353, 0.1804, 0.3686],\n",
       "           [0.1216, 0.0941, 0.4627,  ..., 0.3647, 0.3882, 0.3059],\n",
       "           ...,\n",
       "           [0.7922, 0.7961, 0.8000,  ..., 0.8078, 0.8039, 0.8000],\n",
       "           [0.7882, 0.7882, 0.7922,  ..., 0.7922, 0.7922, 0.7961],\n",
       "           [0.7843, 0.7843, 0.7922,  ..., 0.7882, 0.7843, 0.7725]],\n",
       "  \n",
       "          [[0.1451, 0.1333, 0.2745,  ..., 0.1255, 0.4980, 0.4235],\n",
       "           [0.1373, 0.1725, 0.2157,  ..., 0.3216, 0.2784, 0.4706],\n",
       "           [0.2039, 0.1804, 0.5725,  ..., 0.4667, 0.5020, 0.4196],\n",
       "           ...,\n",
       "           [0.7490, 0.7529, 0.7569,  ..., 0.7333, 0.7294, 0.7255],\n",
       "           [0.7451, 0.7451, 0.7490,  ..., 0.7216, 0.7216, 0.7255],\n",
       "           [0.7412, 0.7412, 0.7490,  ..., 0.7255, 0.7216, 0.7098]],\n",
       "  \n",
       "          [[0.0510, 0.0078, 0.0078,  ..., 0.0000, 0.2275, 0.2314],\n",
       "           [0.0196, 0.0235, 0.0000,  ..., 0.0980, 0.0275, 0.2196],\n",
       "           [0.0392, 0.0157, 0.2275,  ..., 0.1843, 0.1882, 0.0980],\n",
       "           ...,\n",
       "           [0.6235, 0.6275, 0.6314,  ..., 0.6157, 0.6118, 0.6078],\n",
       "           [0.6196, 0.6196, 0.6235,  ..., 0.5922, 0.5922, 0.5961],\n",
       "           [0.6157, 0.6157, 0.6235,  ..., 0.5882, 0.5843, 0.5725]]]),\n",
       "  {'boxes': tensor([[0.2355, 0.1701, 0.8360, 0.8328]]),\n",
       "   'labels': tensor([2])}],\n",
       " [tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.1412, 0.1176, 0.1569,  ..., 0.2000, 0.2275, 0.2000],\n",
       "           [0.2157, 0.2314, 0.2118,  ..., 0.1804, 0.1569, 0.1490],\n",
       "           [0.1725, 0.1451, 0.1294,  ..., 0.2275, 0.2824, 0.2588]],\n",
       "  \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.1059, 0.0863, 0.1216,  ..., 0.1451, 0.1765, 0.1490],\n",
       "           [0.1490, 0.1647, 0.1529,  ..., 0.1020, 0.0745, 0.0667],\n",
       "           [0.1216, 0.0941, 0.0863,  ..., 0.1412, 0.1765, 0.1412]],\n",
       "  \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0549, 0.0353, 0.0627,  ..., 0.1020, 0.1255, 0.1059],\n",
       "           [0.0706, 0.0902, 0.0784,  ..., 0.0353, 0.0078, 0.0039],\n",
       "           [0.0627, 0.0353, 0.0353,  ..., 0.0549, 0.0863, 0.0353]]]),\n",
       "  {'boxes': tensor([[0.1138, 0.4825, 0.3619, 0.7308],\n",
       "           [0.7188, 0.4625, 0.8269, 0.6983]]),\n",
       "   'labels': tensor([4, 4])}],\n",
       " [tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]]),\n",
       "  {'boxes': tensor([[0.0020, 0.0115, 0.5700, 0.9848]]),\n",
       "   'labels': tensor([2])}],\n",
       " [tensor([[[0.0627, 0.0745, 0.0902,  ..., 0.2039, 0.1922, 0.1882],\n",
       "           [0.0667, 0.0745, 0.0902,  ..., 0.2039, 0.1961, 0.1882],\n",
       "           [0.0706, 0.0745, 0.0863,  ..., 0.2078, 0.1961, 0.1922],\n",
       "           ...,\n",
       "           [0.6118, 0.6471, 0.6784,  ..., 0.3333, 0.3255, 0.3176],\n",
       "           [0.5647, 0.5765, 0.6000,  ..., 0.3373, 0.3333, 0.3333],\n",
       "           [0.5647, 0.5608, 0.5765,  ..., 0.3373, 0.3294, 0.3255]],\n",
       "  \n",
       "          [[0.0275, 0.0353, 0.0471,  ..., 0.1451, 0.1333, 0.1294],\n",
       "           [0.0275, 0.0353, 0.0510,  ..., 0.1451, 0.1373, 0.1294],\n",
       "           [0.0314, 0.0353, 0.0471,  ..., 0.1490, 0.1373, 0.1333],\n",
       "           ...,\n",
       "           [0.5373, 0.5725, 0.6039,  ..., 0.2941, 0.2863, 0.2824],\n",
       "           [0.4902, 0.5020, 0.5255,  ..., 0.3020, 0.2980, 0.2980],\n",
       "           [0.4902, 0.4863, 0.5020,  ..., 0.3020, 0.2941, 0.2902]],\n",
       "  \n",
       "          [[0.0000, 0.0000, 0.0118,  ..., 0.1333, 0.1216, 0.1176],\n",
       "           [0.0000, 0.0039, 0.0118,  ..., 0.1333, 0.1255, 0.1176],\n",
       "           [0.0000, 0.0000, 0.0078,  ..., 0.1373, 0.1255, 0.1216],\n",
       "           ...,\n",
       "           [0.4824, 0.5176, 0.5490,  ..., 0.2706, 0.2627, 0.2549],\n",
       "           [0.4353, 0.4471, 0.4706,  ..., 0.2745, 0.2667, 0.2706],\n",
       "           [0.4353, 0.4314, 0.4471,  ..., 0.2784, 0.2667, 0.2627]]]),\n",
       "  {'boxes': tensor([[0.1897, 0.0266, 0.8241, 0.9613]]),\n",
       "   'labels': tensor([5])}],\n",
       " [tensor([[[0.1255, 0.1294, 0.1020,  ..., 0.1843, 0.1882, 0.1804],\n",
       "           [0.1333, 0.1373, 0.1098,  ..., 0.1882, 0.1961, 0.1882],\n",
       "           [0.1412, 0.1451, 0.1176,  ..., 0.1922, 0.2000, 0.1922],\n",
       "           ...,\n",
       "           [0.1137, 0.1216, 0.1490,  ..., 0.2196, 0.2078, 0.2353],\n",
       "           [0.1333, 0.1333, 0.1608,  ..., 0.1922, 0.1882, 0.2118],\n",
       "           [0.1333, 0.1333, 0.1569,  ..., 0.1804, 0.1569, 0.1843]],\n",
       "  \n",
       "          [[0.0745, 0.0745, 0.0471,  ..., 0.1098, 0.1059, 0.0980],\n",
       "           [0.0824, 0.0824, 0.0549,  ..., 0.1098, 0.1137, 0.1059],\n",
       "           [0.0902, 0.0902, 0.0627,  ..., 0.1137, 0.1176, 0.1098],\n",
       "           ...,\n",
       "           [0.0588, 0.0667, 0.0941,  ..., 0.1647, 0.1569, 0.1843],\n",
       "           [0.0784, 0.0784, 0.1059,  ..., 0.1373, 0.1373, 0.1608],\n",
       "           [0.0784, 0.0784, 0.1020,  ..., 0.1255, 0.1059, 0.1333]],\n",
       "  \n",
       "          [[0.0392, 0.0314, 0.0039,  ..., 0.0275, 0.0392, 0.0314],\n",
       "           [0.0510, 0.0392, 0.0118,  ..., 0.0314, 0.0471, 0.0392],\n",
       "           [0.0588, 0.0471, 0.0196,  ..., 0.0353, 0.0510, 0.0431],\n",
       "           ...,\n",
       "           [0.0118, 0.0157, 0.0431,  ..., 0.0941, 0.0824, 0.1098],\n",
       "           [0.0275, 0.0275, 0.0549,  ..., 0.0667, 0.0627, 0.0863],\n",
       "           [0.0275, 0.0275, 0.0510,  ..., 0.0549, 0.0314, 0.0588]]]),\n",
       "  {'boxes': tensor([[0.2020, 0.0211, 0.5580, 0.9759]]),\n",
       "   'labels': tensor([1])}],\n",
       " [tensor([[[0.2431, 0.2471, 0.2471,  ..., 0.8706, 0.8824, 0.8745],\n",
       "           [0.2471, 0.2471, 0.2431,  ..., 0.8588, 0.8667, 0.8431],\n",
       "           [0.2431, 0.2431, 0.2431,  ..., 0.8000, 0.8196, 0.8039],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.4549, 0.4471, 0.4549],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.4118, 0.4039, 0.4157],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.2078, 0.1294, 0.0588]],\n",
       "  \n",
       "          [[0.2824, 0.2863, 0.2863,  ..., 0.5137, 0.5569, 0.5843],\n",
       "           [0.2863, 0.2863, 0.2863,  ..., 0.5059, 0.5529, 0.5608],\n",
       "           [0.2863, 0.2863, 0.2863,  ..., 0.4549, 0.5059, 0.5137],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.2863, 0.2941, 0.3098],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.2627, 0.2863, 0.3059],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.1412, 0.0941, 0.0353]],\n",
       "  \n",
       "          [[0.2784, 0.2824, 0.2824,  ..., 0.3216, 0.3529, 0.3804],\n",
       "           [0.2824, 0.2824, 0.2706,  ..., 0.3098, 0.3373, 0.3412],\n",
       "           [0.2706, 0.2706, 0.2706,  ..., 0.2745, 0.3098, 0.3137],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.3373, 0.3412, 0.3529],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.3098, 0.3216, 0.3412],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.1608, 0.1020, 0.0431]]]),\n",
       "  {'boxes': tensor([[0.0000, 0.0000, 0.9933, 1.0000]]),\n",
       "   'labels': tensor([6])}],\n",
       " [tensor([[[0.6745, 0.6706, 0.6745,  ..., 0.6314, 0.6353, 0.6549],\n",
       "           [0.6863, 0.6824, 0.6863,  ..., 0.7176, 0.7059, 0.6902],\n",
       "           [0.6980, 0.6941, 0.6980,  ..., 0.7451, 0.7216, 0.6902],\n",
       "           ...,\n",
       "           [0.7451, 0.7569, 0.7608,  ..., 0.8510, 0.8549, 0.8588],\n",
       "           [0.7216, 0.7373, 0.7490,  ..., 0.8667, 0.8824, 0.8902],\n",
       "           [0.6784, 0.6980, 0.7098,  ..., 0.8627, 0.8471, 0.8314]],\n",
       "  \n",
       "          [[0.5373, 0.5333, 0.5373,  ..., 0.4392, 0.4431, 0.4627],\n",
       "           [0.5490, 0.5451, 0.5490,  ..., 0.5255, 0.5176, 0.4980],\n",
       "           [0.5608, 0.5569, 0.5608,  ..., 0.5529, 0.5294, 0.4941],\n",
       "           ...,\n",
       "           [0.6314, 0.6431, 0.6471,  ..., 0.6980, 0.7020, 0.7059],\n",
       "           [0.6078, 0.6235, 0.6353,  ..., 0.7137, 0.7294, 0.7373],\n",
       "           [0.5647, 0.5843, 0.5961,  ..., 0.7098, 0.6941, 0.6784]],\n",
       "  \n",
       "          [[0.3176, 0.3137, 0.3176,  ..., 0.2039, 0.2118, 0.2314],\n",
       "           [0.3333, 0.3255, 0.3294,  ..., 0.2941, 0.2824, 0.2667],\n",
       "           [0.3412, 0.3373, 0.3412,  ..., 0.3216, 0.2980, 0.2627],\n",
       "           ...,\n",
       "           [0.4039, 0.4157, 0.4196,  ..., 0.4824, 0.4863, 0.4902],\n",
       "           [0.3804, 0.3961, 0.4078,  ..., 0.4980, 0.5137, 0.5216],\n",
       "           [0.3373, 0.3569, 0.3686,  ..., 0.4941, 0.4784, 0.4627]]]),\n",
       "  {'boxes': tensor([[0.1442, 0.4411, 0.7933, 0.7728],\n",
       "           [0.1917, 0.1082, 0.7314, 0.4038]]),\n",
       "   'labels': tensor([7, 7])}],\n",
       " [tensor([[[0.2471, 0.2471, 0.2471,  ..., 0.2745, 0.2392, 0.0157],\n",
       "           [0.2510, 0.2549, 0.2549,  ..., 0.2902, 0.2549, 0.0157],\n",
       "           [0.2275, 0.2314, 0.2314,  ..., 0.3059, 0.2431, 0.0157],\n",
       "           ...,\n",
       "           [0.0196, 0.0196, 0.0196,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0118, 0.0118, 0.0118,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "          [[0.2510, 0.2510, 0.2510,  ..., 0.3059, 0.2706, 0.0353],\n",
       "           [0.2510, 0.2549, 0.2549,  ..., 0.3216, 0.2863, 0.0392],\n",
       "           [0.2235, 0.2275, 0.2275,  ..., 0.3333, 0.2784, 0.0157],\n",
       "           ...,\n",
       "           [0.0549, 0.0588, 0.0588,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0431, 0.0431, 0.0431,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0078, 0.0118, 0.0118,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "          [[0.2706, 0.2706, 0.2706,  ..., 0.3490, 0.3137, 0.0784],\n",
       "           [0.2706, 0.2745, 0.2745,  ..., 0.3647, 0.3294, 0.0824],\n",
       "           [0.2431, 0.2471, 0.2471,  ..., 0.3804, 0.3216, 0.0627],\n",
       "           ...,\n",
       "           [0.1490, 0.1529, 0.1490,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.1176, 0.1176, 0.1098,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0588, 0.0588, 0.0549,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
       "  {'boxes': tensor([[0.5392, 0.0177, 0.9793, 0.4066],\n",
       "           [0.2309, 0.0386, 0.4710, 0.1981]]),\n",
       "   'labels': tensor([8, 8])}],\n",
       " [tensor([[[0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "           [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "           [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "           ...,\n",
       "           [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "           [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "           [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000]],\n",
       "  \n",
       "          [[0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "           [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "           [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "           ...,\n",
       "           [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "           [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "           [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000]],\n",
       "  \n",
       "          [[0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "           [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "           [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "           ...,\n",
       "           [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "           [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000],\n",
       "           [0.4000, 0.4000, 0.4000,  ..., 0.4000, 0.4000, 0.4000]]]),\n",
       "  {'boxes': tensor([[0.0487, 0.0180, 0.9657, 0.9507]]),\n",
       "   'labels': tensor([2])}],\n",
       " [tensor([[[0.0000, 0.0157, 0.0706,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           [0.2549, 0.3608, 0.4941,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           [0.7137, 0.7490, 0.7686,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           ...,\n",
       "           [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078]],\n",
       "  \n",
       "          [[0.0000, 0.0196, 0.0745,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           [0.2588, 0.3765, 0.5020,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           [0.7216, 0.7647, 0.7961,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           ...,\n",
       "           [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078]],\n",
       "  \n",
       "          [[0.0000, 0.0235, 0.0902,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           [0.2941, 0.4157, 0.5490,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           [0.7961, 0.8392, 0.8667,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           ...,\n",
       "           [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078]]]),\n",
       "  {'boxes': tensor([[0.0921, 0.0685, 0.7523, 0.9626]]),\n",
       "   'labels': tensor([2])}],\n",
       " [tensor([[[0.5647, 0.4157, 0.6118,  ..., 0.1098, 0.1922, 0.1647],\n",
       "           [0.4000, 0.2941, 0.5843,  ..., 0.2235, 0.2353, 0.2824],\n",
       "           [0.5451, 0.8078, 0.6941,  ..., 0.1569, 0.2980, 0.1961],\n",
       "           ...,\n",
       "           [1.0000, 0.8745, 1.0000,  ..., 0.8706, 0.8941, 1.0000],\n",
       "           [0.9686, 0.9529, 0.9804,  ..., 0.9137, 0.7882, 0.8196],\n",
       "           [0.9608, 0.9137, 0.8157,  ..., 0.8118, 0.8745, 1.0000]],\n",
       "  \n",
       "          [[0.7294, 0.4745, 0.8431,  ..., 0.1569, 0.2471, 0.2510],\n",
       "           [0.5686, 0.4510, 0.6706,  ..., 0.1922, 0.2314, 0.3451],\n",
       "           [0.6745, 0.8353, 0.7373,  ..., 0.1176, 0.1333, 0.2157],\n",
       "           ...,\n",
       "           [0.9843, 0.8000, 0.9686,  ..., 0.8157, 0.8784, 0.9961],\n",
       "           [0.9608, 0.8863, 0.9529,  ..., 0.8118, 0.7922, 0.7333],\n",
       "           [0.9725, 0.8510, 0.7725,  ..., 0.8588, 0.8824, 0.9529]],\n",
       "  \n",
       "          [[0.2784, 0.2588, 0.4863,  ..., 0.1647, 0.2118, 0.2588],\n",
       "           [0.2039, 0.2118, 0.4353,  ..., 0.2275, 0.1843, 0.2980],\n",
       "           [0.4196, 0.5569, 0.5608,  ..., 0.1451, 0.2314, 0.1529],\n",
       "           ...,\n",
       "           [0.9255, 0.8078, 0.9216,  ..., 0.7765, 0.7922, 0.9725],\n",
       "           [0.8392, 0.8863, 0.8667,  ..., 0.8275, 0.8118, 0.6706],\n",
       "           [0.8510, 0.8706, 0.6941,  ..., 0.7843, 0.8588, 0.8667]]]),\n",
       "  {'boxes': tensor([[0.2490, 0.1359, 0.6867, 0.8441]]),\n",
       "   'labels': tensor([2])}],\n",
       " [tensor([[[0.8784, 0.8510, 0.8745,  ..., 0.8510, 0.8510, 0.8510],\n",
       "           [0.8627, 0.8980, 0.8706,  ..., 0.8510, 0.8510, 0.8510],\n",
       "           [0.8667, 0.9216, 0.8745,  ..., 0.8510, 0.8510, 0.8510],\n",
       "           ...,\n",
       "           [0.7098, 0.7922, 0.6667,  ..., 0.8510, 0.8510, 0.8510],\n",
       "           [0.7255, 0.8196, 0.7059,  ..., 0.8510, 0.8510, 0.8510],\n",
       "           [0.7294, 0.7490, 0.7098,  ..., 0.8510, 0.8510, 0.8510]],\n",
       "  \n",
       "          [[0.7412, 0.7020, 0.7137,  ..., 0.8510, 0.8510, 0.8510],\n",
       "           [0.7255, 0.7490, 0.7098,  ..., 0.8510, 0.8510, 0.8510],\n",
       "           [0.7176, 0.7686, 0.7216,  ..., 0.8510, 0.8510, 0.8510],\n",
       "           ...,\n",
       "           [0.5843, 0.6784, 0.5333,  ..., 0.8510, 0.8510, 0.8510],\n",
       "           [0.5961, 0.7020, 0.5765,  ..., 0.8510, 0.8510, 0.8510],\n",
       "           [0.6000, 0.6353, 0.5804,  ..., 0.8510, 0.8510, 0.8510]],\n",
       "  \n",
       "          [[0.5922, 0.5490, 0.5647,  ..., 0.8510, 0.8510, 0.8510],\n",
       "           [0.5765, 0.5961, 0.5569,  ..., 0.8510, 0.8510, 0.8510],\n",
       "           [0.5725, 0.6118, 0.5686,  ..., 0.8510, 0.8510, 0.8510],\n",
       "           ...,\n",
       "           [0.4588, 0.5373, 0.3843,  ..., 0.8510, 0.8510, 0.8510],\n",
       "           [0.4745, 0.5608, 0.4275,  ..., 0.8510, 0.8510, 0.8510],\n",
       "           [0.4745, 0.4941, 0.4314,  ..., 0.8510, 0.8510, 0.8510]]]),\n",
       "  {'boxes': tensor([[0.0200, 0.0036, 0.9286, 0.9618]]),\n",
       "   'labels': tensor([5])}],\n",
       " [tensor([[[0.3255, 0.2510, 0.3725,  ..., 0.1686, 0.2196, 0.3647],\n",
       "           [0.2980, 0.3725, 0.1804,  ..., 0.2078, 0.3608, 0.2902],\n",
       "           [0.4039, 0.2980, 0.3098,  ..., 0.2784, 0.3059, 0.2431],\n",
       "           ...,\n",
       "           [0.2196, 0.3059, 0.3686,  ..., 0.3255, 0.3804, 0.3137],\n",
       "           [0.4235, 0.3412, 0.0784,  ..., 0.3333, 0.5608, 0.5569],\n",
       "           [0.2471, 0.4000, 0.2039,  ..., 0.3725, 0.4824, 0.4235]],\n",
       "  \n",
       "          [[0.3333, 0.1529, 0.2745,  ..., 0.3216, 0.2314, 0.3922],\n",
       "           [0.3647, 0.4235, 0.1961,  ..., 0.3137, 0.4745, 0.2235],\n",
       "           [0.3843, 0.3725, 0.3490,  ..., 0.2706, 0.2157, 0.2000],\n",
       "           ...,\n",
       "           [0.2353, 0.3216, 0.5294,  ..., 0.5882, 0.5373, 0.3569],\n",
       "           [0.4078, 0.3961, 0.1804,  ..., 0.7412, 0.7451, 0.7333],\n",
       "           [0.2392, 0.2941, 0.1333,  ..., 0.6627, 0.6667, 0.5176]],\n",
       "  \n",
       "          [[0.3961, 0.1961, 0.3490,  ..., 0.2235, 0.2588, 0.3490],\n",
       "           [0.2863, 0.3373, 0.2314,  ..., 0.2667, 0.4588, 0.3333],\n",
       "           [0.3059, 0.2627, 0.3608,  ..., 0.2392, 0.1961, 0.3490],\n",
       "           ...,\n",
       "           [0.1294, 0.3412, 0.3569,  ..., 0.9412, 0.9451, 0.8118],\n",
       "           [0.1922, 0.4392, 0.1882,  ..., 0.9922, 0.9569, 1.0000],\n",
       "           [0.2980, 0.4235, 0.2706,  ..., 0.9961, 0.9333, 0.9412]]]),\n",
       "  {'boxes': tensor([[0.0000, 0.0367, 1.0000, 1.0000]]),\n",
       "   'labels': tensor([3])}],\n",
       " [tensor([[[0.3412, 0.3529, 0.3412,  ..., 0.2039, 0.2078, 0.2078],\n",
       "           [0.2863, 0.3373, 0.3373,  ..., 0.2392, 0.2667, 0.2667],\n",
       "           [0.2745, 0.3255, 0.3490,  ..., 0.2549, 0.2471, 0.2078],\n",
       "           ...,\n",
       "           [0.1020, 0.1098, 0.1020,  ..., 0.2196, 0.1882, 0.2824],\n",
       "           [0.1216, 0.1216, 0.1098,  ..., 0.3647, 0.2863, 0.2431],\n",
       "           [0.1137, 0.0980, 0.1137,  ..., 0.3412, 0.3294, 0.3333]],\n",
       "  \n",
       "          [[0.3294, 0.3451, 0.3333,  ..., 0.1569, 0.1608, 0.1647],\n",
       "           [0.2863, 0.3294, 0.3412,  ..., 0.1961, 0.2196, 0.2157],\n",
       "           [0.2667, 0.3176, 0.3412,  ..., 0.2118, 0.1961, 0.1647],\n",
       "           ...,\n",
       "           [0.1020, 0.0980, 0.0902,  ..., 0.1647, 0.1412, 0.2353],\n",
       "           [0.1098, 0.1059, 0.0980,  ..., 0.2706, 0.2157, 0.1843],\n",
       "           [0.1137, 0.0980, 0.1020,  ..., 0.2667, 0.2588, 0.2706]],\n",
       "  \n",
       "          [[0.1373, 0.1529, 0.1451,  ..., 0.0941, 0.0941, 0.0980],\n",
       "           [0.1098, 0.1412, 0.1412,  ..., 0.1137, 0.1176, 0.1176],\n",
       "           [0.1059, 0.1412, 0.1529,  ..., 0.1216, 0.1176, 0.0941],\n",
       "           ...,\n",
       "           [0.0706, 0.0706, 0.0627,  ..., 0.0745, 0.0471, 0.1176],\n",
       "           [0.0784, 0.0784, 0.0706,  ..., 0.1294, 0.1059, 0.0824],\n",
       "           [0.0784, 0.0667, 0.0745,  ..., 0.1373, 0.1333, 0.1412]]]),\n",
       "  {'boxes': tensor([[0.0000, 0.0000, 0.9991, 0.8400]]),\n",
       "   'labels': tensor([8])}],\n",
       " [tensor([[[0.8667, 0.8902, 0.8392,  ..., 0.0196, 0.0118, 0.0314],\n",
       "           [0.8706, 0.8627, 0.8745,  ..., 0.0157, 0.0275, 0.0353],\n",
       "           [0.8902, 0.8745, 0.8902,  ..., 0.0118, 0.0039, 0.0824],\n",
       "           ...,\n",
       "           [0.2000, 0.2471, 0.2118,  ..., 0.8588, 0.4314, 0.5451],\n",
       "           [0.1255, 0.1451, 0.1843,  ..., 0.6627, 0.7686, 0.8157],\n",
       "           [0.1647, 0.1961, 0.1529,  ..., 0.2667, 0.6941, 0.6706]],\n",
       "  \n",
       "          [[0.8627, 0.8863, 0.8353,  ..., 0.0431, 0.0275, 0.0392],\n",
       "           [0.8667, 0.8588, 0.8706,  ..., 0.0471, 0.0588, 0.0627],\n",
       "           [0.8863, 0.8706, 0.8863,  ..., 0.0431, 0.0353, 0.1020],\n",
       "           ...,\n",
       "           [0.1373, 0.1804, 0.1373,  ..., 0.7137, 0.3294, 0.4863],\n",
       "           [0.0863, 0.0863, 0.1373,  ..., 0.5451, 0.6588, 0.7176],\n",
       "           [0.1137, 0.1412, 0.0980,  ..., 0.1843, 0.6157, 0.5922]],\n",
       "  \n",
       "          [[0.8941, 0.9098, 0.8549,  ..., 0.0588, 0.0471, 0.0588],\n",
       "           [0.8980, 0.8824, 0.8902,  ..., 0.0588, 0.0706, 0.0745],\n",
       "           [0.9176, 0.8941, 0.9059,  ..., 0.0549, 0.0471, 0.1176],\n",
       "           ...,\n",
       "           [0.0745, 0.1412, 0.1098,  ..., 0.4863, 0.1843, 0.3725],\n",
       "           [0.0392, 0.0627, 0.1098,  ..., 0.2510, 0.5020, 0.6000],\n",
       "           [0.0431, 0.1059, 0.0627,  ..., 0.0275, 0.3765, 0.4588]]]),\n",
       "  {'boxes': tensor([[0.1475, 0.2108, 0.5190, 0.8545],\n",
       "           [0.5215, 0.1290, 0.7445, 0.8515],\n",
       "           [0.7680, 0.0780, 0.9320, 0.7892]]),\n",
       "   'labels': tensor([2, 2, 2])}],\n",
       " [tensor([[[0.2353, 0.2078, 0.1961,  ..., 0.3020, 0.2980, 0.2980],\n",
       "           [0.2275, 0.2431, 0.2235,  ..., 0.2824, 0.2902, 0.3137],\n",
       "           [0.2235, 0.2157, 0.2353,  ..., 0.2902, 0.2706, 0.2667],\n",
       "           ...,\n",
       "           [0.8000, 0.7843, 0.7882,  ..., 0.2980, 0.2980, 0.3294],\n",
       "           [0.8039, 0.7843, 0.7843,  ..., 0.3294, 0.3176, 0.2667],\n",
       "           [0.8039, 0.7922, 0.7882,  ..., 0.3373, 0.3294, 0.3020]],\n",
       "  \n",
       "          [[0.2471, 0.2196, 0.2157,  ..., 0.3412, 0.3333, 0.3333],\n",
       "           [0.2431, 0.2588, 0.2431,  ..., 0.3216, 0.3255, 0.3490],\n",
       "           [0.2431, 0.2353, 0.2549,  ..., 0.3333, 0.3059, 0.3020],\n",
       "           ...,\n",
       "           [0.7922, 0.7922, 0.7961,  ..., 0.2275, 0.2392, 0.2667],\n",
       "           [0.7961, 0.7922, 0.7922,  ..., 0.2588, 0.2549, 0.2000],\n",
       "           [0.7961, 0.8000, 0.7961,  ..., 0.2667, 0.2627, 0.2314]],\n",
       "  \n",
       "          [[0.2745, 0.2471, 0.2392,  ..., 0.3373, 0.3294, 0.3294],\n",
       "           [0.2667, 0.2824, 0.2667,  ..., 0.3176, 0.3176, 0.3451],\n",
       "           [0.2667, 0.2588, 0.2784,  ..., 0.3176, 0.2941, 0.2902],\n",
       "           ...,\n",
       "           [0.7451, 0.7412, 0.7451,  ..., 0.3137, 0.3216, 0.3686],\n",
       "           [0.7490, 0.7412, 0.7412,  ..., 0.3451, 0.3294, 0.2941],\n",
       "           [0.7490, 0.7490, 0.7451,  ..., 0.3529, 0.3373, 0.3176]]]),\n",
       "  {'boxes': tensor([[0.3188, 0.2343, 1.0000, 1.0000]]),\n",
       "   'labels': tensor([2])}],\n",
       " [tensor([[[0.0706, 0.0667, 0.0588,  ..., 0.0824, 0.0902, 0.0863],\n",
       "           [0.0667, 0.0627, 0.0627,  ..., 0.0980, 0.0941, 0.0863],\n",
       "           [0.0627, 0.0627, 0.0706,  ..., 0.1059, 0.0980, 0.0863],\n",
       "           ...,\n",
       "           [1.0000, 0.9922, 0.8471,  ..., 0.0667, 0.0667, 0.0745],\n",
       "           [0.8863, 0.8353, 0.5216,  ..., 0.0667, 0.0706, 0.0627],\n",
       "           [0.8588, 0.5804, 0.3490,  ..., 0.0706, 0.0706, 0.0588]],\n",
       "  \n",
       "          [[0.0706, 0.0667, 0.0588,  ..., 0.0784, 0.0863, 0.0824],\n",
       "           [0.0667, 0.0627, 0.0627,  ..., 0.0941, 0.0902, 0.0824],\n",
       "           [0.0627, 0.0627, 0.0706,  ..., 0.1020, 0.0941, 0.0824],\n",
       "           ...,\n",
       "           [0.8235, 0.7765, 0.6392,  ..., 0.0706, 0.0667, 0.0588],\n",
       "           [0.7412, 0.6706, 0.3529,  ..., 0.0745, 0.0745, 0.0627],\n",
       "           [0.7529, 0.4510, 0.2118,  ..., 0.0824, 0.0784, 0.0588]],\n",
       "  \n",
       "          [[0.0627, 0.0588, 0.0510,  ..., 0.0627, 0.0706, 0.0627],\n",
       "           [0.0588, 0.0549, 0.0549,  ..., 0.0784, 0.0745, 0.0627],\n",
       "           [0.0549, 0.0549, 0.0627,  ..., 0.0863, 0.0784, 0.0627],\n",
       "           ...,\n",
       "           [0.4706, 0.4784, 0.4275,  ..., 0.0706, 0.0510, 0.0392],\n",
       "           [0.4392, 0.4353, 0.1922,  ..., 0.0549, 0.0431, 0.0235],\n",
       "           [0.5020, 0.2588, 0.1020,  ..., 0.0549, 0.0392, 0.0078]]]),\n",
       "  {'boxes': tensor([[0.0250, 0.2766, 0.8438, 0.9984],\n",
       "           [0.2016, 0.1750, 0.5203, 0.5750]]),\n",
       "   'labels': tensor([9, 9])}],\n",
       " [tensor([[[0.9451, 0.9686, 0.8118,  ..., 0.9176, 0.9412, 0.8824],\n",
       "           [0.8667, 0.9725, 0.8510,  ..., 0.6824, 0.8314, 0.9020],\n",
       "           [0.9569, 0.8627, 0.9569,  ..., 0.8588, 0.9216, 0.8902],\n",
       "           ...,\n",
       "           [0.7451, 0.7961, 0.8039,  ..., 0.9647, 0.8980, 0.8078],\n",
       "           [0.8431, 0.9137, 1.0000,  ..., 0.9098, 0.8314, 0.8157],\n",
       "           [0.9020, 0.7686, 0.9725,  ..., 0.8745, 0.9216, 0.9294]],\n",
       "  \n",
       "          [[0.9569, 0.9255, 0.7843,  ..., 0.8314, 0.9412, 0.9412],\n",
       "           [0.8667, 0.9216, 0.8157,  ..., 0.5765, 0.8275, 0.9412],\n",
       "           [0.9255, 0.7922, 0.9412,  ..., 0.7451, 0.9216, 0.8784],\n",
       "           ...,\n",
       "           [0.6275, 0.8078, 0.6863,  ..., 0.9373, 0.7922, 0.8353],\n",
       "           [0.7451, 0.9216, 0.9137,  ..., 0.9176, 0.7647, 0.8941],\n",
       "           [0.8118, 0.7765, 0.9216,  ..., 0.9059, 0.8706, 1.0000]],\n",
       "  \n",
       "          [[0.7922, 0.8039, 0.6980,  ..., 0.8157, 0.8863, 0.9059],\n",
       "           [0.7137, 0.8235, 0.7216,  ..., 0.5608, 0.7725, 0.9176],\n",
       "           [0.8078, 0.7373, 0.8118,  ..., 0.7490, 0.8667, 0.8706],\n",
       "           ...,\n",
       "           [0.5608, 0.7490, 0.6431,  ..., 0.8118, 0.8118, 0.8627],\n",
       "           [0.7098, 0.8667, 0.8863,  ..., 0.7647, 0.8039, 0.8706],\n",
       "           [0.7843, 0.7255, 0.9020,  ..., 0.7451, 0.9176, 0.9804]]]),\n",
       "  {'boxes': tensor([[0.0193, 0.1080, 0.9297, 0.8280]]),\n",
       "   'labels': tensor([10])}],\n",
       " [tensor([[[0.5490, 0.4980, 0.4863,  ..., 0.4275, 0.4000, 0.4510],\n",
       "           [0.5647, 0.5294, 0.5059,  ..., 0.4275, 0.4000, 0.4510],\n",
       "           [0.5686, 0.5451, 0.5373,  ..., 0.4235, 0.4039, 0.4510],\n",
       "           ...,\n",
       "           [0.2549, 0.2471, 0.2392,  ..., 0.4510, 0.3882, 0.3804],\n",
       "           [0.2471, 0.2392, 0.2275,  ..., 0.4784, 0.4314, 0.3922],\n",
       "           [0.2431, 0.2353, 0.2314,  ..., 0.4824, 0.4588, 0.4118]],\n",
       "  \n",
       "          [[0.5098, 0.4745, 0.4824,  ..., 0.3882, 0.3804, 0.4235],\n",
       "           [0.5412, 0.5059, 0.5020,  ..., 0.3961, 0.3843, 0.4157],\n",
       "           [0.5647, 0.5412, 0.5333,  ..., 0.3961, 0.3882, 0.4157],\n",
       "           ...,\n",
       "           [0.4157, 0.4039, 0.3961,  ..., 0.5647, 0.5176, 0.4902],\n",
       "           [0.4078, 0.3961, 0.3843,  ..., 0.5882, 0.5569, 0.5137],\n",
       "           [0.4039, 0.3922, 0.3843,  ..., 0.5922, 0.5882, 0.5412]],\n",
       "  \n",
       "          [[0.2000, 0.1529, 0.1333,  ..., 0.1647, 0.1294, 0.1569],\n",
       "           [0.2118, 0.1725, 0.1451,  ..., 0.1529, 0.1333, 0.1529],\n",
       "           [0.2196, 0.1843, 0.1686,  ..., 0.1451, 0.1373, 0.1647],\n",
       "           ...,\n",
       "           [0.0157, 0.0235, 0.0157,  ..., 0.2510, 0.1882, 0.1686],\n",
       "           [0.0078, 0.0157, 0.0078,  ..., 0.2706, 0.2314, 0.2000],\n",
       "           [0.0039, 0.0118, 0.0078,  ..., 0.2667, 0.2588, 0.2314]]]),\n",
       "  {'boxes': tensor([[0.1729, 0.0881, 0.7529, 0.9640]]),\n",
       "   'labels': tensor([4])}]]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/750329849.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31/2174600200.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model_state_dict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/ssd.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                     \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"boxes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                         torch._assert(\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "output = model(img.to(device), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "class SSD_MOBILENET_V3_Large(nn.Module):\n",
    "    def __init__(self, num_classes_with_bg:int) -> None:\n",
    "        super(SSD_MOBILENET_V3_Large, self).__init__()\n",
    "        self.num_classes_with_bg = num_classes_with_bg\n",
    "        self.model = ssdlite320_mobilenet_v3_large(weights='COCO_V1', weights_backbone=\"DEFAULT\") \n",
    "        self.model.head.classification_head = SSDLiteClassificationHead(\n",
    "            in_channels=det_utils.retrieve_out_channels(self.model.backbone, (320, 320)),\n",
    "            num_anchors=self.model.anchor_generator.num_anchors_per_location(),\n",
    "            num_classes=self.num_classes_with_bg,\n",
    "            norm_layer=partial(nn.BatchNorm2d, eps=0.001, momentum=0.03)\n",
    "        )\n",
    "        self.model.detections_per_img = 100\n",
    "    \n",
    "    def configure_optimizers(self, lr: float = 0.0001, betas: Tuple[float, float] = (0.9, 0.999), weight_decay: float = 0.0001, eps: float = 1e-08, fused: bool = True) -> torch.optim.Optimizer:        \n",
    "        # start with all of the candidate parameters (that require grad)\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
    "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
    "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
    "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
    "        decay_params = [p for _, p in param_dict.items() if p.dim() >= 2]\n",
    "        nodecay_params = [p for _, p in param_dict.items() if p.dim() < 2]\n",
    "\n",
    "        # Create AdamW optimizer and use the fused version if available \n",
    "        return torch.optim.AdamW([{'params': decay_params, 'weight_decay': weight_decay},\n",
    "                                    {'params': nodecay_params, 'weight_decay': 0.0}], \n",
    "                                    lr=lr, \n",
    "                                    betas=betas, \n",
    "                                    eps=eps, \n",
    "                                    fused=fused)\n",
    "    \n",
    "    def forward(self, images: torch.Tensor, targets: dict=None):\n",
    "        return self.model(images, targets)\n",
    "    \n",
    "    def load(self, checkpoint_path: dict, key_name: str = \"model_state_dict\", map_location: str = \"cpu\"):\n",
    "        self.load_state_dict(torch.load(checkpoint_path, map_location=map_location)[key_name])\n",
    "    \n",
    "    def evaluate(self, dataset_root: str, device: torch.device|str, batch_size: int = 64):\n",
    "        num_cores = os.cpu_count()\n",
    "        print(f\"Number of CPU cores: {num_cores}\")\n",
    "        \n",
    "        metric = MeanAveragePrecision(\n",
    "        iou_type=\"bbox\",\n",
    "        class_metrics=True,\n",
    "        extended_summary=True)\n",
    "        \n",
    "        train_dataset = SSDLITEOBJDET_DATASET(dataset_root, split='train')\n",
    "        val_dataset = SSDLITEOBJDET_DATASET(dataset_root, split='val')\n",
    "        test_dataset = SSDLITEOBJDET_DATASET(dataset_root, split='test')\n",
    "        \n",
    "        # if device is a string\n",
    "        if isinstance(device, str):\n",
    "            device = device\n",
    "        else:\n",
    "            device = f\"{device.type}:{device.index}\"\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=num_cores, pin_memory=True, pin_memory_device=device)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=num_cores, pin_memory=True, pin_memory_device=device)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=num_cores, pin_memory=True, pin_memory_device=device)\n",
    "        \n",
    "        # splits = ['train', 'val', 'test']\n",
    "        # loaders = [train_loader, val_loader, test_loader]\n",
    "        splits = ['val', 'test']\n",
    "        loaders = [val_loader, test_loader]\n",
    "        results = {}\n",
    "        for split, loader in zip(splits, loaders):\n",
    "            print(f\"Evaluating {split} set\")\n",
    "            self.eval()\n",
    "            metric.reset()\n",
    "            progress_bar = tqdm(loader, desc=f\"Evaluating {split} set\", unit=\"batch\")\n",
    "            with torch.no_grad():\n",
    "                for images, targets in progress_bar:\n",
    "                    images = list(image.to(device) for image in images)\n",
    "                    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "                    outputs = self(images)\n",
    "                    metric.update(outputs, targets)\n",
    "                results[split] =  metric.compute()\n",
    "        return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD_MOBILENET_V3_Large(\n",
       "  (model): SSD(\n",
       "    (backbone): SSDLiteFeatureExtractorMobileNet(\n",
       "      (features): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "                (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "                (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "                (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "                (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (5): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "                (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (6): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "                (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (7): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "                (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (8): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "                (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (9): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "                (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (10): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "                (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (11): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (12): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "                (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (13): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Sequential(\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): ReLU()\n",
       "              (scale_activation): Hardsigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (extra): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2, 3], [2, 3], [2, 3], [2, 3], [2, 3], [2, 3]], clip=True, scales=[0.2, 0.35, 0.5, 0.65, 0.8, 0.95, 1.0], steps=None)\n",
       "    (head): SSDLiteHead(\n",
       "      (classification_head): SSDLiteClassificationHead(\n",
       "        (module_list): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(672, 66, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(480, 66, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(512, 66, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3-4): 2 x Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(256, 66, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(128, 66, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (regression_head): SSDLiteRegressionHead(\n",
       "        (module_list): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(672, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(480, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3-4): 2 x Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(128, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (transform): GeneralizedRCNNTransform(\n",
       "        Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
       "        Resize(min_size=(320,), max_size=320, mode='bilinear')\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SSD_MOBILENET_V3_Large(num_classes_with_bg=MODEL_NUM_CLASSES)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.load(\"ssd_checkpoint/checkpoint_1.pth\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 4\n",
      "Evaluating val set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating val set: 100%|██████████| 22/22 [00:20<00:00,  1.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating test set: 100%|██████████| 22/22 [00:20<00:00,  1.08batch/s]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(DATASET_FOLDER_PATH, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Set device\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    # Load the model\n",
    "    model = SSD_MOBILENET_V3_Large(num_classes_with_bg=MODEL_NUM_CLASSES)\n",
    "    model.to(device)\n",
    "    \n",
    "    train_dataset = SSDLITEOBJDET_DATASET(DATASET_FOLDER_PATH, 'train')\n",
    "    val_dataset = SSDLITEOBJDET_DATASET(DATASET_FOLDER_PATH, 'val')\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn, num_workers=num_cores, pin_memory=True, pin_memory_device=\"cuda:0\")\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn, num_workers=num_cores, pin_memory=True, pin_memory_device=\"cuda:0\")\n",
    "\n",
    "    # Optimizer and scheduler\n",
    "    optimizer = model.configure_optimizers(lr=0.0001, betas=(0.9, 0.999), weight_decay=0.001, eps=1e-08, fused=True)\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        num_batches = len(train_loader)\n",
    "        \n",
    "        # Import tqdm for progress bar\n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        \n",
    "        for _, (images, targets) in enumerate(train_bar):\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_loss = losses.detach().item()\n",
    "            total_loss += batch_loss\n",
    "            \n",
    "            # Update progress bar with current batch loss\n",
    "            train_bar.set_postfix(loss=batch_loss)\n",
    "\n",
    "        avg_loss = total_loss / num_batches\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Avg Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        metric = MeanAveragePrecision()\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images = list(img.to(device) for img in images)\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "                \n",
    "                predictions = model(images)\n",
    "                metric.update(predictions, targets)\n",
    "        \n",
    "        map_result = metric.compute()\n",
    "        print(f\"Epoch {epoch+1} | Val mAP: {map_result['map']:.4f}\")\n",
    "\n",
    "    # Save model\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()}, 'ssd_mobilenet_v3_finetuned.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training function\n",
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        results.append({\n",
    "            'split': split,\n",
    "            **split_metrics,\n",
    "            'time': f\"{elapsed:.1f}s\"\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nCompleted {split} split in {elapsed:.1f} seconds\")\n",
    "        print(f\"Split Metrics - mAP: {split_metrics['mAP']:.4f}, Precision: {split_metrics['Precision']:.4f}\")\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(results).set_index('split')\n",
    "    numeric_cols = ['mAP', 'mAP_50', 'mAP_75', 'mAP_small', 'mAP_medium', \n",
    "                   'mAP_large', 'Recall', 'Precision', 'F1']\n",
    "    df[numeric_cols] = df[numeric_cols].applymap(lambda x: f\"{float(x):.4f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def evaluate_split(model, dataloader, device, metric):\n",
    "    \"\"\"Evaluate with batch-level progress\"\"\"\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    \n",
    "    # Batch progress bar\n",
    "    batch_progress = tqdm(dataloader, \n",
    "                        desc=\"Processing batches\",\n",
    "                        leave=False,\n",
    "                        position=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in batch_progress:\n",
    "            # Move data to device\n",
    "            images = list(img.to(device) for img in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            # Inference\n",
    "            predictions = model(images)\n",
    "            metric.update(predictions, targets)\n",
    "            \n",
    "            # Update progress description\n",
    "            batch_progress.set_postfix({\n",
    "                'current_mAP': f\"{metric.compute()['map'].item():.3f}\",\n",
    "                'batch_size': len(images)\n",
    "            })\n",
    "\n",
    "    # Final metrics\n",
    "    metrics = metric.compute()\n",
    "    \n",
    "    return {\n",
    "        'mAP': metrics['map'].item(),\n",
    "        'mAP_50': metrics['map_50'].item(),\n",
    "        'mAP_75': metrics['map_75'].item(),\n",
    "        'mAP_small': metrics['map_small'].item(),\n",
    "        'mAP_medium': metrics['map_medium'].item(),\n",
    "        'mAP_large': metrics['map_large'].item(),\n",
    "        'Recall': metrics['mar_100'].item(),\n",
    "        'Class_APs': metrics['classes'].cpu().numpy().round(4),\n",
    "        'Precision': metrics['precision'].cpu().numpy().mean().round(4),\n",
    "        'Recall': metrics['recall'].cpu().numpy().mean().round(4),\n",
    "        'F1': (2 * (metrics['precision'] * metrics['recall']) / \n",
    "              (metrics['precision'] + metrics['recall'] + 1e-16)).cpu().numpy().mean().round(4)\n",
    "    }\n",
    "\n",
    "def evaluate():\n",
    "    print(\"\\n🚀 Starting Comprehensive Evaluation\")\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"🔧 Using device: {device}\")\n",
    "    \n",
    "    # Model loading\n",
    "    print(\"\\n🔄 Loading model weights...\")\n",
    "    start_load = time.time()\n",
    "    model = SSD_MOBILENET_V3_Large(num_classes_with_bg=MODEL_NUM_CLASSES)\n",
    "\n",
    "    print(f\"✅ Model loaded in {time.time()-start_load:.1f}s\")\n",
    "    \n",
    "    # Evaluation\n",
    "    print(\"\\n📊 Starting evaluation on all splits...\")\n",
    "    metrics_df = evaluate_model(model, DATASET_FOLDER_PATH, device)\n",
    "    \n",
    "    # Results display\n",
    "    print(\"\\n🎯 Final Metrics Summary:\")\n",
    "    print(metrics_df[['mAP', 'mAP_50', 'mAP_75', 'Recall', 'Precision', 'F1', 'time']])\n",
    "    \n",
    "    print(\"\\n📈 Class-wise Performance:\")\n",
    "    class_df = pd.DataFrame(metrics_df['Class_APs'].tolist(), \n",
    "                          index=metrics_df.index).T\n",
    "    class_df.columns = metrics_df.index\n",
    "    print(class_df.round(4))\n",
    "    \n",
    "    print(\"\\n🏁 Evaluation complete!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
