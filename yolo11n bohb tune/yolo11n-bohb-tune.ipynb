{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0983d65",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-28T18:55:43.321860Z",
     "iopub.status.busy": "2025-03-28T18:55:43.321556Z",
     "iopub.status.idle": "2025-03-28T18:55:52.250752Z",
     "shell.execute_reply": "2025-03-28T18:55:52.249587Z"
    },
    "papermill": {
     "duration": 8.934469,
     "end_time": "2025-03-28T18:55:52.252461",
     "exception": false,
     "start_time": "2025-03-28T18:55:43.317992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.20)\r\n",
      "Collecting albumentations\r\n",
      "  Downloading albumentations-2.0.5-py3-none-any.whl.metadata (41 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting ultralytics\r\n",
      "  Downloading ultralytics-8.3.98-py3-none-any.whl.metadata (37 kB)\r\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.2.1)\r\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.29.0)\r\n",
      "Collecting huggingface_hub\r\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\r\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.11.0a2)\r\n",
      "Collecting albucore==0.0.23 (from albumentations)\r\n",
      "  Downloading albucore-0.0.23-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\r\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.23->albumentations) (3.11.1)\r\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.23->albumentations)\r\n",
      "  Downloading simsimd-6.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (66 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.5)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\r\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.3)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\r\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.1)\r\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.17.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.12.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\r\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->albumentations) (2.4.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (2.29.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24.4->albumentations) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24.4->albumentations) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.4->albumentations) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.24.4->albumentations) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.24.4->albumentations) (2024.2.0)\r\n",
      "Downloading albumentations-2.0.5-py3-none-any.whl (290 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m290.6/290.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading albucore-0.0.23-py3-none-any.whl (14 kB)\r\n",
      "Downloading ultralytics-8.3.98-py3-none-any.whl (949 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m950.0/950.0 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\r\n",
      "Downloading simsimd-6.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (632 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m632.7/632.7 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: simsimd, huggingface_hub, ultralytics-thop, albucore, ultralytics, albumentations\r\n",
      "  Attempting uninstall: huggingface_hub\r\n",
      "    Found existing installation: huggingface-hub 0.29.0\r\n",
      "    Uninstalling huggingface-hub-0.29.0:\r\n",
      "      Successfully uninstalled huggingface-hub-0.29.0\r\n",
      "  Attempting uninstall: albucore\r\n",
      "    Found existing installation: albucore 0.0.19\r\n",
      "    Uninstalling albucore-0.0.19:\r\n",
      "      Successfully uninstalled albucore-0.0.19\r\n",
      "  Attempting uninstall: albumentations\r\n",
      "    Found existing installation: albumentations 1.4.20\r\n",
      "    Uninstalling albumentations-1.4.20:\r\n",
      "      Successfully uninstalled albumentations-1.4.20\r\n",
      "Successfully installed albucore-0.0.23 albumentations-2.0.5 huggingface_hub-0.29.3 simsimd-6.2.1 ultralytics-8.3.98 ultralytics-thop-2.0.14\r\n",
      "Cloning into 'ADIS'...\r\n",
      "remote: Enumerating objects: 918, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (56/56), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (38/38), done.\u001b[K\r\n",
      "remote: Total 918 (delta 26), reused 46 (delta 17), pack-reused 862 (from 2)\u001b[K\r\n",
      "Receiving objects: 100% (918/918), 6.27 MiB | 29.86 MiB/s, done.\r\n",
      "Resolving deltas: 100% (454/454), done.\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U albumentations ultralytics optuna huggingface_hub\n",
    "!git clone https://github.com/sathishkumar67/ADIS.git\n",
    "!mv /kaggle/working/ADIS/* /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ae0908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T18:55:52.262068Z",
     "iopub.status.busy": "2025-03-28T18:55:52.261831Z",
     "iopub.status.idle": "2025-03-28T18:55:58.477665Z",
     "shell.execute_reply": "2025-03-28T18:55:58.476989Z"
    },
    "papermill": {
     "duration": 6.222002,
     "end_time": "2025-03-28T18:55:58.479146",
     "exception": false,
     "start_time": "2025-03-28T18:55:52.257144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "# necessary imports\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import joblib\n",
    "import optuna\n",
    "from huggingface_hub import hf_hub_download\n",
    "from utils import unzip_file\n",
    "from model import YOLO11Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd0d9a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T18:55:58.488774Z",
     "iopub.status.busy": "2025-03-28T18:55:58.488415Z",
     "iopub.status.idle": "2025-03-28T18:55:58.492724Z",
     "shell.execute_reply": "2025-03-28T18:55:58.491949Z"
    },
    "papermill": {
     "duration": 0.01017,
     "end_time": "2025-03-28T18:55:58.493937",
     "exception": false,
     "start_time": "2025-03-28T18:55:58.483767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the global variables\n",
    "REPO_ID = \"pt-sk/ADIS\" \n",
    "FILENAME_IN_REPO = \"dataset.zip\"\n",
    "LOCAL_DIR = os.getcwd()\n",
    "TRAIN_PATH = f\"{LOCAL_DIR}/dataset/train\"\n",
    "VAL_PATH = f\"{LOCAL_DIR}/dataset/val\"\n",
    "TEST_PATH = f\"{LOCAL_DIR}/dataset/test\"\n",
    "DATASET_PATH = f\"{LOCAL_DIR}/{FILENAME_IN_REPO}\"\n",
    "REPO_TYPE = \"dataset\"\n",
    "NUM_CLASSES = 10                                               \n",
    "CLASSES = ['Cat', 'Cattle', 'Chicken', 'Deer', 'Dog', \"Squirrel\", 'Eagle', 'Goat', 'Rodents', 'Snake'] \n",
    "DATA_YAML_FILE = f\"{LOCAL_DIR}/data.yaml\"\n",
    "MODEL_PATH = \"yolo11n.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10bd54d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T18:55:58.502662Z",
     "iopub.status.busy": "2025-03-28T18:55:58.502453Z",
     "iopub.status.idle": "2025-03-28T18:57:40.710538Z",
     "shell.execute_reply": "2025-03-28T18:57:40.709534Z"
    },
    "papermill": {
     "duration": 102.213983,
     "end_time": "2025-03-28T18:57:40.711981",
     "exception": false,
     "start_time": "2025-03-28T18:55:58.497998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e028835304644d3ad5484337126b917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset.zip:   0%|          | 0.00/9.57G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unzipping: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.60G/9.60G [00:59<00:00, 161MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# download the dataset and unzip it\n",
    "hf_hub_download(repo_id=REPO_ID, filename=FILENAME_IN_REPO, repo_type=REPO_TYPE, local_dir=LOCAL_DIR)\n",
    "unzip_file(DATASET_PATH, LOCAL_DIR)\n",
    "\n",
    "\n",
    "# Get the number of CPU cores\n",
    "num_cores = os.cpu_count()\n",
    "print(f\"Number of CPU cores: {num_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a721b70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T18:57:40.774299Z",
     "iopub.status.busy": "2025-03-28T18:57:40.773952Z",
     "iopub.status.idle": "2025-03-28T18:57:40.779046Z",
     "shell.execute_reply": "2025-03-28T18:57:40.778343Z"
    },
    "papermill": {
     "duration": 0.038594,
     "end_time": "2025-03-28T18:57:40.780289",
     "exception": false,
     "start_time": "2025-03-28T18:57:40.741695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data yaml file written!.............\n"
     ]
    }
   ],
   "source": [
    "# split paths for model\n",
    "data_yaml = f\"\"\"\n",
    "train: {TRAIN_PATH}\n",
    "val: {VAL_PATH}\n",
    "test: {TEST_PATH}\n",
    "\n",
    "nc: {NUM_CLASSES}\n",
    "names: {CLASSES}\n",
    "\"\"\"\n",
    "\n",
    "# write data yaml file\n",
    "with open(DATA_YAML_FILE, \"w\") as file:\n",
    "    file.write(data_yaml)\n",
    "    print(\"data yaml file written!.............\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "624a986f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T18:57:40.838787Z",
     "iopub.status.busy": "2025-03-28T18:57:40.838463Z",
     "iopub.status.idle": "2025-03-28T18:57:40.844627Z",
     "shell.execute_reply": "2025-03-28T18:57:40.843911Z"
    },
    "papermill": {
     "duration": 0.037029,
     "end_time": "2025-03-28T18:57:40.845974",
     "exception": false,
     "start_time": "2025-03-28T18:57:40.808945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    \n",
    "    # Define callback to report intermediate results\n",
    "    def on_train_epoch_end(score, epoch):\n",
    "        trial.report(score, step=epoch)  \n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    callbacks = {\n",
    "        \"on_train_epoch_end\" : on_train_epoch_end\n",
    "    }\n",
    "    \n",
    "    # Define hyperparameters using Optuna suggestions\n",
    "    lr0 = trial.suggest_float(\"lr0\", 1e-5, 1e-3, log=True)\n",
    "    lrf = trial.suggest_float(\"lrf\", 0.1, 1, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.0001, 0.01, log=True)\n",
    "    warmup_momentum = trial.suggest_float(\"warmup_momentum\", 0.5, 0.9)\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.8, 0.99)\n",
    "    \n",
    "    CONFIG_DICT = {\n",
    "    \"task\": \"detect\",\n",
    "    \"mode\": \"train\",\n",
    "    \"bohb\": True,\n",
    "    \"custom_callbacks\": callbacks,\n",
    "    \"data\": DATA_YAML_FILE,\n",
    "    \"batch\": 352,\n",
    "    \"imgsz\": 320,\n",
    "    \"save\": True,\n",
    "    \"device\": 0,\n",
    "    \"workers\": num_cores,\n",
    "    \"pretrained\": True,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 20,\n",
    "    \"warmup_epochs\": 3,\n",
    "    \"patience\": 4}\n",
    "\n",
    "    # Train YOLO model\n",
    "    model = YOLO11Model(MODEL_PATH)\n",
    "    model.train(**CONFIG_DICT, lr0=lr0, lrf=lrf, momentum=momentum, weight_decay=weight_decay, warmup_momentum=warmup_momentum)\n",
    "    \n",
    "    # Return validation mAP as the objective value\n",
    "    return model.score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71a56f07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T18:57:40.906562Z",
     "iopub.status.busy": "2025-03-28T18:57:40.906255Z",
     "iopub.status.idle": "2025-03-28T23:37:19.470202Z",
     "shell.execute_reply": "2025-03-28T23:37:19.468876Z"
    },
    "papermill": {
     "duration": 16778.597693,
     "end_time": "2025-03-28T23:37:19.472133",
     "exception": false,
     "start_time": "2025-03-28T18:57:40.874440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 18:57:40,908] A new study created in memory with name: yolo11_tuning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 74.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mtrainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/working/data.yaml, epochs=20, time=None, patience=4, batch=352, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0004208251757777279, lrf=0.973221631311918, momentum=0.8064931575457418, weight_decay=0.001128553144595827, warmup_epochs=3, warmup_momentum=0.8118680889772834, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 17.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  blocks.Conv                                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  blocks.Conv                                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  blocks.C3k2                                  [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  blocks.C3k2                                  [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  blocks.C3k2                                  [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  blocks.Conv                                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  blocks.C3k2                                  [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  blocks.SPPF                                  [256, 256, 5]                 \n",
      " 10                  -1  1    249728  blocks.C2PSA                                 [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  blocks.Concat                                [1]                           \n",
      " 13                  -1  1    111296  blocks.C3k2                                  [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  blocks.Concat                                [1]                           \n",
      " 16                  -1  1     32096  blocks.C3k2                                  [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  blocks.Concat                                [1]                           \n",
      " 19                  -1  1     86720  blocks.C3k2                                  [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  blocks.Concat                                [1]                           \n",
      " 22                  -1  1    378880  blocks.C3k2                                  [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    753262  blocks.Detect                                [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 239 layers, 2,912,430 parameters, 2,912,414 gradients, 7.7 GFLOPs\n",
      "\n",
      "Transferred 421/463 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train... 20000 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:20<00:00, 977.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val... 1400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:01<00:00, 719.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/dataset/val.cache\n",
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0004208251757777279, momentum=0.8064931575457418) with parameter groups 75 weight(decay=0.0), 82 weight(decay=0.006207042295277049), 81 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      13.4G      1.201      2.904      1.282        863        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:54<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: AVG Box Loss: 1.2010 | AVG Cls Loss: 2.9036 | AVG DFL Loss: 1.2820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.423      0.184      0.229      0.135\n",
      "Epoch 1: AVG Val Box Loss: 1.4711 | AVG Val Cls Loss: 3.0453 | AVG Val DFL Loss: 1.3713 | Total Val Loss: 5.8877\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      13.1G       1.18      1.889       1.25        832        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:45<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: AVG Box Loss: 1.1801 | AVG Cls Loss: 1.8893 | AVG DFL Loss: 1.2499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.614      0.479      0.545      0.333\n",
      "Epoch 2: AVG Val Box Loss: 1.2862 | AVG Val Cls Loss: 1.7960 | AVG Val DFL Loss: 1.2632 | Total Val Loss: 4.3453\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      13.1G      1.155      1.605      1.246        840        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:43<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: AVG Box Loss: 1.1555 | AVG Cls Loss: 1.6050 | AVG DFL Loss: 1.2457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.633      0.552      0.595      0.376\n",
      "Epoch 3: AVG Val Box Loss: 1.2476 | AVG Val Cls Loss: 1.7690 | AVG Val DFL Loss: 1.2859 | Total Val Loss: 4.3025\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      12.8G      1.131      1.502      1.239        917        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:43<00:00,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: AVG Box Loss: 1.1305 | AVG Cls Loss: 1.5019 | AVG DFL Loss: 1.2392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.628      0.607      0.633      0.404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: AVG Val Box Loss: 1.2370 | AVG Val Cls Loss: 1.4960 | AVG Val DFL Loss: 1.2704 | Total Val Loss: 4.0034\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      12.8G      1.116      1.419       1.23        881        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:44<00:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: AVG Box Loss: 1.1156 | AVG Cls Loss: 1.4192 | AVG DFL Loss: 1.2303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.723       0.65      0.723      0.479\n",
      "Epoch 5: AVG Val Box Loss: 1.1835 | AVG Val Cls Loss: 1.2645 | AVG Val DFL Loss: 1.2208 | Total Val Loss: 3.6689\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      12.8G      1.094       1.36      1.222        888        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:43<00:00,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: AVG Box Loss: 1.0937 | AVG Cls Loss: 1.3597 | AVG DFL Loss: 1.2221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.658      0.604      0.682      0.444\n",
      "Epoch 6: AVG Val Box Loss: 1.1991 | AVG Val Cls Loss: 1.4327 | AVG Val DFL Loss: 1.2423 | Total Val Loss: 3.8742\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      12.8G      1.086      1.309      1.216        908        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:40<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: AVG Box Loss: 1.0857 | AVG Cls Loss: 1.3089 | AVG DFL Loss: 1.2161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.712      0.592      0.692      0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: AVG Val Box Loss: 1.1750 | AVG Val Cls Loss: 1.3792 | AVG Val DFL Loss: 1.2255 | Total Val Loss: 3.7797\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      12.8G      1.081      1.271      1.216        859        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:39<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: AVG Box Loss: 1.0812 | AVG Cls Loss: 1.2707 | AVG DFL Loss: 1.2159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.775      0.686      0.771      0.514\n",
      "Epoch 8: AVG Val Box Loss: 1.1566 | AVG Val Cls Loss: 1.0851 | AVG Val DFL Loss: 1.2062 | Total Val Loss: 3.4479\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      12.8G      1.071      1.243       1.21        925        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: AVG Box Loss: 1.0709 | AVG Cls Loss: 1.2432 | AVG DFL Loss: 1.2097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.742      0.675       0.75      0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: AVG Val Box Loss: 1.2181 | AVG Val Cls Loss: 1.1786 | AVG Val DFL Loss: 1.2375 | Total Val Loss: 3.6342\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      12.8G      1.065      1.219      1.205        908        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:39<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: AVG Box Loss: 1.0655 | AVG Cls Loss: 1.2193 | AVG DFL Loss: 1.2053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.822      0.728      0.817      0.548\n",
      "Epoch 10: AVG Val Box Loss: 1.1095 | AVG Val Cls Loss: 0.9476 | AVG Val DFL Loss: 1.1699 | Total Val Loss: 3.2270\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      13.1G      1.014     0.9324      1.175        350        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:46<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: AVG Box Loss: 1.0143 | AVG Cls Loss: 0.9324 | AVG DFL Loss: 1.1750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.804      0.689       0.78      0.522\n",
      "Epoch 11: AVG Val Box Loss: 1.1316 | AVG Val Cls Loss: 1.0777 | AVG Val DFL Loss: 1.1715 | Total Val Loss: 3.3808\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      12.8G      0.997     0.8809      1.167        375        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:36<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: AVG Box Loss: 0.9970 | AVG Cls Loss: 0.8809 | AVG DFL Loss: 1.1666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.779      0.688       0.78      0.531\n",
      "Epoch 12: AVG Val Box Loss: 1.0999 | AVG Val Cls Loss: 1.0620 | AVG Val DFL Loss: 1.1599 | Total Val Loss: 3.3218\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      12.8G     0.9832     0.8327      1.157        392        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:36<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: AVG Box Loss: 0.9832 | AVG Cls Loss: 0.8327 | AVG DFL Loss: 1.1566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.782      0.679      0.761      0.517\n",
      "Epoch 13: AVG Val Box Loss: 1.0898 | AVG Val Cls Loss: 1.1339 | AVG Val DFL Loss: 1.1516 | Total Val Loss: 3.3753\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      12.8G     0.9688     0.8042      1.148        397        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:37<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: AVG Box Loss: 0.9688 | AVG Cls Loss: 0.8042 | AVG DFL Loss: 1.1475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.789      0.696       0.78      0.521\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 4 epochs. Best results observed at epoch 10, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=4) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "Epoch 14: AVG Val Box Loss: 1.1015 | AVG Val Cls Loss: 1.0325 | AVG Val DFL Loss: 1.1561 | Total Val Loss: 3.2901\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "14 epochs completed in 0.452 hours.\n",
      "\n",
      "Validating Validation Data runs/detect/train/weights/best.pt...\n",
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "YOLO11n summary (fused): 164 layers, 2,905,382 parameters, 0 gradients, 7.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781       0.82       0.73      0.817      0.547\n",
      "                   Cat        140        144      0.863      0.834       0.92      0.661\n",
      "                Cattle        140        174      0.859      0.773      0.856      0.601\n",
      "               Chicken        140        313      0.818      0.728      0.814      0.522\n",
      "                  Deer        140        189      0.818      0.767      0.849      0.594\n",
      "                   Dog        140        169      0.832      0.716      0.823      0.449\n",
      "              Squirrel        140        143      0.772       0.72      0.791       0.55\n",
      "                 Eagle        140        156       0.93      0.763      0.856      0.687\n",
      "                  Goat        140        186      0.667      0.668      0.712      0.469\n",
      "               Rodents        140        155      0.828      0.703      0.797      0.506\n",
      "                 Snake        140        152      0.812      0.623      0.754      0.435\n",
      "Per-class IoU and Accuracy:\n",
      "          Cat: IoU: 0.855 | Accuracy: 0.778\n",
      "          Cattle: IoU: 0.861 | Accuracy: 0.711\n",
      "          Chicken: IoU: 0.825 | Accuracy: 0.711\n",
      "          Deer: IoU: 0.852 | Accuracy: 0.675\n",
      "          Dog: IoU: 0.795 | Accuracy: 0.670\n",
      "          Squirrel: IoU: 0.857 | Accuracy: 0.646\n",
      "          Eagle: IoU: 0.904 | Accuracy: 0.730\n",
      "          Goat: IoU: 0.840 | Accuracy: 0.521\n",
      "          Rodents: IoU: 0.839 | Accuracy: 0.655\n",
      "          Snake: IoU: 0.806 | Accuracy: 0.637\n",
      "          Background Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.0ms preprocess, 0.6ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 19:26:11,308] Trial 0 finished with value: 0.0 and parameters: {'lr0': 0.0004208251757777279, 'lrf': 0.973221631311918, 'weight_decay': 0.001128553144595827, 'warmup_momentum': 0.8118680889772834, 'momentum': 0.8064931575457418}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mtrainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/working/data.yaml, epochs=20, time=None, patience=4, batch=352, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.00010184556429026328, lrf=0.19916757626587187, momentum=0.9363789423797441, weight_decay=0.00015790593441848133, warmup_epochs=3, warmup_momentum=0.6170723113964784, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  blocks.Conv                                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  blocks.Conv                                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  blocks.C3k2                                  [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  blocks.C3k2                                  [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  blocks.C3k2                                  [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  blocks.Conv                                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  blocks.C3k2                                  [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  blocks.SPPF                                  [256, 256, 5]                 \n",
      " 10                  -1  1    249728  blocks.C2PSA                                 [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  blocks.Concat                                [1]                           \n",
      " 13                  -1  1    111296  blocks.C3k2                                  [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  blocks.Concat                                [1]                           \n",
      " 16                  -1  1     32096  blocks.C3k2                                  [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  blocks.Concat                                [1]                           \n",
      " 19                  -1  1     86720  blocks.C3k2                                  [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  blocks.Concat                                [1]                           \n",
      " 22                  -1  1    378880  blocks.C3k2                                  [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    753262  blocks.Detect                                [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 239 layers, 2,912,430 parameters, 2,912,414 gradients, 7.7 GFLOPs\n",
      "\n",
      "Transferred 421/463 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train.cache... 20000 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 1400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00010184556429026328, momentum=0.9363789423797441) with parameter groups 75 weight(decay=0.0), 82 weight(decay=0.0008684826393016473), 81 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      13.2G      1.192      3.126      1.274        863        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:44<00:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: AVG Box Loss: 1.1922 | AVG Cls Loss: 3.1263 | AVG DFL Loss: 1.2742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781     0.0117       0.71      0.135     0.0757\n",
      "Epoch 1: AVG Val Box Loss: 1.8042 | AVG Val Cls Loss: 3.3103 | AVG Val DFL Loss: 1.5370 | Total Val Loss: 6.6514\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      13.1G      1.173      2.442      1.241        832        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:41<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: AVG Box Loss: 1.1732 | AVG Cls Loss: 2.4415 | AVG DFL Loss: 1.2409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.333      0.475      0.374      0.235\n",
      "Epoch 2: AVG Val Box Loss: 1.3029 | AVG Val Cls Loss: 2.2416 | AVG Val DFL Loss: 1.2398 | Total Val Loss: 4.7843\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      13.1G      1.164      2.009      1.235        840        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:36<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: AVG Box Loss: 1.1642 | AVG Cls Loss: 2.0093 | AVG DFL Loss: 1.2352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.622      0.555      0.591      0.385\n",
      "Epoch 3: AVG Val Box Loss: 1.1388 | AVG Val Cls Loss: 1.7657 | AVG Val DFL Loss: 1.1966 | Total Val Loss: 4.1010\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      12.8G       1.12      1.769      1.219        917        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:39<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: AVG Box Loss: 1.1203 | AVG Cls Loss: 1.7685 | AVG DFL Loss: 1.2191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.657      0.665      0.699      0.459\n",
      "Epoch 4: AVG Val Box Loss: 1.1086 | AVG Val Cls Loss: 1.3759 | AVG Val DFL Loss: 1.1633 | Total Val Loss: 3.6478\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      12.8G      1.106      1.633      1.208        881        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:39<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: AVG Box Loss: 1.1064 | AVG Cls Loss: 1.6327 | AVG DFL Loss: 1.2081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.736      0.687      0.753        0.5\n",
      "Epoch 5: AVG Val Box Loss: 1.1226 | AVG Val Cls Loss: 1.2138 | AVG Val DFL Loss: 1.1621 | Total Val Loss: 3.4985\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      12.8G      1.089      1.538      1.201        888        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: AVG Box Loss: 1.0888 | AVG Cls Loss: 1.5381 | AVG DFL Loss: 1.2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.774      0.683      0.778      0.519\n",
      "Epoch 6: AVG Val Box Loss: 1.0932 | AVG Val Cls Loss: 1.1296 | AVG Val DFL Loss: 1.1435 | Total Val Loss: 3.3662\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      12.8G      1.073      1.475      1.192        908        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:36<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: AVG Box Loss: 1.0727 | AVG Cls Loss: 1.4754 | AVG DFL Loss: 1.1915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.799       0.72      0.802      0.545\n",
      "Epoch 7: AVG Val Box Loss: 1.0615 | AVG Val Cls Loss: 1.0627 | AVG Val DFL Loss: 1.1185 | Total Val Loss: 3.2428\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      12.8G      1.065      1.423      1.194        859        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: AVG Box Loss: 1.0654 | AVG Cls Loss: 1.4227 | AVG DFL Loss: 1.1936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.823      0.733      0.817      0.561\n",
      "Epoch 8: AVG Val Box Loss: 1.0610 | AVG Val Cls Loss: 1.0129 | AVG Val DFL Loss: 1.1129 | Total Val Loss: 3.1868\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      12.8G      1.058       1.39      1.191        925        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: AVG Box Loss: 1.0585 | AVG Cls Loss: 1.3902 | AVG DFL Loss: 1.1911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.825      0.738      0.816      0.559\n",
      "Epoch 9: AVG Val Box Loss: 1.0638 | AVG Val Cls Loss: 1.0136 | AVG Val DFL Loss: 1.1237 | Total Val Loss: 3.2011\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      12.8G      1.049      1.351      1.186        908        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:39<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: AVG Box Loss: 1.0489 | AVG Cls Loss: 1.3506 | AVG DFL Loss: 1.1861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.805      0.751      0.822      0.561\n",
      "Epoch 10: AVG Val Box Loss: 1.0584 | AVG Val Cls Loss: 0.9991 | AVG Val DFL Loss: 1.1186 | Total Val Loss: 3.1761\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      13.1G     0.9882      1.128      1.152        350        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:43<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: AVG Box Loss: 0.9882 | AVG Cls Loss: 1.1275 | AVG DFL Loss: 1.1523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.793      0.752      0.828       0.58\n",
      "Epoch 11: AVG Val Box Loss: 1.0490 | AVG Val Cls Loss: 0.9978 | AVG Val DFL Loss: 1.1206 | Total Val Loss: 3.1673\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      12.8G      0.962     0.9828      1.135        375        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: AVG Box Loss: 0.9620 | AVG Cls Loss: 0.9828 | AVG DFL Loss: 1.1353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.851      0.757      0.844      0.591\n",
      "Epoch 12: AVG Val Box Loss: 1.0242 | AVG Val Cls Loss: 0.9121 | AVG Val DFL Loss: 1.0982 | Total Val Loss: 3.0345\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      12.8G     0.9479     0.9316      1.126        392        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: AVG Box Loss: 0.9479 | AVG Cls Loss: 0.9316 | AVG DFL Loss: 1.1262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.833      0.764      0.851      0.597\n",
      "Epoch 13: AVG Val Box Loss: 1.0169 | AVG Val Cls Loss: 0.8813 | AVG Val DFL Loss: 1.0858 | Total Val Loss: 2.9840\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      12.8G     0.9356     0.8964      1.118        397        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: AVG Box Loss: 0.9356 | AVG Cls Loss: 0.8964 | AVG DFL Loss: 1.1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781       0.85      0.777      0.861       0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: AVG Val Box Loss: 0.9990 | AVG Val Cls Loss: 0.8525 | AVG Val DFL Loss: 1.0819 | Total Val Loss: 2.9334\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      12.8G     0.9268     0.8618       1.11        385        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:35<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: AVG Box Loss: 0.9268 | AVG Cls Loss: 0.8618 | AVG DFL Loss: 1.1104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.843      0.783      0.864      0.607\n",
      "Epoch 15: AVG Val Box Loss: 1.0017 | AVG Val Cls Loss: 0.8306 | AVG Val DFL Loss: 1.0815 | Total Val Loss: 2.9139\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      12.8G     0.9154     0.8392      1.109        371        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: AVG Box Loss: 0.9154 | AVG Cls Loss: 0.8392 | AVG DFL Loss: 1.1089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.855      0.792      0.866      0.618\n",
      "Epoch 16: AVG Val Box Loss: 0.9863 | AVG Val Cls Loss: 0.8230 | AVG Val DFL Loss: 1.0716 | Total Val Loss: 2.8810\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      12.8G     0.9097     0.8191      1.103        371        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: AVG Box Loss: 0.9097 | AVG Cls Loss: 0.8191 | AVG DFL Loss: 1.1027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.844      0.803      0.876       0.62\n",
      "Epoch 17: AVG Val Box Loss: 0.9875 | AVG Val Cls Loss: 0.8019 | AVG Val DFL Loss: 1.0700 | Total Val Loss: 2.8594\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      12.8G     0.9052     0.8072      1.103        408        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: AVG Box Loss: 0.9052 | AVG Cls Loss: 0.8072 | AVG DFL Loss: 1.1030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.864      0.786      0.872      0.626\n",
      "Epoch 18: AVG Val Box Loss: 0.9775 | AVG Val Cls Loss: 0.7953 | AVG Val DFL Loss: 1.0618 | Total Val Loss: 2.8345\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      12.8G     0.8972     0.7847      1.093        416        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:36<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: AVG Box Loss: 0.8972 | AVG Cls Loss: 0.7847 | AVG DFL Loss: 1.0929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.855      0.797      0.881      0.633\n",
      "Epoch 19: AVG Val Box Loss: 0.9698 | AVG Val Cls Loss: 0.7814 | AVG Val DFL Loss: 1.0557 | Total Val Loss: 2.8068\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      12.8G     0.8897     0.7737      1.091        362        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: AVG Box Loss: 0.8897 | AVG Cls Loss: 0.7737 | AVG DFL Loss: 1.0907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.858      0.811      0.883      0.635\n",
      "Epoch 20: AVG Val Box Loss: 0.9696 | AVG Val Cls Loss: 0.7654 | AVG Val DFL Loss: 1.0558 | Total Val Loss: 2.7909\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 0.627 hours.\n",
      "\n",
      "Validating Validation Data runs/detect/train2/weights/best.pt...\n",
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "YOLO11n summary (fused): 164 layers, 2,905,382 parameters, 0 gradients, 7.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.858      0.812      0.883      0.635\n",
      "                   Cat        140        144      0.907      0.951      0.965      0.763\n",
      "                Cattle        140        174       0.92      0.828       0.91      0.685\n",
      "               Chicken        140        313      0.869      0.763      0.882      0.616\n",
      "                  Deer        140        189      0.902      0.873      0.928      0.696\n",
      "                   Dog        140        169      0.824      0.805      0.865      0.523\n",
      "              Squirrel        140        143      0.813      0.839      0.861      0.614\n",
      "                 Eagle        140        156      0.903      0.827       0.92      0.746\n",
      "                  Goat        140        186      0.769      0.735      0.823      0.567\n",
      "               Rodents        140        155      0.835      0.718      0.832      0.578\n",
      "                 Snake        140        152      0.841      0.776      0.848      0.556\n",
      "Per-class IoU and Accuracy:\n",
      "          Cat: IoU: 0.884 | Accuracy: 0.902\n",
      "          Cattle: IoU: 0.866 | Accuracy: 0.803\n",
      "          Chicken: IoU: 0.848 | Accuracy: 0.789\n",
      "          Deer: IoU: 0.870 | Accuracy: 0.828\n",
      "          Dog: IoU: 0.807 | Accuracy: 0.750\n",
      "          Squirrel: IoU: 0.851 | Accuracy: 0.728\n",
      "          Eagle: IoU: 0.900 | Accuracy: 0.784\n",
      "          Goat: IoU: 0.852 | Accuracy: 0.658\n",
      "          Rodents: IoU: 0.854 | Accuracy: 0.730\n",
      "          Snake: IoU: 0.825 | Accuracy: 0.772\n",
      "          Background Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.0ms preprocess, 0.6ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:04:20,470] Trial 1 finished with value: 0.6345 and parameters: {'lr0': 0.00010184556429026328, 'lrf': 0.19916757626587187, 'weight_decay': 0.00015790593441848133, 'warmup_momentum': 0.6170723113964784, 'momentum': 0.9363789423797441}. Best is trial 1 with value: 0.6345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mtrainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/working/data.yaml, epochs=20, time=None, patience=4, batch=352, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0008564896358732444, lrf=0.6327259787286987, momentum=0.87210344043186, weight_decay=0.00479243410169218, warmup_epochs=3, warmup_momentum=0.7445268897476802, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  blocks.Conv                                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  blocks.Conv                                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  blocks.C3k2                                  [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  blocks.C3k2                                  [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  blocks.C3k2                                  [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  blocks.Conv                                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  blocks.C3k2                                  [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  blocks.SPPF                                  [256, 256, 5]                 \n",
      " 10                  -1  1    249728  blocks.C2PSA                                 [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  blocks.Concat                                [1]                           \n",
      " 13                  -1  1    111296  blocks.C3k2                                  [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  blocks.Concat                                [1]                           \n",
      " 16                  -1  1     32096  blocks.C3k2                                  [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  blocks.Concat                                [1]                           \n",
      " 19                  -1  1     86720  blocks.C3k2                                  [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  blocks.Concat                                [1]                           \n",
      " 22                  -1  1    378880  blocks.C3k2                                  [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    753262  blocks.Detect                                [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 239 layers, 2,912,430 parameters, 2,912,414 gradients, 7.7 GFLOPs\n",
      "\n",
      "Transferred 421/463 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train.cache... 20000 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 1400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0008564896358732444, momentum=0.87210344043186) with parameter groups 75 weight(decay=0.0), 82 weight(decay=0.02635838755930699), 81 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      13.2G      1.215      2.832      1.291        863        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:44<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: AVG Box Loss: 1.2150 | AVG Cls Loss: 2.8318 | AVG DFL Loss: 1.2915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.268      0.286       0.17     0.0949\n",
      "Epoch 1: AVG Val Box Loss: 1.5934 | AVG Val Cls Loss: 3.2948 | AVG Val DFL Loss: 1.8021 | Total Val Loss: 6.6904\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      13.1G      1.196      1.821       1.26        832        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:40<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: AVG Box Loss: 1.1957 | AVG Cls Loss: 1.8213 | AVG DFL Loss: 1.2603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.505      0.418      0.411      0.249\n",
      "Epoch 2: AVG Val Box Loss: 1.3658 | AVG Val Cls Loss: 2.2955 | AVG Val DFL Loss: 1.3913 | Total Val Loss: 5.0526\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      13.1G      1.189      1.633      1.267        840        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:37<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: AVG Box Loss: 1.1894 | AVG Cls Loss: 1.6332 | AVG DFL Loss: 1.2670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.541      0.291      0.344      0.209\n",
      "Epoch 3: AVG Val Box Loss: 1.5090 | AVG Val Cls Loss: 2.7991 | AVG Val DFL Loss: 1.6057 | Total Val Loss: 5.9137\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      12.8G      1.173      1.575      1.271        917        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:40<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: AVG Box Loss: 1.1728 | AVG Cls Loss: 1.5746 | AVG DFL Loss: 1.2712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.611      0.405      0.445      0.281\n",
      "Epoch 4: AVG Val Box Loss: 1.3427 | AVG Val Cls Loss: 2.1277 | AVG Val DFL Loss: 1.3415 | Total Val Loss: 4.8119\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      12.8G      1.152      1.479      1.258        881        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:40<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: AVG Box Loss: 1.1520 | AVG Cls Loss: 1.4787 | AVG DFL Loss: 1.2577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781       0.62      0.572      0.613      0.381\n",
      "Epoch 5: AVG Val Box Loss: 1.3452 | AVG Val Cls Loss: 1.6275 | AVG Val DFL Loss: 1.3504 | Total Val Loss: 4.3231\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      12.8G      1.129      1.415      1.247        888        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: AVG Box Loss: 1.1292 | AVG Cls Loss: 1.4148 | AVG DFL Loss: 1.2469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781       0.63      0.535      0.592      0.381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: AVG Val Box Loss: 1.2552 | AVG Val Cls Loss: 1.5883 | AVG Val DFL Loss: 1.3040 | Total Val Loss: 4.1476\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      12.8G      1.113      1.362      1.236        908        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:35<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: AVG Box Loss: 1.1132 | AVG Cls Loss: 1.3623 | AVG DFL Loss: 1.2362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.725       0.66      0.715      0.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: AVG Val Box Loss: 1.2146 | AVG Val Cls Loss: 1.2405 | AVG Val DFL Loss: 1.2690 | Total Val Loss: 3.7241\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      12.8G      1.109      1.322      1.237        859        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: AVG Box Loss: 1.1089 | AVG Cls Loss: 1.3218 | AVG DFL Loss: 1.2373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.756      0.623      0.719      0.458\n",
      "Epoch 8: AVG Val Box Loss: 1.2120 | AVG Val Cls Loss: 1.2920 | AVG Val DFL Loss: 1.2340 | Total Val Loss: 3.7380\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      12.8G      1.094       1.29      1.228        925        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:37<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: AVG Box Loss: 1.0943 | AVG Cls Loss: 1.2903 | AVG DFL Loss: 1.2284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.685      0.586      0.615      0.394\n",
      "Epoch 9: AVG Val Box Loss: 1.2926 | AVG Val Cls Loss: 1.6701 | AVG Val DFL Loss: 1.2918 | Total Val Loss: 4.2544\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      12.8G      1.088      1.257      1.221        908        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:39<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: AVG Box Loss: 1.0876 | AVG Cls Loss: 1.2570 | AVG DFL Loss: 1.2213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781       0.81      0.638      0.747      0.488\n",
      "Epoch 10: AVG Val Box Loss: 1.1698 | AVG Val Cls Loss: 1.1472 | AVG Val DFL Loss: 1.2249 | Total Val Loss: 3.5418\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      13.1G      1.046      0.981      1.199        350        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:47<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: AVG Box Loss: 1.0459 | AVG Cls Loss: 0.9810 | AVG DFL Loss: 1.1994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.697      0.586      0.674      0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: AVG Val Box Loss: 1.2064 | AVG Val Cls Loss: 1.4641 | AVG Val DFL Loss: 1.2651 | Total Val Loss: 3.9356\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      12.8G      1.031      0.926      1.193        375        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:36<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: AVG Box Loss: 1.0314 | AVG Cls Loss: 0.9260 | AVG DFL Loss: 1.1927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.796      0.678      0.781      0.529\n",
      "Epoch 12: AVG Val Box Loss: 1.1153 | AVG Val Cls Loss: 1.0659 | AVG Val DFL Loss: 1.1821 | Total Val Loss: 3.3632\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      12.8G      1.008     0.8791      1.175        392        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:35<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: AVG Box Loss: 1.0075 | AVG Cls Loss: 0.8791 | AVG DFL Loss: 1.1750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.799      0.709      0.795      0.533\n",
      "Epoch 13: AVG Val Box Loss: 1.1086 | AVG Val Cls Loss: 1.0078 | AVG Val DFL Loss: 1.1639 | Total Val Loss: 3.2803\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      12.8G     0.9963      0.841      1.167        397        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: AVG Box Loss: 0.9963 | AVG Cls Loss: 0.8410 | AVG DFL Loss: 1.1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.742      0.646      0.748      0.496\n",
      "Epoch 14: AVG Val Box Loss: 1.1269 | AVG Val Cls Loss: 1.1843 | AVG Val DFL Loss: 1.1961 | Total Val Loss: 3.5073\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      12.8G     0.9896     0.8176      1.162        385        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:32<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: AVG Box Loss: 0.9896 | AVG Cls Loss: 0.8176 | AVG DFL Loss: 1.1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.798      0.713      0.802      0.534\n",
      "Epoch 15: AVG Val Box Loss: 1.1361 | AVG Val Cls Loss: 0.9852 | AVG Val DFL Loss: 1.1883 | Total Val Loss: 3.3095\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      12.8G     0.9709     0.7979      1.157        371        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:35<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: AVG Box Loss: 0.9709 | AVG Cls Loss: 0.7979 | AVG DFL Loss: 1.1568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.791      0.699      0.797      0.542\n",
      "Epoch 16: AVG Val Box Loss: 1.1143 | AVG Val Cls Loss: 0.9823 | AVG Val DFL Loss: 1.1725 | Total Val Loss: 3.2691\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      12.8G     0.9691     0.7783       1.15        371        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:37<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: AVG Box Loss: 0.9691 | AVG Cls Loss: 0.7783 | AVG DFL Loss: 1.1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.803      0.709      0.811      0.556\n",
      "Epoch 17: AVG Val Box Loss: 1.1062 | AVG Val Cls Loss: 0.9702 | AVG Val DFL Loss: 1.1557 | Total Val Loss: 3.2321\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      12.8G     0.9643     0.7594      1.149        408        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:33<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: AVG Box Loss: 0.9643 | AVG Cls Loss: 0.7594 | AVG DFL Loss: 1.1486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.812      0.747       0.83      0.573\n",
      "Epoch 18: AVG Val Box Loss: 1.0634 | AVG Val Cls Loss: 0.8898 | AVG Val DFL Loss: 1.1442 | Total Val Loss: 3.0974\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      12.8G     0.9497     0.7334      1.136        416        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:34<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: AVG Box Loss: 0.9497 | AVG Cls Loss: 0.7334 | AVG DFL Loss: 1.1359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.826      0.753      0.836      0.583\n",
      "Epoch 19: AVG Val Box Loss: 1.0594 | AVG Val Cls Loss: 0.8730 | AVG Val DFL Loss: 1.1437 | Total Val Loss: 3.0761\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      12.8G     0.9342     0.7144      1.131        362        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:37<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: AVG Box Loss: 0.9342 | AVG Cls Loss: 0.7144 | AVG DFL Loss: 1.1306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.826      0.761       0.84      0.581\n",
      "Epoch 20: AVG Val Box Loss: 1.0833 | AVG Val Cls Loss: 0.8523 | AVG Val DFL Loss: 1.1356 | Total Val Loss: 3.0711\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 0.619 hours.\n",
      "\n",
      "Validating Validation Data runs/detect/train3/weights/best.pt...\n",
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "YOLO11n summary (fused): 164 layers, 2,905,382 parameters, 0 gradients, 7.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.825      0.754      0.836      0.583\n",
      "                   Cat        140        144       0.91      0.931      0.952      0.709\n",
      "                Cattle        140        174      0.933      0.724      0.886      0.647\n",
      "               Chicken        140        313      0.867      0.706      0.814      0.567\n",
      "                  Deer        140        189      0.801      0.841      0.888      0.633\n",
      "                   Dog        140        169      0.832      0.705      0.833      0.482\n",
      "              Squirrel        140        143      0.712      0.713      0.764      0.521\n",
      "                 Eagle        140        156      0.843      0.823      0.871      0.696\n",
      "                  Goat        140        186      0.679       0.79      0.791      0.564\n",
      "               Rodents        140        155      0.921      0.599      0.798      0.541\n",
      "                 Snake        140        152       0.75      0.704      0.768      0.471\n",
      "Per-class IoU and Accuracy:\n",
      "          Cat: IoU: 0.872 | Accuracy: 0.831\n",
      "          Cattle: IoU: 0.860 | Accuracy: 0.684\n",
      "          Chicken: IoU: 0.850 | Accuracy: 0.728\n",
      "          Deer: IoU: 0.856 | Accuracy: 0.761\n",
      "          Dog: IoU: 0.800 | Accuracy: 0.654\n",
      "          Squirrel: IoU: 0.839 | Accuracy: 0.587\n",
      "          Eagle: IoU: 0.900 | Accuracy: 0.737\n",
      "          Goat: IoU: 0.854 | Accuracy: 0.605\n",
      "          Rodents: IoU: 0.859 | Accuracy: 0.581\n",
      "          Snake: IoU: 0.810 | Accuracy: 0.680\n",
      "          Background Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.0ms preprocess, 0.7ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:42:01,718] Trial 2 finished with value: 0.581 and parameters: {'lr0': 0.0008564896358732444, 'lrf': 0.6327259787286987, 'weight_decay': 0.00479243410169218, 'warmup_momentum': 0.7445268897476802, 'momentum': 0.87210344043186}. Best is trial 1 with value: 0.6345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mtrainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/working/data.yaml, epochs=20, time=None, patience=4, batch=352, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0007269943417689886, lrf=0.17615964857852845, momentum=0.8405998194558932, weight_decay=0.004787658099911233, warmup_epochs=3, warmup_momentum=0.5435520177792202, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  blocks.Conv                                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  blocks.Conv                                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  blocks.C3k2                                  [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  blocks.C3k2                                  [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  blocks.C3k2                                  [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  blocks.Conv                                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  blocks.C3k2                                  [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  blocks.SPPF                                  [256, 256, 5]                 \n",
      " 10                  -1  1    249728  blocks.C2PSA                                 [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  blocks.Concat                                [1]                           \n",
      " 13                  -1  1    111296  blocks.C3k2                                  [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  blocks.Concat                                [1]                           \n",
      " 16                  -1  1     32096  blocks.C3k2                                  [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  blocks.Concat                                [1]                           \n",
      " 19                  -1  1     86720  blocks.C3k2                                  [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  blocks.Concat                                [1]                           \n",
      " 22                  -1  1    378880  blocks.C3k2                                  [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    753262  blocks.Detect                                [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 239 layers, 2,912,430 parameters, 2,912,414 gradients, 7.7 GFLOPs\n",
      "\n",
      "Transferred 421/463 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train.cache... 20000 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 1400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train4/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0007269943417689886, momentum=0.8405998194558932) with parameter groups 75 weight(decay=0.0), 82 weight(decay=0.02633211954951178), 81 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train4\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      13.2G      1.208      2.851      1.289        863        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:43<00:00,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: AVG Box Loss: 1.2084 | AVG Cls Loss: 2.8514 | AVG DFL Loss: 1.2891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.342      0.299      0.252       0.14\n",
      "Epoch 1: AVG Val Box Loss: 1.6226 | AVG Val Cls Loss: 2.7918 | AVG Val DFL Loss: 1.4965 | Total Val Loss: 5.9110\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      13.1G      1.189      1.831       1.26        832        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:40<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: AVG Box Loss: 1.1890 | AVG Cls Loss: 1.8315 | AVG DFL Loss: 1.2605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.452      0.357      0.356      0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: AVG Val Box Loss: 1.3223 | AVG Val Cls Loss: 2.3634 | AVG Val DFL Loss: 1.3150 | Total Val Loss: 5.0007\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      13.1G      1.171      1.607      1.256        840        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:43<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: AVG Box Loss: 1.1706 | AVG Cls Loss: 1.6065 | AVG DFL Loss: 1.2564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781       0.59       0.51      0.527      0.329\n",
      "Epoch 3: AVG Val Box Loss: 1.3148 | AVG Val Cls Loss: 1.9299 | AVG Val DFL Loss: 1.3819 | Total Val Loss: 4.6267\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:48:20,679] Trial 3 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mtrainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/working/data.yaml, epochs=20, time=None, patience=4, batch=352, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=5.776890352961998e-05, lrf=0.13914931268856653, momentum=0.8322030926043059, weight_decay=0.004714408640793181, warmup_epochs=3, warmup_momentum=0.7256842991543777, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train5\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  blocks.Conv                                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  blocks.Conv                                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  blocks.C3k2                                  [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  blocks.C3k2                                  [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  blocks.C3k2                                  [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  blocks.Conv                                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  blocks.C3k2                                  [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  blocks.SPPF                                  [256, 256, 5]                 \n",
      " 10                  -1  1    249728  blocks.C2PSA                                 [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  blocks.Concat                                [1]                           \n",
      " 13                  -1  1    111296  blocks.C3k2                                  [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  blocks.Concat                                [1]                           \n",
      " 16                  -1  1     32096  blocks.C3k2                                  [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  blocks.Concat                                [1]                           \n",
      " 19                  -1  1     86720  blocks.C3k2                                  [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  blocks.Concat                                [1]                           \n",
      " 22                  -1  1    378880  blocks.C3k2                                  [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    753262  blocks.Detect                                [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 239 layers, 2,912,430 parameters, 2,912,414 gradients, 7.7 GFLOPs\n",
      "\n",
      "Transferred 421/463 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train5', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train.cache... 20000 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 1400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train5/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=5.776890352961998e-05, momentum=0.8322030926043059) with parameter groups 75 weight(decay=0.0), 82 weight(decay=0.025929247524362497), 81 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train5\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      14.6G      1.191        3.1      1.273        863        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:46<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: AVG Box Loss: 1.1907 | AVG Cls Loss: 3.1000 | AVG DFL Loss: 1.2734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781    0.00472      0.804      0.132     0.0742\n",
      "Epoch 1: AVG Val Box Loss: 1.4384 | AVG Val Cls Loss: 3.3273 | AVG Val DFL Loss: 1.3500 | Total Val Loss: 6.1157\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      13.1G      1.178      2.449      1.254        832        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:40<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: AVG Box Loss: 1.1783 | AVG Cls Loss: 2.4495 | AVG DFL Loss: 1.2535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.346      0.418      0.341      0.211\n",
      "Epoch 2: AVG Val Box Loss: 1.2776 | AVG Val Cls Loss: 2.3900 | AVG Val DFL Loss: 1.2583 | Total Val Loss: 4.9259\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      13.1G      1.172      2.071       1.25        840        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: AVG Box Loss: 1.1720 | AVG Cls Loss: 2.0705 | AVG DFL Loss: 1.2504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.572      0.565      0.576      0.371\n",
      "Epoch 3: AVG Val Box Loss: 1.1726 | AVG Val Cls Loss: 1.7793 | AVG Val DFL Loss: 1.2225 | Total Val Loss: 4.1743\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 20:54:45,045] Trial 4 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mtrainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/working/data.yaml, epochs=20, time=None, patience=4, batch=352, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.00023011132047855642, lrf=0.9896139689201932, momentum=0.9158865006538601, weight_decay=0.007401877331116337, warmup_epochs=3, warmup_momentum=0.6585499877941675, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train6\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  blocks.Conv                                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  blocks.Conv                                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  blocks.C3k2                                  [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  blocks.C3k2                                  [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  blocks.C3k2                                  [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  blocks.Conv                                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  blocks.C3k2                                  [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  blocks.SPPF                                  [256, 256, 5]                 \n",
      " 10                  -1  1    249728  blocks.C2PSA                                 [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  blocks.Concat                                [1]                           \n",
      " 13                  -1  1    111296  blocks.C3k2                                  [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  blocks.Concat                                [1]                           \n",
      " 16                  -1  1     32096  blocks.C3k2                                  [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  blocks.Concat                                [1]                           \n",
      " 19                  -1  1     86720  blocks.C3k2                                  [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  blocks.Concat                                [1]                           \n",
      " 22                  -1  1    378880  blocks.C3k2                                  [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    753262  blocks.Detect                                [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 239 layers, 2,912,430 parameters, 2,912,414 gradients, 7.7 GFLOPs\n",
      "\n",
      "Transferred 421/463 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train6', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train.cache... 20000 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 1400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train6/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00023011132047855642, momentum=0.9158865006538601) with parameter groups 75 weight(decay=0.0), 82 weight(decay=0.040710325321139856), 81 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train6\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      14.6G      1.197      3.045      1.277        863        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:43<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: AVG Box Loss: 1.1966 | AVG Cls Loss: 3.0451 | AVG DFL Loss: 1.2773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.666     0.0772      0.185      0.107\n",
      "Epoch 1: AVG Val Box Loss: 1.5592 | AVG Val Cls Loss: 3.1924 | AVG Val DFL Loss: 1.3543 | Total Val Loss: 6.1060\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      13.1G      1.184       2.15      1.247        832        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:40<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: AVG Box Loss: 1.1838 | AVG Cls Loss: 2.1502 | AVG DFL Loss: 1.2475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.587       0.51      0.557      0.359\n",
      "Epoch 2: AVG Val Box Loss: 1.1695 | AVG Val Cls Loss: 1.9654 | AVG Val DFL Loss: 1.2094 | Total Val Loss: 4.3443\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      13.1G      1.153      1.735       1.23        840        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:35<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: AVG Box Loss: 1.1535 | AVG Cls Loss: 1.7352 | AVG DFL Loss: 1.2302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.654       0.57      0.624      0.408\n",
      "Epoch 3: AVG Val Box Loss: 1.1854 | AVG Val Cls Loss: 1.5526 | AVG Val DFL Loss: 1.2487 | Total Val Loss: 3.9868\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      12.8G      1.113      1.558      1.221        917        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: AVG Box Loss: 1.1128 | AVG Cls Loss: 1.5580 | AVG DFL Loss: 1.2207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.712      0.662      0.716      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: AVG Val Box Loss: 1.1422 | AVG Val Cls Loss: 1.3246 | AVG Val DFL Loss: 1.1741 | Total Val Loss: 3.6409\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      12.8G      1.098      1.454      1.214        881        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: AVG Box Loss: 1.0977 | AVG Cls Loss: 1.4545 | AVG DFL Loss: 1.2139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781       0.74      0.709      0.766      0.513\n",
      "Epoch 5: AVG Val Box Loss: 1.1287 | AVG Val Cls Loss: 1.1431 | AVG Val DFL Loss: 1.1660 | Total Val Loss: 3.4378\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      12.8G      1.082      1.384      1.208        888        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:40<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: AVG Box Loss: 1.0822 | AVG Cls Loss: 1.3836 | AVG DFL Loss: 1.2078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.735      0.689      0.762      0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: AVG Val Box Loss: 1.1570 | AVG Val Cls Loss: 1.1281 | AVG Val DFL Loss: 1.1808 | Total Val Loss: 3.4659\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      12.8G      1.073      1.328      1.201        908        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:39<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: AVG Box Loss: 1.0728 | AVG Cls Loss: 1.3282 | AVG DFL Loss: 1.2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781       0.82      0.714      0.817      0.554\n",
      "Epoch 7: AVG Val Box Loss: 1.0962 | AVG Val Cls Loss: 1.0060 | AVG Val DFL Loss: 1.1580 | Total Val Loss: 3.2602\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      12.8G      1.064      1.286      1.201        859        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:39<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: AVG Box Loss: 1.0645 | AVG Cls Loss: 1.2862 | AVG DFL Loss: 1.2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781       0.83       0.72       0.82      0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: AVG Val Box Loss: 1.0645 | AVG Val Cls Loss: 0.9781 | AVG Val DFL Loss: 1.1326 | Total Val Loss: 3.1752\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      12.8G      1.053      1.253      1.196        925        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:42<00:00,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: AVG Box Loss: 1.0527 | AVG Cls Loss: 1.2528 | AVG DFL Loss: 1.1957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.30s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.823      0.742      0.824      0.569\n",
      "Epoch 9: AVG Val Box Loss: 1.0930 | AVG Val Cls Loss: 0.9597 | AVG Val DFL Loss: 1.1385 | Total Val Loss: 3.1911\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      12.8G      1.047       1.22      1.193       1047        320:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 50/57 [01:27<00:10,  1.54s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "      10/20      12.8G      1.049       1.22      1.193        908        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:41<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: AVG Box Loss: 1.0490 | AVG Cls Loss: 1.2195 | AVG DFL Loss: 1.1934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.818      0.709      0.824      0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: AVG Val Box Loss: 1.0954 | AVG Val Cls Loss: 0.9586 | AVG Val DFL Loss: 1.1461 | Total Val Loss: 3.2001\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      13.1G     0.9844     0.9408      1.155        350        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:45<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: AVG Box Loss: 0.9844 | AVG Cls Loss: 0.9408 | AVG DFL Loss: 1.1547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.752      0.742      0.794      0.538\n",
      "Epoch 11: AVG Val Box Loss: 1.0968 | AVG Val Cls Loss: 1.0303 | AVG Val DFL Loss: 1.1784 | Total Val Loss: 3.3055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      12.8G     0.9736     0.8505      1.147        375        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:39<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: AVG Box Loss: 0.9736 | AVG Cls Loss: 0.8505 | AVG DFL Loss: 1.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.841      0.722      0.818      0.574\n",
      "Epoch 12: AVG Val Box Loss: 1.0389 | AVG Val Cls Loss: 0.9668 | AVG Val DFL Loss: 1.1355 | Total Val Loss: 3.1412\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      12.8G      0.952     0.8177      1.134        392        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:39<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: AVG Box Loss: 0.9520 | AVG Cls Loss: 0.8177 | AVG DFL Loss: 1.1343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.799      0.764      0.834      0.571\n",
      "Epoch 13: AVG Val Box Loss: 1.0602 | AVG Val Cls Loss: 0.8906 | AVG Val DFL Loss: 1.1213 | Total Val Loss: 3.0722\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      12.8G     0.9441     0.7843      1.127        397        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:38<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: AVG Box Loss: 0.9441 | AVG Cls Loss: 0.7843 | AVG DFL Loss: 1.1267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.845      0.769      0.855      0.594\n",
      "Epoch 14: AVG Val Box Loss: 1.0237 | AVG Val Cls Loss: 0.8517 | AVG Val DFL Loss: 1.0918 | Total Val Loss: 2.9673\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      12.8G     0.9346     0.7613      1.122        385        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:35<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: AVG Box Loss: 0.9346 | AVG Cls Loss: 0.7613 | AVG DFL Loss: 1.1221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.844      0.756      0.851      0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: AVG Val Box Loss: 0.9925 | AVG Val Cls Loss: 0.8512 | AVG Val DFL Loss: 1.0872 | Total Val Loss: 2.9309\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      12.8G     0.9241      0.745      1.121        371        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:36<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: AVG Box Loss: 0.9241 | AVG Cls Loss: 0.7450 | AVG DFL Loss: 1.1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.866      0.751      0.849      0.593\n",
      "Epoch 16: AVG Val Box Loss: 1.0453 | AVG Val Cls Loss: 0.8556 | AVG Val DFL Loss: 1.1059 | Total Val Loss: 3.0068\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      12.8G     0.9176     0.7288      1.111        371        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:37<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: AVG Box Loss: 0.9176 | AVG Cls Loss: 0.7288 | AVG DFL Loss: 1.1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.821      0.781      0.857      0.606\n",
      "Epoch 17: AVG Val Box Loss: 1.0049 | AVG Val Cls Loss: 0.8494 | AVG Val DFL Loss: 1.0995 | Total Val Loss: 2.9538\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      12.8G     0.9139     0.7146      1.112        408        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:35<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: AVG Box Loss: 0.9139 | AVG Cls Loss: 0.7146 | AVG DFL Loss: 1.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.829      0.728      0.835      0.578\n",
      "Epoch 18: AVG Val Box Loss: 1.0530 | AVG Val Cls Loss: 0.9185 | AVG Val DFL Loss: 1.1162 | Total Val Loss: 3.0877\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      12.8G     0.9016     0.6872      1.101        416        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:35<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: AVG Box Loss: 0.9016 | AVG Cls Loss: 0.6872 | AVG DFL Loss: 1.1012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.845      0.768      0.859      0.606\n",
      "Epoch 19: AVG Val Box Loss: 1.0121 | AVG Val Cls Loss: 0.8196 | AVG Val DFL Loss: 1.0863 | Total Val Loss: 2.9180\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      12.8G     0.8947     0.6765        1.1        362        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:37<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: AVG Box Loss: 0.8947 | AVG Cls Loss: 0.6765 | AVG DFL Loss: 1.1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.849      0.792      0.874      0.622\n",
      "Epoch 20: AVG Val Box Loss: 1.0178 | AVG Val Cls Loss: 0.7924 | AVG Val DFL Loss: 1.0893 | Total Val Loss: 2.8994\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 0.627 hours.\n",
      "\n",
      "Validating Validation Data runs/detect/train6/weights/best.pt...\n",
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "YOLO11n summary (fused): 164 layers, 2,905,382 parameters, 0 gradients, 7.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.848      0.791      0.874      0.622\n",
      "                   Cat        140        144      0.933      0.847      0.956      0.727\n",
      "                Cattle        140        174      0.863      0.879      0.914      0.669\n",
      "               Chicken        140        313      0.879      0.768       0.87      0.613\n",
      "                  Deer        140        189      0.753      0.894      0.885      0.671\n",
      "                   Dog        140        169      0.769      0.811      0.871       0.52\n",
      "              Squirrel        140        143      0.745      0.818      0.846      0.574\n",
      "                 Eagle        140        156      0.915      0.808      0.907      0.746\n",
      "                  Goat        140        186      0.801      0.758      0.826      0.597\n",
      "               Rodents        140        155      0.887      0.677      0.836      0.593\n",
      "                 Snake        140        152      0.934      0.655      0.827      0.508\n",
      "Per-class IoU and Accuracy:\n",
      "          Cat: IoU: 0.879 | Accuracy: 0.818\n",
      "          Cattle: IoU: 0.859 | Accuracy: 0.798\n",
      "          Chicken: IoU: 0.854 | Accuracy: 0.769\n",
      "          Deer: IoU: 0.870 | Accuracy: 0.769\n",
      "          Dog: IoU: 0.805 | Accuracy: 0.736\n",
      "          Squirrel: IoU: 0.830 | Accuracy: 0.674\n",
      "          Eagle: IoU: 0.903 | Accuracy: 0.796\n",
      "          Goat: IoU: 0.863 | Accuracy: 0.676\n",
      "          Rodents: IoU: 0.866 | Accuracy: 0.620\n",
      "          Snake: IoU: 0.827 | Accuracy: 0.677\n",
      "          Background Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.0ms preprocess, 0.6ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train6\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 21:32:58,652] Trial 5 finished with value: 0.6219 and parameters: {'lr0': 0.00023011132047855642, 'lrf': 0.9896139689201932, 'weight_decay': 0.007401877331116337, 'warmup_momentum': 0.6585499877941675, 'momentum': 0.9158865006538601}. Best is trial 1 with value: 0.6345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mtrainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/working/data.yaml, epochs=20, time=None, patience=4, batch=352, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=7.259905948873614e-05, lrf=0.4816424394751877, momentum=0.8351460076661097, weight_decay=0.00042812689683553474, warmup_epochs=3, warmup_momentum=0.8757616092098787, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train7\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  blocks.Conv                                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  blocks.Conv                                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  blocks.C3k2                                  [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  blocks.C3k2                                  [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  blocks.C3k2                                  [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  blocks.Conv                                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  blocks.C3k2                                  [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  blocks.SPPF                                  [256, 256, 5]                 \n",
      " 10                  -1  1    249728  blocks.C2PSA                                 [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  blocks.Concat                                [1]                           \n",
      " 13                  -1  1    111296  blocks.C3k2                                  [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  blocks.Concat                                [1]                           \n",
      " 16                  -1  1     32096  blocks.C3k2                                  [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  blocks.Concat                                [1]                           \n",
      " 19                  -1  1     86720  blocks.C3k2                                  [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  blocks.Concat                                [1]                           \n",
      " 22                  -1  1    378880  blocks.C3k2                                  [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    753262  blocks.Detect                                [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 239 layers, 2,912,430 parameters, 2,912,414 gradients, 7.7 GFLOPs\n",
      "\n",
      "Transferred 421/463 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train7', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train.cache... 20000 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 1400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train7/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=7.259905948873614e-05, momentum=0.8351460076661097) with parameter groups 75 weight(decay=0.0), 82 weight(decay=0.002354697932595441), 81 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train7\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      13.2G      1.187      3.089      1.272        863        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:48<00:00,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: AVG Box Loss: 1.1874 | AVG Cls Loss: 3.0890 | AVG DFL Loss: 1.2716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.257       0.23      0.178      0.105\n",
      "Epoch 1: AVG Val Box Loss: 1.4981 | AVG Val Cls Loss: 3.2365 | AVG Val DFL Loss: 1.3363 | Total Val Loss: 6.0709\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      13.1G      1.181      2.389      1.252        832        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:41<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: AVG Box Loss: 1.1806 | AVG Cls Loss: 2.3894 | AVG DFL Loss: 1.2523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.374      0.397      0.363      0.225\n",
      "Epoch 2: AVG Val Box Loss: 1.2679 | AVG Val Cls Loss: 2.3244 | AVG Val DFL Loss: 1.2455 | Total Val Loss: 4.8379\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      13.1G      1.166      1.983      1.242        840        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:39<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: AVG Box Loss: 1.1658 | AVG Cls Loss: 1.9828 | AVG DFL Loss: 1.2417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.628      0.615      0.643      0.419\n",
      "Epoch 3: AVG Val Box Loss: 1.1561 | AVG Val Cls Loss: 1.6131 | AVG Val DFL Loss: 1.1942 | Total Val Loss: 3.9634\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      12.8G      1.124      1.766      1.224        917        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:42<00:00,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: AVG Box Loss: 1.1236 | AVG Cls Loss: 1.7660 | AVG DFL Loss: 1.2239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.734       0.64      0.722      0.481\n",
      "Epoch 4: AVG Val Box Loss: 1.1004 | AVG Val Cls Loss: 1.3384 | AVG Val DFL Loss: 1.1643 | Total Val Loss: 3.6032\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      12.8G      1.109      1.645      1.214        881        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:40<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: AVG Box Loss: 1.1087 | AVG Cls Loss: 1.6446 | AVG DFL Loss: 1.2144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781       0.76      0.688      0.753       0.51\n",
      "Epoch 5: AVG Val Box Loss: 1.1052 | AVG Val Cls Loss: 1.2147 | AVG Val DFL Loss: 1.1578 | Total Val Loss: 3.4777\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      12.8G      1.093      1.556      1.207        888        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:40<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: AVG Box Loss: 1.0927 | AVG Cls Loss: 1.5558 | AVG DFL Loss: 1.2069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.776      0.702      0.779      0.525\n",
      "Epoch 6: AVG Val Box Loss: 1.0817 | AVG Val Cls Loss: 1.1285 | AVG Val DFL Loss: 1.1396 | Total Val Loss: 3.3498\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      12.8G       1.08      1.497        1.2        908        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:39<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: AVG Box Loss: 1.0800 | AVG Cls Loss: 1.4970 | AVG DFL Loss: 1.2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.801      0.724      0.805      0.543\n",
      "Epoch 7: AVG Val Box Loss: 1.0815 | AVG Val Cls Loss: 1.0441 | AVG Val DFL Loss: 1.1431 | Total Val Loss: 3.2686\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      12.8G      1.071      1.443        1.2        859        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:44<00:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: AVG Box Loss: 1.0710 | AVG Cls Loss: 1.4431 | AVG DFL Loss: 1.1998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.805      0.742      0.817       0.56\n",
      "Epoch 8: AVG Val Box Loss: 1.0588 | AVG Val Cls Loss: 1.0080 | AVG Val DFL Loss: 1.1255 | Total Val Loss: 3.1922\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      12.8G      1.066       1.41      1.199        925        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:45<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: AVG Box Loss: 1.0656 | AVG Cls Loss: 1.4098 | AVG DFL Loss: 1.1991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.829      0.724       0.82       0.56\n",
      "Epoch 9: AVG Val Box Loss: 1.0677 | AVG Val Cls Loss: 1.0141 | AVG Val DFL Loss: 1.1332 | Total Val Loss: 3.2150\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      12.8G      1.056      1.373      1.193        908        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:44<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: AVG Box Loss: 1.0562 | AVG Cls Loss: 1.3730 | AVG DFL Loss: 1.1929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.824      0.719      0.824       0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: AVG Val Box Loss: 1.0789 | AVG Val Cls Loss: 1.0011 | AVG Val DFL Loss: 1.1333 | Total Val Loss: 3.2133\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      13.1G     0.9921      1.124       1.16        350        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:50<00:00,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: AVG Box Loss: 0.9921 | AVG Cls Loss: 1.1236 | AVG DFL Loss: 1.1599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.807      0.745      0.822      0.569\n",
      "Epoch 11: AVG Val Box Loss: 1.0448 | AVG Val Cls Loss: 1.0113 | AVG Val DFL Loss: 1.1226 | Total Val Loss: 3.1786\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      12.8G     0.9665      1.003      1.142        375        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:39<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: AVG Box Loss: 0.9665 | AVG Cls Loss: 1.0034 | AVG DFL Loss: 1.1422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.832      0.763       0.84       0.59\n",
      "Epoch 12: AVG Val Box Loss: 1.0140 | AVG Val Cls Loss: 0.9309 | AVG Val DFL Loss: 1.0955 | Total Val Loss: 3.0404\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      12.8G     0.9535     0.9482      1.133        392        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:39<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: AVG Box Loss: 0.9535 | AVG Cls Loss: 0.9482 | AVG DFL Loss: 1.1329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.825      0.767      0.846      0.593\n",
      "Epoch 13: AVG Val Box Loss: 1.0235 | AVG Val Cls Loss: 0.8896 | AVG Val DFL Loss: 1.0961 | Total Val Loss: 3.0091\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      12.8G     0.9448     0.9142      1.129        397        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:41<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: AVG Box Loss: 0.9448 | AVG Cls Loss: 0.9142 | AVG DFL Loss: 1.1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.841       0.78      0.855      0.608\n",
      "Epoch 14: AVG Val Box Loss: 1.0012 | AVG Val Cls Loss: 0.8718 | AVG Val DFL Loss: 1.0872 | Total Val Loss: 2.9602\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      12.8G     0.9373     0.8827       1.12        385        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:36<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: AVG Box Loss: 0.9373 | AVG Cls Loss: 0.8827 | AVG DFL Loss: 1.1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.859      0.764      0.858      0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: AVG Val Box Loss: 0.9958 | AVG Val Cls Loss: 0.8634 | AVG Val DFL Loss: 1.0855 | Total Val Loss: 2.9446\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      12.8G      0.925     0.8582      1.119        371        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:37<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: AVG Box Loss: 0.9250 | AVG Cls Loss: 0.8582 | AVG DFL Loss: 1.1188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.848      0.783      0.863      0.615\n",
      "Epoch 16: AVG Val Box Loss: 0.9963 | AVG Val Cls Loss: 0.8420 | AVG Val DFL Loss: 1.0854 | Total Val Loss: 2.9237\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      12.8G      0.923     0.8383      1.113        371        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:40<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: AVG Box Loss: 0.9230 | AVG Cls Loss: 0.8383 | AVG DFL Loss: 1.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.841      0.793      0.866      0.613\n",
      "Epoch 17: AVG Val Box Loss: 0.9949 | AVG Val Cls Loss: 0.8287 | AVG Val DFL Loss: 1.0800 | Total Val Loss: 2.9036\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      12.8G     0.9163     0.8228      1.112        408        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:41<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: AVG Box Loss: 0.9163 | AVG Cls Loss: 0.8228 | AVG DFL Loss: 1.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.859      0.787      0.868      0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: AVG Val Box Loss: 0.9805 | AVG Val Cls Loss: 0.8132 | AVG Val DFL Loss: 1.0702 | Total Val Loss: 2.8639\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      12.8G     0.9063     0.7996      1.101        416        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:49<00:00,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: AVG Box Loss: 0.9063 | AVG Cls Loss: 0.7996 | AVG DFL Loss: 1.1014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  7.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.853      0.791      0.867      0.613\n",
      "Epoch 19: AVG Val Box Loss: 0.9846 | AVG Val Cls Loss: 0.8074 | AVG Val DFL Loss: 1.0694 | Total Val Loss: 2.8613\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      12.8G     0.9008      0.782      1.101        362        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:51<00:00,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: AVG Box Loss: 0.9008 | AVG Cls Loss: 0.7820 | AVG DFL Loss: 1.1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781       0.86      0.799      0.881      0.628\n",
      "Epoch 20: AVG Val Box Loss: 0.9766 | AVG Val Cls Loss: 0.7820 | AVG Val DFL Loss: 1.0668 | Total Val Loss: 2.8254\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 0.654 hours.\n",
      "\n",
      "Validating Validation Data runs/detect/train7/weights/best.pt...\n",
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "YOLO11n summary (fused): 164 layers, 2,905,382 parameters, 0 gradients, 7.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.861      0.798      0.881      0.628\n",
      "                   Cat        140        144      0.901      0.938      0.966      0.764\n",
      "                Cattle        140        174       0.87       0.81      0.898      0.667\n",
      "               Chicken        140        313      0.909      0.764      0.871      0.604\n",
      "                  Deer        140        189       0.87      0.878       0.92      0.695\n",
      "                   Dog        140        169      0.807      0.769      0.855      0.503\n",
      "              Squirrel        140        143      0.876      0.789      0.886      0.607\n",
      "                 Eagle        140        156      0.922      0.814      0.917      0.743\n",
      "                  Goat        140        186      0.789      0.723      0.823      0.565\n",
      "               Rodents        140        155      0.848      0.722      0.832      0.582\n",
      "                 Snake        140        152      0.819      0.774      0.842      0.549\n",
      "Per-class IoU and Accuracy:\n",
      "          Cat: IoU: 0.886 | Accuracy: 0.866\n",
      "          Cattle: IoU: 0.871 | Accuracy: 0.753\n",
      "          Chicken: IoU: 0.850 | Accuracy: 0.792\n",
      "          Deer: IoU: 0.873 | Accuracy: 0.821\n",
      "          Dog: IoU: 0.810 | Accuracy: 0.683\n",
      "          Squirrel: IoU: 0.848 | Accuracy: 0.747\n",
      "          Eagle: IoU: 0.898 | Accuracy: 0.819\n",
      "          Goat: IoU: 0.850 | Accuracy: 0.633\n",
      "          Rodents: IoU: 0.849 | Accuracy: 0.695\n",
      "          Snake: IoU: 0.819 | Accuracy: 0.776\n",
      "          Background Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.0ms preprocess, 0.6ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train7\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:12:48,941] Trial 6 finished with value: 0.6281 and parameters: {'lr0': 7.259905948873614e-05, 'lrf': 0.4816424394751877, 'weight_decay': 0.00042812689683553474, 'warmup_momentum': 0.8757616092098787, 'momentum': 0.8351460076661097}. Best is trial 1 with value: 0.6345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mtrainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/working/data.yaml, epochs=20, time=None, patience=4, batch=352, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train8, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0004529506023955361, lrf=0.20616715247573278, momentum=0.9045523548224818, weight_decay=0.009595920293773862, warmup_epochs=3, warmup_momentum=0.6787859275065684, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train8\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  blocks.Conv                                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  blocks.Conv                                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  blocks.C3k2                                  [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  blocks.C3k2                                  [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  blocks.C3k2                                  [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  blocks.Conv                                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  blocks.C3k2                                  [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  blocks.SPPF                                  [256, 256, 5]                 \n",
      " 10                  -1  1    249728  blocks.C2PSA                                 [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  blocks.Concat                                [1]                           \n",
      " 13                  -1  1    111296  blocks.C3k2                                  [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  blocks.Concat                                [1]                           \n",
      " 16                  -1  1     32096  blocks.C3k2                                  [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  blocks.Concat                                [1]                           \n",
      " 19                  -1  1     86720  blocks.C3k2                                  [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  blocks.Concat                                [1]                           \n",
      " 22                  -1  1    378880  blocks.C3k2                                  [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    753262  blocks.Detect                                [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 239 layers, 2,912,430 parameters, 2,912,414 gradients, 7.7 GFLOPs\n",
      "\n",
      "Transferred 421/463 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train8', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train.cache... 20000 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 1400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train8/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0004529506023955361, momentum=0.9045523548224818) with parameter groups 75 weight(decay=0.0), 82 weight(decay=0.05277756161575624), 81 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train8\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      13.2G      1.202      2.952      1.282        863        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [02:04<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: AVG Box Loss: 1.2020 | AVG Cls Loss: 2.9518 | AVG DFL Loss: 1.2818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.372      0.308      0.257      0.156\n",
      "Epoch 1: AVG Val Box Loss: 1.4209 | AVG Val Cls Loss: 3.1075 | AVG Val DFL Loss: 1.3834 | Total Val Loss: 5.9118\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      13.1G      1.183      1.953      1.251        832        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [02:00<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: AVG Box Loss: 1.1830 | AVG Cls Loss: 1.9525 | AVG DFL Loss: 1.2515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781        0.5      0.487      0.472      0.289\n",
      "Epoch 2: AVG Val Box Loss: 1.2346 | AVG Val Cls Loss: 2.2129 | AVG Val DFL Loss: 1.2461 | Total Val Loss: 4.6936\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      13.1G      1.157      1.626      1.241        840        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:57<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: AVG Box Loss: 1.1569 | AVG Cls Loss: 1.6260 | AVG DFL Loss: 1.2414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.592      0.509      0.513      0.325\n",
      "Epoch 3: AVG Val Box Loss: 1.2522 | AVG Val Cls Loss: 2.0270 | AVG Val DFL Loss: 1.3274 | Total Val Loss: 4.6066\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:20:18,483] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mtrainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/working/data.yaml, epochs=20, time=None, patience=4, batch=352, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train9, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=5.604733126757513e-05, lrf=0.9027991056314836, momentum=0.971330729500081, weight_decay=0.009292684892974117, warmup_epochs=3, warmup_momentum=0.8892649564175328, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train9\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  blocks.Conv                                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  blocks.Conv                                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  blocks.C3k2                                  [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  blocks.C3k2                                  [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  blocks.C3k2                                  [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  blocks.Conv                                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  blocks.C3k2                                  [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  blocks.SPPF                                  [256, 256, 5]                 \n",
      " 10                  -1  1    249728  blocks.C2PSA                                 [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  blocks.Concat                                [1]                           \n",
      " 13                  -1  1    111296  blocks.C3k2                                  [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  blocks.Concat                                [1]                           \n",
      " 16                  -1  1     32096  blocks.C3k2                                  [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  blocks.Concat                                [1]                           \n",
      " 19                  -1  1     86720  blocks.C3k2                                  [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  blocks.Concat                                [1]                           \n",
      " 22                  -1  1    378880  blocks.C3k2                                  [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    753262  blocks.Detect                                [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 239 layers, 2,912,430 parameters, 2,912,414 gradients, 7.7 GFLOPs\n",
      "\n",
      "Transferred 421/463 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train9', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train.cache... 20000 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 1400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train9/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=5.604733126757513e-05, momentum=0.971330729500081) with parameter groups 75 weight(decay=0.0), 82 weight(decay=0.05110976691135764), 81 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train9\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      14.6G      1.201      3.169      1.278        863        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [02:04<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: AVG Box Loss: 1.2013 | AVG Cls Loss: 3.1695 | AVG DFL Loss: 1.2776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781     0.0105      0.751     0.0841     0.0492\n",
      "Epoch 1: AVG Val Box Loss: 1.4965 | AVG Val Cls Loss: 3.3457 | AVG Val DFL Loss: 1.3727 | Total Val Loss: 6.2150\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      13.1G      1.176      2.663      1.238        832        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [02:00<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: AVG Box Loss: 1.1759 | AVG Cls Loss: 2.6632 | AVG DFL Loss: 1.2380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.352      0.384        0.3      0.184\n",
      "Epoch 2: AVG Val Box Loss: 1.2958 | AVG Val Cls Loss: 2.6741 | AVG Val DFL Loss: 1.2463 | Total Val Loss: 5.2163\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      13.1G      1.169      2.315       1.24        840        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:58<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: AVG Box Loss: 1.1692 | AVG Cls Loss: 2.3145 | AVG DFL Loss: 1.2397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:16<00:00,  8.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.426      0.513      0.492      0.319\n",
      "Epoch 3: AVG Val Box Loss: 1.1759 | AVG Val Cls Loss: 2.1517 | AVG Val DFL Loss: 1.1941 | Total Val Loss: 4.5217\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:27:54,103] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mtrainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/working/data.yaml, epochs=20, time=None, patience=4, batch=352, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train10, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=1.949667562215962e-05, lrf=0.1572258631360501, momentum=0.9230239959390067, weight_decay=0.007893138273469115, warmup_epochs=3, warmup_momentum=0.8095289052889183, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train10\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  blocks.Conv                                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  blocks.Conv                                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  blocks.C3k2                                  [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  blocks.C3k2                                  [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  blocks.C3k2                                  [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  blocks.Conv                                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  blocks.C3k2                                  [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  blocks.SPPF                                  [256, 256, 5]                 \n",
      " 10                  -1  1    249728  blocks.C2PSA                                 [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  blocks.Concat                                [1]                           \n",
      " 13                  -1  1    111296  blocks.C3k2                                  [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  blocks.Concat                                [1]                           \n",
      " 16                  -1  1     32096  blocks.C3k2                                  [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  blocks.Concat                                [1]                           \n",
      " 19                  -1  1     86720  blocks.C3k2                                  [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  blocks.Concat                                [1]                           \n",
      " 22                  -1  1    378880  blocks.C3k2                                  [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    753262  blocks.Detect                                [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 239 layers, 2,912,430 parameters, 2,912,414 gradients, 7.7 GFLOPs\n",
      "\n",
      "Transferred 421/463 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train10', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train.cache... 20000 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 1400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train10/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=1.949667562215962e-05, momentum=0.9230239959390067) with parameter groups 75 weight(decay=0.0), 82 weight(decay=0.04341226050408013), 81 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train10\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      14.6G      1.192      3.159      1.275        863        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [02:04<00:00,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: AVG Box Loss: 1.1916 | AVG Cls Loss: 3.1594 | AVG DFL Loss: 1.2749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781    0.00595      0.766      0.101     0.0556\n",
      "Epoch 1: AVG Val Box Loss: 1.5114 | AVG Val Cls Loss: 3.3018 | AVG Val DFL Loss: 1.3556 | Total Val Loss: 6.1688\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      13.1G      1.166      2.708      1.237        832        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [02:03<00:00,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: AVG Box Loss: 1.1661 | AVG Cls Loss: 2.7083 | AVG DFL Loss: 1.2374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.394      0.203      0.241      0.154\n",
      "Epoch 2: AVG Val Box Loss: 1.2869 | AVG Val Cls Loss: 2.7556 | AVG Val DFL Loss: 1.2367 | Total Val Loss: 5.2792\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      13.1G      1.166      2.453      1.244        840        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:57<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: AVG Box Loss: 1.1663 | AVG Cls Loss: 2.4531 | AVG DFL Loss: 1.2439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  7.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781       0.35      0.488      0.429      0.278\n",
      "Epoch 3: AVG Val Box Loss: 1.1751 | AVG Val Cls Loss: 2.1665 | AVG Val DFL Loss: 1.2038 | Total Val Loss: 4.5453\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:35:25,896] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mtrainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/working/data.yaml, epochs=20, time=None, patience=4, batch=352, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train11, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=1.9172602198912764e-05, lrf=0.28180075310157177, momentum=0.9830608531409043, weight_decay=0.00010962146302924358, warmup_epochs=3, warmup_momentum=0.5600049696615275, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train11\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  blocks.Conv                                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  blocks.Conv                                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  blocks.C3k2                                  [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  blocks.C3k2                                  [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  blocks.C3k2                                  [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  blocks.Conv                                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  blocks.C3k2                                  [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  blocks.SPPF                                  [256, 256, 5]                 \n",
      " 10                  -1  1    249728  blocks.C2PSA                                 [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  blocks.Concat                                [1]                           \n",
      " 13                  -1  1    111296  blocks.C3k2                                  [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  blocks.Concat                                [1]                           \n",
      " 16                  -1  1     32096  blocks.C3k2                                  [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  blocks.Concat                                [1]                           \n",
      " 19                  -1  1     86720  blocks.C3k2                                  [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  blocks.Concat                                [1]                           \n",
      " 22                  -1  1    378880  blocks.C3k2                                  [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    753262  blocks.Detect                                [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 239 layers, 2,912,430 parameters, 2,912,414 gradients, 7.7 GFLOPs\n",
      "\n",
      "Transferred 421/463 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train11', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train.cache... 20000 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 1400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train11/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=1.9172602198912764e-05, momentum=0.9830608531409043) with parameter groups 75 weight(decay=0.0), 82 weight(decay=0.0006029180466608397), 81 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train11\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      14.6G      1.206      3.204      1.285        863        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:59<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: AVG Box Loss: 1.2061 | AVG Cls Loss: 3.2038 | AVG DFL Loss: 1.2846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781    0.00676      0.686     0.0481     0.0226\n",
      "Epoch 1: AVG Val Box Loss: 1.9202 | AVG Val Cls Loss: 3.5713 | AVG Val DFL Loss: 1.6921 | Total Val Loss: 7.1837\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      13.1G      1.182       2.82      1.234        832        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:58<00:00,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: AVG Box Loss: 1.1821 | AVG Cls Loss: 2.8196 | AVG DFL Loss: 1.2343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.236      0.207      0.141     0.0811\n",
      "Epoch 2: AVG Val Box Loss: 1.4039 | AVG Val Cls Loss: 3.2373 | AVG Val DFL Loss: 1.4347 | Total Val Loss: 6.0759\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      13.1G      1.169      2.622      1.233        840        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:57<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: AVG Box Loss: 1.1685 | AVG Cls Loss: 2.6221 | AVG DFL Loss: 1.2327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.305      0.401      0.344      0.222\n",
      "Epoch 3: AVG Val Box Loss: 1.1772 | AVG Val Cls Loss: 2.4832 | AVG Val DFL Loss: 1.2205 | Total Val Loss: 4.8810\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:42:49,752] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mtrainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/working/data.yaml, epochs=20, time=None, patience=4, batch=352, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train12, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.00012372688710696615, lrf=0.4622168339216165, momentum=0.9484411507987619, weight_decay=0.00017261396416277358, warmup_epochs=3, warmup_momentum=0.6417351285384706, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train12\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  blocks.Conv                                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  blocks.Conv                                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  blocks.C3k2                                  [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  blocks.C3k2                                  [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  blocks.C3k2                                  [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  blocks.Conv                                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  blocks.C3k2                                  [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  blocks.SPPF                                  [256, 256, 5]                 \n",
      " 10                  -1  1    249728  blocks.C2PSA                                 [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  blocks.Concat                                [1]                           \n",
      " 13                  -1  1    111296  blocks.C3k2                                  [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  blocks.Concat                                [1]                           \n",
      " 16                  -1  1     32096  blocks.C3k2                                  [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  blocks.Concat                                [1]                           \n",
      " 19                  -1  1     86720  blocks.C3k2                                  [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  blocks.Concat                                [1]                           \n",
      " 22                  -1  1    378880  blocks.C3k2                                  [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    753262  blocks.Detect                                [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 239 layers, 2,912,430 parameters, 2,912,414 gradients, 7.7 GFLOPs\n",
      "\n",
      "Transferred 421/463 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train12', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train.cache... 20000 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 1400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train12/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00012372688710696615, momentum=0.9484411507987619) with parameter groups 75 weight(decay=0.0), 82 weight(decay=0.0009493768028952547), 81 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train12\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      14.6G      1.199      3.122      1.276        863        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [02:01<00:00,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: AVG Box Loss: 1.1988 | AVG Cls Loss: 3.1218 | AVG DFL Loss: 1.2765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781     0.0123      0.737      0.135     0.0757\n",
      "Epoch 1: AVG Val Box Loss: 1.7690 | AVG Val Cls Loss: 3.3190 | AVG Val DFL Loss: 1.5263 | Total Val Loss: 6.6143\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:45:47,397] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mtrainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/working/data.yaml, epochs=20, time=None, patience=4, batch=352, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train13, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=8.540447187023972e-05, lrf=0.10088245888683312, momentum=0.8699987514525119, weight_decay=0.0003488605603197939, warmup_epochs=3, warmup_momentum=0.5859814155387131, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train13\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  blocks.Conv                                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  blocks.Conv                                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  blocks.C3k2                                  [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  blocks.C3k2                                  [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  blocks.C3k2                                  [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  blocks.Conv                                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  blocks.C3k2                                  [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  blocks.SPPF                                  [256, 256, 5]                 \n",
      " 10                  -1  1    249728  blocks.C2PSA                                 [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  blocks.Concat                                [1]                           \n",
      " 13                  -1  1    111296  blocks.C3k2                                  [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  blocks.Concat                                [1]                           \n",
      " 16                  -1  1     32096  blocks.C3k2                                  [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  blocks.Concat                                [1]                           \n",
      " 19                  -1  1     86720  blocks.C3k2                                  [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  blocks.Concat                                [1]                           \n",
      " 22                  -1  1    378880  blocks.C3k2                                  [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    753262  blocks.Detect                                [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 239 layers, 2,912,430 parameters, 2,912,414 gradients, 7.7 GFLOPs\n",
      "\n",
      "Transferred 421/463 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train13', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train.cache... 20000 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 1400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train13/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=8.540447187023972e-05, momentum=0.8699987514525119) with parameter groups 75 weight(decay=0.0), 82 weight(decay=0.0019187330817588665), 81 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train13\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      14.6G      1.187      3.097      1.273        863        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [02:03<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: AVG Box Loss: 1.1872 | AVG Cls Loss: 3.0970 | AVG DFL Loss: 1.2732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781    0.00986      0.723      0.129     0.0755\n",
      "Epoch 1: AVG Val Box Loss: 1.8105 | AVG Val Cls Loss: 3.4551 | AVG Val DFL Loss: 1.4946 | Total Val Loss: 6.7602\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:48:44,509] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mtrainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/working/data.yaml, epochs=20, time=None, patience=4, batch=352, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train14, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=3.6675920473761106e-05, lrf=0.36936354618814554, momentum=0.9427344065397084, weight_decay=0.0004771544332290633, warmup_epochs=3, warmup_momentum=0.8966232114802736, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train14\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  blocks.Conv                                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  blocks.Conv                                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  blocks.C3k2                                  [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  blocks.C3k2                                  [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  blocks.C3k2                                  [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  blocks.Conv                                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  blocks.C3k2                                  [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  blocks.SPPF                                  [256, 256, 5]                 \n",
      " 10                  -1  1    249728  blocks.C2PSA                                 [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  blocks.Concat                                [1]                           \n",
      " 13                  -1  1    111296  blocks.C3k2                                  [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  blocks.Concat                                [1]                           \n",
      " 16                  -1  1     32096  blocks.C3k2                                  [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  blocks.Concat                                [1]                           \n",
      " 19                  -1  1     86720  blocks.C3k2                                  [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  blocks.Concat                                [1]                           \n",
      " 22                  -1  1    378880  blocks.C3k2                                  [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    753262  blocks.Detect                                [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 239 layers, 2,912,430 parameters, 2,912,414 gradients, 7.7 GFLOPs\n",
      "\n",
      "Transferred 421/463 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train14', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train.cache... 20000 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 1400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train14/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=3.6675920473761106e-05, momentum=0.9427344065397084) with parameter groups 75 weight(decay=0.0), 82 weight(decay=0.002624349382759848), 81 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train14\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      14.6G      1.195      3.161      1.278        863        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:59<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: AVG Box Loss: 1.1947 | AVG Cls Loss: 3.1608 | AVG DFL Loss: 1.2780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781     0.0133      0.611     0.0722     0.0406\n",
      "Epoch 1: AVG Val Box Loss: 2.0074 | AVG Val Cls Loss: 3.6347 | AVG Val DFL Loss: 1.6705 | Total Val Loss: 7.3126\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 22:51:41,179] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mtrainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/working/data.yaml, epochs=20, time=None, patience=4, batch=352, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=train15, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.00016085912940390362, lrf=0.28483517884756543, momentum=0.8791173993410675, weight_decay=0.0009766184587345897, warmup_epochs=3, warmup_momentum=0.7872779644993031, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train15\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  blocks.Conv                                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  blocks.Conv                                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  blocks.C3k2                                  [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  blocks.C3k2                                  [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  blocks.C3k2                                  [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  blocks.Conv                                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  blocks.C3k2                                  [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  blocks.SPPF                                  [256, 256, 5]                 \n",
      " 10                  -1  1    249728  blocks.C2PSA                                 [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  blocks.Concat                                [1]                           \n",
      " 13                  -1  1    111296  blocks.C3k2                                  [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  blocks.Concat                                [1]                           \n",
      " 16                  -1  1     32096  blocks.C3k2                                  [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  blocks.Concat                                [1]                           \n",
      " 19                  -1  1     86720  blocks.C3k2                                  [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  blocks.Concat                                [1]                           \n",
      " 22                  -1  1    378880  blocks.C3k2                                  [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    753262  blocks.Detect                                [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 239 layers, 2,912,430 parameters, 2,912,414 gradients, 7.7 GFLOPs\n",
      "\n",
      "Transferred 421/463 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train15', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/train.cache... 20000 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/val.cache... 1400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train15/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00016085912940390362, momentum=0.8791173993410675) with parameter groups 75 weight(decay=0.0), 82 weight(decay=0.005371401523040243), 81 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train15\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      14.6G      1.195      3.055      1.276        863        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [02:01<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: AVG Box Loss: 1.1949 | AVG Cls Loss: 3.0551 | AVG DFL Loss: 1.2757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.686     0.0947        0.2      0.114\n",
      "Epoch 1: AVG Val Box Loss: 1.5729 | AVG Val Cls Loss: 3.2168 | AVG Val DFL Loss: 1.3563 | Total Val Loss: 6.1460\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      13.1G      1.179      2.202      1.246        832        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:57<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: AVG Box Loss: 1.1788 | AVG Cls Loss: 2.2018 | AVG DFL Loss: 1.2457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.502      0.472      0.451      0.287\n",
      "Epoch 2: AVG Val Box Loss: 1.2167 | AVG Val Cls Loss: 2.0664 | AVG Val DFL Loss: 1.2191 | Total Val Loss: 4.5022\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      13.1G      1.158      1.868      1.231       1117        320:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 21/57 [00:36<01:32,  2.58s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "       3/20      13.1G      1.157      1.865      1.231       1074        320:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 22/57 [00:40<01:39,  2.84s/it]\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "       3/20      13.1G      1.156      1.861       1.23        999        320:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/57 [00:43<01:11,  2.18s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():    \n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "       3/20      13.1G      1.155      1.794      1.228       1016        320:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53/57 [01:48<00:08,  2.18s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "       3/20      13.1G      1.152      1.785      1.227        840        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:55<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: AVG Box Loss: 1.1519 | AVG Cls Loss: 1.7851 | AVG DFL Loss: 1.2273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  7.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781       0.69      0.603       0.67      0.444\n",
      "Epoch 3: AVG Val Box Loss: 1.1419 | AVG Val Cls Loss: 1.4491 | AVG Val DFL Loss: 1.2008 | Total Val Loss: 3.7917\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      12.8G      1.108      1.613      1.212        997        320:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 32/57 [01:00<00:42,  1.71s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "AssertionError: can only test a child process\n",
      "       4/20      12.8G       1.11      1.588      1.213        917        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:59<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: AVG Box Loss: 1.1096 | AVG Cls Loss: 1.5883 | AVG DFL Loss: 1.2129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.755      0.668      0.752      0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: AVG Val Box Loss: 1.1150 | AVG Val Cls Loss: 1.2263 | AVG Val DFL Loss: 1.1545 | Total Val Loss: 3.4959\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      12.8G      1.093      1.483      1.207        881        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:59<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: AVG Box Loss: 1.0934 | AVG Cls Loss: 1.4825 | AVG DFL Loss: 1.2069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.797      0.693      0.786      0.533\n",
      "Epoch 5: AVG Val Box Loss: 1.0877 | AVG Val Cls Loss: 1.1141 | AVG Val DFL Loss: 1.1308 | Total Val Loss: 3.3326\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      12.8G      1.069      1.427      1.195       1099        320:   4%|â–         | 2/57 [00:02<01:10,  1.28s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "       6/20      12.8G      1.072      1.441      1.199       1006        320:   5%|â–Œ         | 3/57 [00:03<01:09,  1.29s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "       6/20      12.8G      1.074      1.405      1.199        888        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [02:01<00:00,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: AVG Box Loss: 1.0736 | AVG Cls Loss: 1.4047 | AVG DFL Loss: 1.1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.811      0.699      0.798      0.536\n",
      "Epoch 6: AVG Val Box Loss: 1.0750 | AVG Val Cls Loss: 1.0328 | AVG Val DFL Loss: 1.1367 | Total Val Loss: 3.2444\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/57 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       7/20      12.8G      1.076      1.374      1.183       1060        320:   0%|          | 0/57 [00:01<?, ?it/s]  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "       7/20      12.8G      1.076      1.374      1.183       1060        320:   2%|â–         | 1/57 [00:01<01:05,  1.17s/it]    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x794269022830>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "       7/20      12.8G      1.061      1.356      1.193        908        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:56<00:00,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: AVG Box Loss: 1.0607 | AVG Cls Loss: 1.3555 | AVG DFL Loss: 1.1926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  7.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.832      0.718      0.826      0.565\n",
      "Epoch 7: AVG Val Box Loss: 1.0655 | AVG Val Cls Loss: 0.9784 | AVG Val DFL Loss: 1.1354 | Total Val Loss: 3.1793\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      12.8G      1.053      1.308      1.192        859        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:56<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: AVG Box Loss: 1.0534 | AVG Cls Loss: 1.3082 | AVG DFL Loss: 1.1919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:15<00:00,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.814      0.771      0.834      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: AVG Val Box Loss: 1.0472 | AVG Val Cls Loss: 0.9438 | AVG Val DFL Loss: 1.1128 | Total Val Loss: 3.1038\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      12.8G      1.046      1.278      1.188        925        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:59<00:00,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: AVG Box Loss: 1.0463 | AVG Cls Loss: 1.2776 | AVG DFL Loss: 1.1876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:15<00:00,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.806      0.763      0.829      0.573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: AVG Val Box Loss: 1.0679 | AVG Val Cls Loss: 0.9477 | AVG Val DFL Loss: 1.1318 | Total Val Loss: 3.1475\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      12.8G      1.036      1.237      1.184        908        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:58<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: AVG Box Loss: 1.0365 | AVG Cls Loss: 1.2372 | AVG DFL Loss: 1.1838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.811      0.768      0.843      0.579\n",
      "Epoch 10: AVG Val Box Loss: 1.0596 | AVG Val Cls Loss: 0.9284 | AVG Val DFL Loss: 1.1227 | Total Val Loss: 3.1107\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      13.1G     0.9676      0.956      1.143        350        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [02:04<00:00,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: AVG Box Loss: 0.9676 | AVG Cls Loss: 0.9560 | AVG DFL Loss: 1.1428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  7.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.824      0.771      0.847      0.591\n",
      "Epoch 11: AVG Val Box Loss: 1.0311 | AVG Val Cls Loss: 0.9043 | AVG Val DFL Loss: 1.1133 | Total Val Loss: 3.0487\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      12.8G     0.9423     0.8559      1.127        375        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:56<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: AVG Box Loss: 0.9423 | AVG Cls Loss: 0.8559 | AVG DFL Loss: 1.1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781       0.83      0.784      0.858      0.611\n",
      "Epoch 12: AVG Val Box Loss: 1.0024 | AVG Val Cls Loss: 0.8508 | AVG Val DFL Loss: 1.0847 | Total Val Loss: 2.9379\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      12.8G      0.927     0.8113      1.117        392        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:57<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: AVG Box Loss: 0.9270 | AVG Cls Loss: 0.8113 | AVG DFL Loss: 1.1166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.843      0.808      0.878       0.62\n",
      "Epoch 13: AVG Val Box Loss: 0.9984 | AVG Val Cls Loss: 0.7965 | AVG Val DFL Loss: 1.0769 | Total Val Loss: 2.8718\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      12.8G     0.9167     0.7821      1.109        397        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:57<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: AVG Box Loss: 0.9167 | AVG Cls Loss: 0.7821 | AVG DFL Loss: 1.1086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.841      0.789       0.87      0.617\n",
      "Epoch 14: AVG Val Box Loss: 0.9934 | AVG Val Cls Loss: 0.8132 | AVG Val DFL Loss: 1.0738 | Total Val Loss: 2.8804\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      12.8G       0.91     0.7552      1.104        385        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:51<00:00,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: AVG Box Loss: 0.9100 | AVG Cls Loss: 0.7552 | AVG DFL Loss: 1.1036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.856      0.785      0.874      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: AVG Val Box Loss: 0.9789 | AVG Val Cls Loss: 0.7809 | AVG Val DFL Loss: 1.0691 | Total Val Loss: 2.8288\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      12.8G     0.8968      0.731      1.101        371        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:56<00:00,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: AVG Box Loss: 0.8968 | AVG Cls Loss: 0.7310 | AVG DFL Loss: 1.1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.862      0.814      0.883      0.642\n",
      "Epoch 16: AVG Val Box Loss: 0.9676 | AVG Val Cls Loss: 0.7565 | AVG Val DFL Loss: 1.0627 | Total Val Loss: 2.7868\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      12.8G      0.888      0.713      1.092        371        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:56<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: AVG Box Loss: 0.8880 | AVG Cls Loss: 0.7130 | AVG DFL Loss: 1.0918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.869      0.807      0.887      0.638\n",
      "Epoch 17: AVG Val Box Loss: 0.9556 | AVG Val Cls Loss: 0.7456 | AVG Val DFL Loss: 1.0575 | Total Val Loss: 2.7587\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      12.8G     0.8785     0.6938       1.09        408        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:55<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: AVG Box Loss: 0.8785 | AVG Cls Loss: 0.6938 | AVG DFL Loss: 1.0901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.869      0.827      0.894      0.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: AVG Val Box Loss: 0.9582 | AVG Val Cls Loss: 0.7198 | AVG Val DFL Loss: 1.0508 | Total Val Loss: 2.7288\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      12.8G     0.8688     0.6712      1.081        416        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:54<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: AVG Box Loss: 0.8688 | AVG Cls Loss: 0.6712 | AVG DFL Loss: 1.0806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781       0.88      0.815      0.894      0.645\n",
      "Epoch 19: AVG Val Box Loss: 0.9605 | AVG Val Cls Loss: 0.7208 | AVG Val DFL Loss: 1.0506 | Total Val Loss: 2.7318\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      12.8G      0.859     0.6595      1.076        362        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [01:57<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: AVG Box Loss: 0.8590 | AVG Cls Loss: 0.6595 | AVG DFL Loss: 1.0765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.888      0.819      0.904      0.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: AVG Val Box Loss: 0.9429 | AVG Val Cls Loss: 0.6884 | AVG Val DFL Loss: 1.0463 | Total Val Loss: 2.6776\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "20 epochs completed in 0.746 hours.\n",
      "\n",
      "Validating Validation Data runs/detect/train15/weights/best.pt...\n",
      "Ultralytics 8.3.98 ğŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "YOLO11n summary (fused): 164 layers, 2,905,382 parameters, 0 gradients, 7.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.889      0.815      0.904      0.658\n",
      "                   Cat        140        144      0.913      0.952      0.958      0.779\n",
      "                Cattle        140        174      0.909      0.793      0.922      0.693\n",
      "               Chicken        140        313      0.923      0.764      0.893      0.642\n",
      "                  Deer        140        189      0.912      0.881      0.933      0.699\n",
      "                   Dog        140        169      0.885      0.777      0.894      0.544\n",
      "              Squirrel        140        143      0.865      0.803      0.886      0.641\n",
      "                 Eagle        140        156      0.942      0.827      0.941      0.767\n",
      "                  Goat        140        186       0.82      0.785      0.871      0.615\n",
      "               Rodents        140        155      0.857      0.772      0.867      0.606\n",
      "                 Snake        140        152      0.866      0.796      0.877      0.589\n",
      "Per-class IoU and Accuracy:\n",
      "          Cat: IoU: 0.893 | Accuracy: 0.916\n",
      "          Cattle: IoU: 0.875 | Accuracy: 0.804\n",
      "          Chicken: IoU: 0.856 | Accuracy: 0.824\n",
      "          Deer: IoU: 0.873 | Accuracy: 0.854\n",
      "          Dog: IoU: 0.815 | Accuracy: 0.730\n",
      "          Squirrel: IoU: 0.853 | Accuracy: 0.747\n",
      "          Eagle: IoU: 0.908 | Accuracy: 0.814\n",
      "          Goat: IoU: 0.857 | Accuracy: 0.729\n",
      "          Rodents: IoU: 0.856 | Accuracy: 0.767\n",
      "          Snake: IoU: 0.829 | Accuracy: 0.791\n",
      "          Background Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.0ms preprocess, 0.6ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train15\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-28 23:37:19,450] Trial 14 finished with value: 0.6582 and parameters: {'lr0': 0.00016085912940390362, 'lrf': 0.28483517884756543, 'weight_decay': 0.0009766184587345897, 'warmup_momentum': 0.7872779644993031, 'momentum': 0.8791173993410675}. Best is trial 14 with value: 0.6582.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/optuna_study.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "NUM_TRIALS = 15\n",
    "\n",
    "# load the study\n",
    "study = optuna.create_study(direction='maximize', \n",
    "                            sampler=optuna.samplers.TPESampler(), \n",
    "                            pruner=optuna.pruners.HyperbandPruner(),\n",
    "                            study_name=\"yolo11_tuning\",\n",
    "                            load_if_exists=True)\n",
    "\n",
    "# Optimize with a callback to stop after NUM_TRIALS complete trials\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=NUM_TRIALS)\n",
    "\n",
    "joblib.dump(study, \"/kaggle/working/optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33489308",
   "metadata": {
    "papermill": {
     "duration": 1.188225,
     "end_time": "2025-03-28T23:37:21.737636",
     "exception": false,
     "start_time": "2025-03-28T23:37:20.549411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16906.957176,
   "end_time": "2025-03-28T23:37:27.680329",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-28T18:55:40.723153",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "149833fa3f2a4decadeb9fdd8016f81d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "651ec8ee866e4c08a4fe206a9c6d576c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7625b534144d40e5bf919faea041261e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ffab7b6f665e4263a01667d5463c3c6d",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_d7ab6b75f9fd47a28614748c4466c602",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡9.57G/9.57Gâ€‡[00:41&lt;00:00,â€‡262MB/s]"
      }
     },
     "8e028835304644d3ad5484337126b917": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cc5e8d61348a4c13a5ed0bbc974c1039",
        "IPY_MODEL_e494f3a80fea4b2db94261ec7023e03b",
        "IPY_MODEL_7625b534144d40e5bf919faea041261e"
       ],
       "layout": "IPY_MODEL_f70fc7e1eaf74250aa489c690a808df8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "cc5e8d61348a4c13a5ed0bbc974c1039": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d8cb941ee8de49c291112ee8efcba648",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_f2950c0cdfc14a8b84884cd315b0b652",
       "tabbable": null,
       "tooltip": null,
       "value": "dataset.zip:â€‡100%"
      }
     },
     "d7ab6b75f9fd47a28614748c4466c602": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d8cb941ee8de49c291112ee8efcba648": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e494f3a80fea4b2db94261ec7023e03b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_651ec8ee866e4c08a4fe206a9c6d576c",
       "max": 9569453176.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_149833fa3f2a4decadeb9fdd8016f81d",
       "tabbable": null,
       "tooltip": null,
       "value": 9569453176.0
      }
     },
     "f2950c0cdfc14a8b84884cd315b0b652": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f70fc7e1eaf74250aa489c690a808df8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ffab7b6f665e4263a01667d5463c3c6d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
