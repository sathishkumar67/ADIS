{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U albumentations ultralytics optuna huggingface_hub\n",
    "!git clone https://github.com/sathishkumar67/ADIS.git\n",
    "!mv /teamspace/studios/this_studio/ADIS/* /teamspace/studios/this_studio/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
      "View Ultralytics Settings with 'yolo settings' or at '/teamspace/studios/this_studio/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "# necessary imports\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import joblib\n",
    "import optuna\n",
    "from huggingface_hub import hf_hub_download\n",
    "from utils import unzip_file\n",
    "from model import YOLO11Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the global variables\n",
    "REPO_ID = \"pt-sk/ADIS\" \n",
    "FILENAME_IN_REPO = \"dataset.zip\"\n",
    "LOCAL_DIR = os.getcwd()\n",
    "TRAIN_PATH = f\"{LOCAL_DIR}/dataset/train\"\n",
    "VAL_PATH = f\"{LOCAL_DIR}/dataset/val\"\n",
    "TEST_PATH = f\"{LOCAL_DIR}/dataset/test\"\n",
    "DATASET_PATH = f\"{LOCAL_DIR}/{FILENAME_IN_REPO}\"\n",
    "REPO_TYPE = \"dataset\"\n",
    "NUM_CLASSES = 10                                               \n",
    "CLASSES = ['Cat', 'Cattle', 'Chicken', 'Deer', 'Dog', \"Squirrel\", 'Eagle', 'Goat', 'Rodents', 'Snake'] \n",
    "DATA_YAML_FILE = f\"{LOCAL_DIR}/data.yaml\"\n",
    "MODEL_PATH = \"yolo11n.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abba8b6a0ec4783907e3cbe2932ce18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset.zip:   0%|          | 0.00/9.57G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not set the permissions on the file '/teamspace/studios/this_studio/.cache/huggingface/download/v7Xt8H1GQ8W09J-6CSgzA0zuBH0=.d957c623096e6fa45d2927706b5d650c880bbad6352ec28015eb8af4f6b5777f.incomplete'. Error: [Errno 13] Permission denied: '/teamspace/studios/tmp_bd1a2057-6f88-46dc-b62f-c460aa2ac889'.\n",
      "Continuing without setting permissions.\n",
      "Unzipping: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.60G/9.60G [00:56<00:00, 170MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# download the dataset and unzip it\n",
    "hf_hub_download(repo_id=REPO_ID, filename=FILENAME_IN_REPO, repo_type=REPO_TYPE, local_dir=LOCAL_DIR)\n",
    "unzip_file(DATASET_PATH, LOCAL_DIR)\n",
    "\n",
    "\n",
    "# Get the number of CPU cores\n",
    "num_cores = os.cpu_count()\n",
    "print(f\"Number of CPU cores: {num_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data yaml file written!.............\n"
     ]
    }
   ],
   "source": [
    "# split paths for model\n",
    "data_yaml = f\"\"\"\n",
    "train: {TRAIN_PATH}\n",
    "val: {VAL_PATH}\n",
    "test: {TEST_PATH}\n",
    "\n",
    "nc: {NUM_CLASSES}\n",
    "names: {CLASSES}\n",
    "\"\"\"\n",
    "\n",
    "# write data yaml file\n",
    "with open(DATA_YAML_FILE, \"w\") as file:\n",
    "    file.write(data_yaml)\n",
    "    print(\"data yaml file written!.............\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    \n",
    "    # Define callback to report intermediate results\n",
    "    def on_train_epoch_end(score, epoch):\n",
    "        trial.report(score, step=epoch)  \n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    callbacks = {\n",
    "        \"on_train_epoch_end\" : on_train_epoch_end\n",
    "    }\n",
    "    \n",
    "    # Define hyperparameters using Optuna suggestions\n",
    "    lr0 = trial.suggest_float(\"lr0\", 1e-5, 1e-3, log=True)\n",
    "    lrf = trial.suggest_float(\"lrf\", 0.1, 1, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.00001, 0.01, log=True)\n",
    "    warmup_momentum = trial.suggest_float(\"warmup_momentum\", 0.6, 0.9)\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.8, 0.99)\n",
    "    \n",
    "    CONFIG_DICT = {\n",
    "    \"task\": \"detect\",\n",
    "    \"mode\": \"train\",\n",
    "    \"bohb\": True,\n",
    "    \"custom_callbacks\": callbacks,\n",
    "    \"data\": DATA_YAML_FILE,\n",
    "    \"batch\": 640,\n",
    "    \"imgsz\": 320,\n",
    "    \"save\": True,\n",
    "    \"device\": 0,\n",
    "    \"workers\": num_cores,\n",
    "    \"pretrained\": True,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 5,\n",
    "    \"warmup_epochs\": 2,\n",
    "    \"patience\": 1}\n",
    "\n",
    "    # Train YOLO model\n",
    "    model = YOLO11Model(MODEL_PATH)\n",
    "    model.train(**CONFIG_DICT, lr0=lr0, lrf=lrf, momentum=momentum, weight_decay=weight_decay, warmup_momentum=warmup_momentum)\n",
    "    \n",
    "    # Return validation mAP as the objective value\n",
    "    return model.score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 18:06:56,460] A new study created in memory with name: yolo11_tuning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.97 ðŸš€ Python-3.10.10 torch-2.2.1+cu121 CUDA:0 (NVIDIA L40S, 45596MiB)\n",
      "\u001b[34m\u001b[1mtrainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/teamspace/studios/this_studio/data.yaml, epochs=10, time=None, patience=2, batch=704, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=16, project=None, name=train, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.00018479658518959094, lrf=0.6517410260408169, momentum=0.829608869562936, weight_decay=0.0012474346648448068, warmup_epochs=2, warmup_momentum=0.7625736217592378, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/teamspace/studios/this_studio/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 108MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  blocks.Conv                                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  blocks.Conv                                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  blocks.C3k2                                  [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  blocks.C3k2                                  [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  blocks.C3k2                                  [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  blocks.Conv                                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  blocks.C3k2                                  [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  blocks.SPPF                                  [256, 256, 5]                 \n",
      " 10                  -1  1    249728  blocks.C2PSA                                 [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  blocks.Concat                                [1]                           \n",
      " 13                  -1  1    111296  blocks.C3k2                                  [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  blocks.Concat                                [1]                           \n",
      " 16                  -1  1     32096  blocks.C3k2                                  [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  blocks.Conv                                  [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  blocks.Concat                                [1]                           \n",
      " 19                  -1  1     86720  blocks.C3k2                                  [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  blocks.Conv                                  [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  blocks.Concat                                [1]                           \n",
      " 22                  -1  1    378880  blocks.C3k2                                  [384, 256, 1, True]           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23        [16, 19, 22]  1    753262  blocks.Detect                                [10, [64, 128, 256]]          \n",
      "YOLO11n summary: 239 layers, 2,912,430 parameters, 2,912,414 gradients, 7.7 GFLOPs\n",
      "\n",
      "Transferred 421/463 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /teamspace/studios/this_studio/dataset/train... 20000 images, 4 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:11<00:00, 1814.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /teamspace/studios/this_studio/dataset/train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /teamspace/studios/this_studio/dataset/val... 1400 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:00<00:00, 1762.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /teamspace/studios/this_studio/dataset/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profilelibpng warning: iCCP: known incorrect sRGB profile\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00018479658518959094, momentum=0.829608869562936) with parameter groups 75 weight(decay=0.0), 82 weight(decay=0.013721781313292875), 81 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 320 train, 320 val\n",
      "Using 16 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29 [00:00<?, ?it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "       1/10      23.2G      1.189      3.767      1.364        916        320:   3%|â–Ž         | 1/29 [00:14<06:53, 14.75s/it]libpng warning: iCCP: known incorrect sRGB profile\n",
      "       1/10        25G      1.162      3.751      1.343        889        320:  28%|â–ˆâ–ˆâ–Š       | 8/29 [00:20<00:23,  1.11s/it]libpng warning: iCCP: known incorrect sRGB profile\n",
      "       1/10        25G      1.131      3.632      1.311        947        320:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 15/29 [00:24<00:08,  1.59it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "       1/10        25G      1.115      3.312      1.268        364        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:33<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: AVG Box Loss: 1.1146 | AVG Cls Loss: 3.3121 | AVG DFL Loss: 1.2684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781    0.00514      0.789       0.11     0.0691\n",
      "Epoch 1: AVG Val Box Loss: 1.3523 | AVG Val Cls Loss: 3.5391 | AVG Val DFL Loss: 1.3978 | Total Val Loss: 6.2891\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      22.8G      1.136      2.604      1.239        862        320:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:05<00:11,  1.67it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "       2/10      22.8G      1.145      2.247      1.239        366        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:17<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: AVG Box Loss: 1.1446 | AVG Cls Loss: 2.2466 | AVG DFL Loss: 1.2393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.504      0.372      0.401       0.25\n",
      "Epoch 2: AVG Val Box Loss: 1.2779 | AVG Val Cls Loss: 2.7250 | AVG Val DFL Loss: 1.2703 | Total Val Loss: 5.2733\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10        23G       1.13      1.743      1.229        862        320:  31%|â–ˆâ–ˆâ–ˆ       | 9/29 [00:05<00:11,  1.75it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "       3/10        23G      1.124      1.613      1.226        331        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:16<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: AVG Box Loss: 1.1243 | AVG Cls Loss: 1.6134 | AVG DFL Loss: 1.2260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.636      0.528      0.547      0.365\n",
      "Epoch 3: AVG Val Box Loss: 1.2215 | AVG Val Cls Loss: 2.1454 | AVG Val DFL Loss: 1.2417 | Total Val Loss: 4.6086\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      23.1G      1.084      1.354      1.204        925        320:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 16/29 [00:09<00:07,  1.71it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "       4/10      23.1G      1.083      1.323      1.205        370        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:16<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: AVG Box Loss: 1.0831 | AVG Cls Loss: 1.3227 | AVG DFL Loss: 1.2055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.687      0.605      0.661      0.437\n",
      "Epoch 4: AVG Val Box Loss: 1.2060 | AVG Val Cls Loss: 1.6648 | AVG Val DFL Loss: 1.2486 | Total Val Loss: 4.1194\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      22.9G      1.065      1.214      1.191        931        320:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 11/29 [00:06<00:10,  1.68it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "       5/10      22.9G      1.043       1.19      1.183        915        320:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 27/29 [00:15<00:01,  1.68it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "       5/10      22.9G      1.043      1.193      1.183        369        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:16<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: AVG Box Loss: 1.0427 | AVG Cls Loss: 1.1928 | AVG DFL Loss: 1.1834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1400       1781      0.748      0.689      0.757      0.522\n",
      "Epoch 5: AVG Val Box Loss: 1.0909 | AVG Val Cls Loss: 1.2729 | AVG Val DFL Loss: 1.1412 | Total Val Loss: 3.5050\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      23.1G      1.016       1.11      1.163        970        320:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 14/29 [00:07<00:08,  1.70it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "       6/10      23.1G      1.008      1.087      1.164        357        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:16<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: AVG Box Loss: 1.0078 | AVG Cls Loss: 1.0873 | AVG DFL Loss: 1.1637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    }
   ],
   "source": [
    "# Define the study\n",
    "NUM_TRIALS = 30\n",
    "study = optuna.create_study(direction='maximize', \n",
    "                            sampler=optuna.samplers.TPESampler(), \n",
    "                            pruner=optuna.pruners.HyperbandPruner(),\n",
    "                            study_name=\"yolo11_tuning\",\n",
    "                            load_if_exists=True)\n",
    "\n",
    "# Optimize with a callback to stop after NUM_TRIALS complete trials\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(study, \"optuna_study.pkl\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
